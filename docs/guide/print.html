<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Shadow Simulator</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="custom.css">


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Shadow Simulator</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/shadow/shadow" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="the-shadow-simulator"><a class="header" href="#the-shadow-simulator">The Shadow Simulator</a></h1>
<h2 id="what-is-shadow"><a class="header" href="#what-is-shadow">What is Shadow?</a></h2>
<p>Shadow is a discrete-event network simulator that directly executes real
application code, enabling you to simulate distributed systems with thousands of
network-connected processes in <strong>realistic</strong> and <strong>scalable</strong> private network
experiments using your laptop, desktop, or server running Linux.</p>
<p>Shadow experiments can be scientifically <strong>controlled</strong> and deterministically
<strong>replicated</strong>, making it easier for you to reproduce bugs and eliminate
confounding factors in your experiments.</p>
<h2 id="how-does-shadow-work"><a class="header" href="#how-does-shadow-work">How Does Shadow Work?</a></h2>
<p>Shadow directly executes <strong>real applications</strong>:</p>
<ul>
<li>Shadow directly executes unmodified, real application code using native OS
(Linux) processes.</li>
<li>Shadow co-opts the native processes into a discrete-event simulation by
interposing at the system call API.</li>
<li>The necessary system calls are emulated such that the applications need not
be aware that they are running in a Shadow simulation.</li>
</ul>
<p>Shadow connects the applications in a <strong>simulated network</strong>:</p>
<ul>
<li>Shadow constructs a private, virtual network through which the managed
processes can communicate.</li>
<li>Shadow internally implements simulated versions of common network protocols
(e.g., TCP and UDP).</li>
<li>Shadow internally models network routing characteristics (e.g., path latency
and packet loss) using a configurable network graph.</li>
</ul>
<h2 id="why-is-shadow-needed"><a class="header" href="#why-is-shadow-needed">Why is Shadow Needed?</a></h2>
<p>Network emulators (e.g., <a href="http://mininet.org">mininet</a>) run real application
code on top of real OS kernels in real time, but are non-determinsitic and have
limited scalability: time distortion can occur if emulated processes exceed an
unknown computational threshold, leading to undefined behavior.</p>
<p>Network simulators (e.g., <a href="https://www.nsnam.org">ns-3</a>) offer more experimental
control and scalability, but have limited application-layer realism because they
run application abstractions in place of real application code.</p>
<p>Shadow offers a novel, hybrid emulation/simulation architecture: it directly
executes real applications as native OS processes in order to faithfully
reproduce application-layer behavior while also co-opting the processes into a
high-performance network simulation that can scale to large distributed systems
with hundreds of thousands of processes.</p>
<h2 id="caveats"><a class="header" href="#caveats">Caveats</a></h2>
<p>Shadow implements <strong>over 150 functions from the system call API</strong>, but does not
yet fully support all API features. Although applications that make <em>basic</em> use
of the supported system calls should work out of the box, those that use more
<em>complex</em> features or functions may not yet function correctly when running in
Shadow. Extending support for the API is a work-in-progress.</p>
<p>That being said, we are particularly motivated to run large-scale <a href="https://www.torproject.org">Tor
Network</a> simulations. This use-case is already
fairly well-supported and we are eager to continue extending support for it.</p>
<h2 id="more-information"><a class="header" href="#more-information">More Information</a></h2>
<p>Homepage:</p>
<ul>
<li><a href="https://shadow.github.io">https://shadow.github.io</a></li>
</ul>
<p>Documentation:</p>
<ul>
<li><a href="https://shadow.github.io/docs/guide">User documentation</a></li>
<li><a href="https://shadow.github.io/docs/rust">Developer documentation</a></li>
</ul>
<p>Community Support:</p>
<ul>
<li><a href="https://github.com/shadow/shadow/discussions">https://github.com/shadow/shadow/discussions</a></li>
</ul>
<p>Bug Reports:</p>
<ul>
<li><a href="https://github.com/shadow/shadow/issues">https://github.com/shadow/shadow/issues</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="shadow-design-overview"><a class="header" href="#shadow-design-overview">Shadow Design Overview</a></h1>
<p>Shadow is a multi-threaded network experimentation tool that is designed as a
hybrid between simulation and emulation architectures: it directly executes
applications as Linux processes, but runs them in the context of a
discrete-event network simulation.</p>
<p>Shadow's version 2 design is summarized in the following sections. Please see
the end of this document for references to published design articles with more
details.</p>
<h2 id="executing-applications"><a class="header" href="#executing-applications">Executing Applications</a></h2>
<p>Shadow directly executes real, unmodified application binaries natively in Linux
as standard OS processes (using <code>vfork()</code> and <code>execvpe()</code>): we call these
processes executed by Shadow <em>managed processes</em>. When executing each managed
process, Shadow dynamically injects a shim library using preloading (via the
<code>LD_PRELOAD</code> environment variable) and establishes an inter-process control
channel using shared memory and semaphores. The control channel enables Shadow
to exchange messages with the shim and to instruct the shim to perform actions
in the managed process space.</p>
<h2 id="intercepting-system-calls"><a class="header" href="#intercepting-system-calls">Intercepting System Calls</a></h2>
<p>The shim co-opts each running managed process into the simulation environment by
intercepting all system calls they make rather than allowing them to be handled
by the Linux kernel. System call interception happens through two methods: first
via preloading and second via a seccomp filter.</p>
<ul>
<li>
<p>Preloading: Because the shim is preloaded, the shim will be the first library
that is searched when attempting to dynamically resolve symbols. We use the shim
to override functions in other shared libraries (e.g., system call wrapper
functions from libc) by supplying identically named functions with alternative
implementations inside the shim. Note that preloading works on dynamically
linked function calls (e.g., to libc system call wrappers), but not on
statically linked function calls (e.g. those made from inside of libc) or system
calls made using a <code>syscall</code> instruction.</p>
</li>
<li>
<p>seccomp: System calls that are not interceptable via preloading are
intercepted using the kernel's seccomp facility. The shim of each managed
process installs a seccomp filter that traps all system calls (except those made
from the shim) and a handler function to handle the trapped system calls. This
facility has a very small overhead because it involves running the installed
filter in kernel mode, but we infrequently incur this overhead in practice since
most system calls are interceptable via the more efficient preloading method.</p>
</li>
</ul>
<h2 id="emulating-system-calls"><a class="header" href="#emulating-system-calls">Emulating System Calls</a></h2>
<p>System calls that are intercepted by the shim (using either preloading or
seccomp) are emulated by Shadow. Hot-path system calls (e.g., time-related
system calls) are handled directly in the shim by using state that is stored in
shared memory. Other system calls are sent from the shim to Shadow via the
control channel and handled in Shadow (the shim sends the system call number and
argument registers). While the shim is waiting for a system call to be serviced
by Shadow, the managed process is blocked; this allows Shadow to precisely
control the running state of each process.</p>
<p>Shadow emulates system calls using its simulated kernel. The simulated kernel
(re)implements (i.e., simulates) important system functionality, including: the
passage of time; input and output operations on file, socket, pipe, timer, and
event descriptors; signals; packet transmissions with respect to transport layer
protocols such as TCP and UDP; and aspects of computer networking including
routing, queuing, and bandwidth limits. Thus, Shadow establishes a private,
simulated network environment that is completely isolated from the real network,
but is internally interoperable and entirely controllable.</p>
<p>Care is taken to ensure that all random bytes that are needed during the
simulation are initiated from a seeded pseudorandom source, including during the
emulation of system calls such as <code>getrandom()</code> and when emulating reads from
files like <code>/dev/*random</code>. This enables Shadow to produce deterministic
simulations, i.e., running a simulation twice using the same inputs and the same
seed should produce the same sequence of operations in the managed process.</p>
<h2 id="managing-memory"><a class="header" href="#managing-memory">Managing Memory</a></h2>
<p>Some system calls pass dynamically allocated memory addresses (e.g., the buffer
address in the <code>sendto()</code> system call). To handle this system call in Shadow,
this shim sends the buffer address but not the buffer contents to Shadow. Shadow
uses an inter-process memory access manager to directly and efficiently read and
write the memory of each managed process without extraneous data copies or
control messages. Briefly, the memory manager (re)maps the memory of each
managed process into a shared memory file that is accessible by both Shadow and
the managed process. When Shadow needs to copy data from a memory address passed
to it by the shim, the memory manager translates the managed process's memory
address to a shared memory address and brokers requested data copies. This
approach minimizes the number of data copies and system calls needed to transfer
the buffer contents from the managed process to Shadow.</p>
<h2 id="scheduling"><a class="header" href="#scheduling">Scheduling</a></h2>
<p>Shadow is designed to be high performance: it uses a thread for every virtual
host configured in an experiment while only allowing a number of threads equal
to the number of available CPU cores to run in parallel to avoid performance
degradation caused by CPU oversubscription. Work stealing is used to ensure that
each core is always running a worker thread as long as remaining work exists.
Shadow also effectively uses CPU pinning to reduce the frequency of cache
misses, CPU migrations, and context switches.</p>
<h1 id="research"><a class="header" href="#research">Research</a></h1>
<p>Shadow's design is based on the following published research articles. Please
cite our work when using Shadow in your projects.</p>
<h2 id="shadow-version-2-latest"><a class="header" href="#shadow-version-2-latest">Shadow version 2 (latest)</a></h2>
<p>This is the latest v2 design described above:</p>
<p>Co-opting Linux Processes for High-Performance Network Simulation<br />
by Rob Jansen, Jim Newsome, and Ryan Wails<br />
in the 2022 USENIX Annual Technical Conference, 2022.</p>
<pre><code>@inproceedings{netsim-atc2022,
  author = {Rob Jansen and Jim Newsome and Ryan Wails},
  title = {Co-opting Linux Processes for High-Performance Network Simulation},
  booktitle = {USENIX Annual Technical Conference},
  year = {2022},
  note = {See also \url{https://netsim-atc2022.github.io}},
}
</code></pre>
<h2 id="shadow-version-1-original"><a class="header" href="#shadow-version-1-original">Shadow version 1 (original)</a></h2>
<p>This is the original v1 design, using plugins loaded into the Shadow process
rather than independent processes:</p>
<p>Shadow: Running Tor in a Box for Accurate and Efficient Experimentation<br />
by Rob Jansen and Nicholas Hopper<br />
in the Symposium on Network and Distributed System Security, 2012.</p>
<pre><code>@inproceedings{shadow-ndss12,
  title = {Shadow: Running Tor in a Box for Accurate and Efficient Experimentation},
  author = {Rob Jansen and Nicholas Hopper},
  booktitle = {Symposium on Network and Distributed System Security},
  year = {2012},
  note = {See also \url{https://shadow.github.io}},
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="supported-platforms"><a class="header" href="#supported-platforms">Supported Platforms</a></h1>
<h2 id="officially-supported-platforms"><a class="header" href="#officially-supported-platforms">Officially supported platforms</a></h2>
<p>We support the following Linux x86-64 distributions:</p>
<ul>
<li>Ubuntu 20.04, 22.04, 24.04</li>
<li>Debian 10, 11, and 12</li>
<li>Fedora 40</li>
</ul>
<p>We do not provide official support for other platforms. This means that we do
not ensure that Shadow successfully builds and passes tests on other platforms.
However, we will review pull requests that allow Shadow to build and run on
unsupported platforms.</p>
<p>Our policy regarding supported platforms can be found in our <a href="semver.html">"stability
guarantees"</a>.</p>
<h2 id="supported-linux-kernel-versions"><a class="header" href="#supported-linux-kernel-versions">Supported Linux kernel versions</a></h2>
<p>Some Linux distributions support multiple kernel versions, for example an older
General Availability (GA) kernel and newer hardware-enablement (HWE) kernels.
We try to allow Shadow to run on the oldest kernel supported on each
distribution (the GA kernel). However:</p>
<ul>
<li>On Debian 10 (buster) We do not support the GA kernel. We do support the HWE
kernel (e.g. installed via backports).</li>
<li>We are currently only able to regularly test on the latest Ubuntu kernel,
since that's what GitHub Actions provides.</li>
</ul>
<p>By these criteria, Shadow's oldest supported kernel version is currently 5.4
(the GA kernel in Ubuntu 20.04.0).</p>
<h2 id="docker"><a class="header" href="#docker">Docker</a></h2>
<p>If you are installing Shadow within a Docker container, you must increase the
size of the container's <code>/dev/shm</code> mount and disable the seccomp security
profile. You can do this by passing additional flags to <code>docker run</code>.</p>
<p>Example:</p>
<pre><code class="language-bash">docker run -it --shm-size=1024g --security-opt seccomp=unconfined ubuntu:24.04
</code></pre>
<p>If you are having difficulty installing Shadow on any supported platforms, you
may find the <a href="https://github.com/shadow/shadow/blob/main/.github/workflows/run_tests.yml">continuous integration build
steps</a>
helpful.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="installing-dependencies"><a class="header" href="#installing-dependencies">Installing Dependencies</a></h1>
<h3 id="required"><a class="header" href="#required">Required:</a></h3>
<ul>
<li>gcc, gcc-c++</li>
<li>python (version &gt;= 3.6)</li>
<li>glib (version &gt;= 2.58.0)</li>
<li>cmake (version &gt;= 3.13.4)</li>
<li>make</li>
<li>pkg-config</li>
<li>xz-utils</li>
<li>lscpu</li>
<li>rustup (version ~ latest)</li>
<li>libclang (version &gt;= 9)</li>
</ul>
<h2 id="apt-debianubuntu"><a class="header" href="#apt-debianubuntu">APT (Debian/Ubuntu):</a></h2>
<pre><code class="language-bash"># required dependencies
sudo apt-get install -y \
    cmake \
    findutils \
    libclang-dev \
    libc-dbg \
    libglib2.0-0 \
    libglib2.0-dev \
    make \
    netbase \
    python3 \
    python3-networkx \
    xz-utils \
    util-linux \
    gcc \
    g++

# rustup: https://rustup.rs
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
</code></pre>
<p>On older versions of Debian or Ubuntu, the default version of libclang is too
old, which may cause bindgen to have errors finding system header files,
particularly when compiling with gcc. In this case you will need to explicitly
install a newer-than-default version of libclang. e.g. on <code>debian-10</code> install
<code>libclang-13-dev</code>.</p>
<h2 id="dnf-fedora"><a class="header" href="#dnf-fedora">DNF (Fedora):</a></h2>
<p><strong>Warning:</strong> <code>dnf</code> often installs 32-bit (<code>i686</code>) versions of
libraries. You may want to use the <code>--best</code> option to make sure you're
installing the 64-bit (<code>x86_64</code>) versions, which are required by Shadow.</p>
<pre><code class="language-bash"># required dependencies
sudo dnf install -y \
    cmake \
    findutils \
    clang-devel \
    glib2 \
    glib2-devel \
    make \
    python3 \
    python3-networkx \
    xz \
    xz-devel \
    yum-utils \
    diffutils \
    util-linux \
    gcc \
    gcc-c++

# rustup: https://rustup.rs
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="shadow-setup"><a class="header" href="#shadow-setup">Shadow Setup</a></h1>
<p>After building and testing Shadow, the install step is optional. If you do not
wish to install Shadow, you can run it directly from the build directory
(<code>./build/src/main/shadow</code>). Shadow only supports building from directories
that do not have whitespace characters.</p>
<pre><code class="language-bash">git clone https://github.com/shadow/shadow.git
cd shadow
./setup build --clean --test
./setup test
# Optionally install (to ~/.local/bin by default). Can otherwise run the binary
# directly at build/src/main/shadow.
./setup install
</code></pre>
<p>For the remainder of this documentation, we assume the Shadow binary is in your
<code>PATH</code>. The default installed location of <code>/home/${USER}/.local/bin</code> is
probably already in your <code>PATH</code>. If it isn't, you can add it by running:</p>
<pre><code class="language-bash">echo 'export PATH="${PATH}:/home/${USER}/.local/bin"' &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc
</code></pre>
<p>The path that Shadow is installed to must not contain any space characters as
they are not supported by the dynamic linker's <code>LD_PRELOAD</code> mechanism.</p>
<p>Check that Shadow is installed and runs:</p>
<pre><code class="language-bash">shadow --version
shadow --help
</code></pre>
<h2 id="uninstall-shadow"><a class="header" href="#uninstall-shadow">Uninstall Shadow</a></h2>
<p>After running <code>./setup install</code>, you can find the list of installed files in
<code>./build/install_manifest.txt</code>. To uninstall Shadow, remove any files listed.</p>
<h2 id="setup-notes"><a class="header" href="#setup-notes">Setup Notes</a></h2>
<ul>
<li>
<p>All build output is generated to the <code>./build</code> directory.</p>
</li>
<li>
<p>Use <code>./setup build --help</code> to see all build options; some useful build
options are:</p>
<ul>
<li><code>-g</code> or <code>--debug</code> to build Shadow with debugging symbols and additional
runtime checks. This option will significantly reduce the simulator
performance.</li>
<li><code>--search</code> if you installed dependencies to non-standard locations.
Used when searching for libraries, headers, and pkg-config files.
Appropriate suffixes like <code>/lib</code> and <code>/include</code> of the provided path
are also searched  when looking for files of the corresponding type.</li>
<li><code>--prefix</code> if you want to install Shadow somewhere besides <code>~/.local</code>.</li>
</ul>
</li>
<li>
<p>The <code>setup</code> script is a wrapper to <code>cmake</code> and <code>make</code>. Using <code>cmake</code> and
<code>make</code> directly is also possible, but unsupported. For example:</p>
<pre><code class="language-bash"># alternative installation method
rm -r build &amp;&amp; mkdir build &amp;&amp; cd build
cmake -DCMAKE_INSTALL_PREFIX="~/.local" -DSHADOW_TEST=ON ..
make
ctest
make install
</code></pre>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="system-configs-and-limits"><a class="header" href="#system-configs-and-limits">System Configs and Limits</a></h1>
<p>Some Linux system configuration changes are needed to run large-scale Shadow
simulations (more than about 1000 processes). If you're just trying Shadow or
running small simulations, you can skip these steps.</p>
<h2 id="number-of-open-files"><a class="header" href="#number-of-open-files">Number of Open Files</a></h2>
<p>There is a default Linux system limit on the total number of open files. Since
Shadow opens files from within its own process space and not from within the
managed processes, both the system limit and the per-process limit must be
greater than the combined total number of files opened by all managed
processes. If each managed process in your simulation opens many files, you'll
likely want to increase the limit so that your application doesn't receive
<code>EMFILE</code> errors when calling <code>open()</code>.</p>
<h3 id="system-wide-limits"><a class="header" href="#system-wide-limits">System-wide Limits</a></h3>
<p>Check the <em>system-wide</em> limits with:</p>
<pre><code class="language-bash">sysctl fs.nr_open # per-process open file limit
sysctl fs.file-max # system-wide open file limit
</code></pre>
<p>Use <code>cat /proc/sys/fs/file-nr</code> to find:</p>
<ol>
<li>the current, system-wide number of used file handles</li>
<li>the current, system-wide number of free file handles</li>
<li>and the system-wide limit on the maximum number of open files for all processes</li>
</ol>
<p>Change the limits, persistent across reboots, and apply now:</p>
<pre><code class="language-bash">sudo sysctl -w fs.nr_open=10485760
echo "fs.nr_open = 10485760" | sudo tee -a /etc/sysctl.conf
sudo sysctl -w fs.file-max=10485760
echo "fs.file-max = 10485760" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
</code></pre>
<h3 id="user-limits"><a class="header" href="#user-limits">User Limits</a></h3>
<p>Check the maximum number of open file descriptors <em>currently allowed</em> in your
session:</p>
<pre><code class="language-bash">ulimit -n
</code></pre>
<p>Check the number of files <em>currently used</em> in a process with pid=PID:</p>
<pre><code class="language-bash">/bin/ls -l /proc/PID/fd/ | wc -l
</code></pre>
<p>You will want to almost certainly want to raise the user file limit by modifying
<code>/etc/security/limits.conf</code>. For example:</p>
<pre><code>rjansen soft nofile 10485760
rjansen hard nofile 10485760
</code></pre>
<p>The max you can use is your <code>fs.nr_open</code> system-wide limit setting from above.
You need to either log out and back in or reboot for the changes to take affect.
You can watch <code>/proc/sys/fs/file-nr</code> and reduce the limit according to your
usage, if you'd like.</p>
<h3 id="systemd-limits"><a class="header" href="#systemd-limits">systemd Limits</a></h3>
<p>systemd may place a limit on the number of tasks that a user can run in its
slice. You can check to see if a limit is in place by running</p>
<pre><code>$ systemctl status user-$UID.slice
</code></pre>
<p>Here's a listing of an example response:</p>
<pre><code>● user-1027.slice - User Slice of &lt;user&gt;
   Loaded: loaded
Transient: yes
  Drop-In: /run/systemd/system/user-1027.slice.d
           └─50-After-systemd-logind\x2eservice.conf, 50-After-systemd-user-sessions\x2eservice.conf, 50-Description.conf, 50-TasksMax.conf
   Active: active since Wed 2020-05-06 21:20:08 EDT; 1 years 2 months ago
    Tasks: 81 (limit: 12288)
</code></pre>
<p>The last line of the listing shows that this user has a task limit of 12288
tasks.</p>
<p>If this task limit is too small, it can be removed with the following command:</p>
<pre><code>$ sudo systemctl set-property user-$UID.slice TasksMax=infinity
</code></pre>
<h2 id="number-of-maps"><a class="header" href="#number-of-maps">Number of Maps</a></h2>
<p>There is a system limit on the number of <code>mmap()</code> mappings per process. Most
users will not have to modify these settings. However, if an application running
in Shadow makes extensive use of <code>mmap()</code>, you may need to increase the limit.</p>
<h3 id="process-limit"><a class="header" href="#process-limit">Process Limit</a></h3>
<p>The process limit can be queried in these ways:</p>
<pre><code class="language-bash">sysctl vm.max_map_count
cat /proc/sys/vm/max_map_count
</code></pre>
<p>You can check the number of maps currently used in a process with pid=PID like
this:</p>
<pre><code class="language-bash">wc -l /proc/PID/maps
</code></pre>
<p>Set a new limit, make it persistent, apply it now:</p>
<pre><code class="language-bash">sudo sysctl -w vm.max_map_count=1073741824
echo "vm.max_map_count = 1073741824" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
</code></pre>
<h2 id="process--thread-count-limits"><a class="header" href="#process--thread-count-limits">Process / Thread Count Limits</a></h2>
<h3 id="system-wide-limits-1"><a class="header" href="#system-wide-limits-1">System-Wide Limits</a></h3>
<p>The kernel may limit the max-pid value to a small value, which will limit the
total number of possible processes running on the machine. This limit can be
raised by the command</p>
<pre><code class="language-bash">sudo sysctl -w kernel.pid_max=4194304
echo "kernel.pid_max = 4194304" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
</code></pre>
<p>The kernel may also limit the total number of threads running on the machine.
This limit can be raised, too.</p>
<pre><code class="language-bash">sudo sysctl -w kernel.threads-max=4194304
echo "kernel.threads-max = 4194304" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
</code></pre>
<p>The kernel has a <a href="https://github.com/torvalds/linux/blob/b8481381d4e2549f06812eb6069198144696340c/include/linux/threads.h#L30-L35">fixed system-wide limit</a> of 4,194,304
processes/threads. When running extremely large simulations, or when running
multiple simulations in parallel, you should be aware of this limit and ensure
the total number of processes/threads used by all simulations will not exceed
this limit.</p>
<p>The kernel may cap the <code>kernel.threads-max</code> value automatically so that, in the
maximum limit, the memory consumed by kernel thread control structures do not
consume more than approx. (1/8)th of system memory (see
<a href="https://stackoverflow.com/a/21926745">https://stackoverflow.com/a/21926745</a>).</p>
<h3 id="user-limits-1"><a class="header" href="#user-limits-1">User Limits</a></h3>
<p>You may need to raise the maximum number of user processes allowed in
<code>/etc/security/limits.conf</code>. For example, user limits can be removed with the
lines:</p>
<pre><code>rjansen soft nproc unlimited
rjansen hard nproc unlimited
</code></pre>
<h2 id="for-more-information"><a class="header" href="#for-more-information">For more information</a></h2>
<p><a href="https://www.kernel.org/doc/Documentation/sysctl/fs.txt">https://www.kernel.org/doc/Documentation/sysctl/fs.txt</a><br />
<a href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt">https://www.kernel.org/doc/Documentation/sysctl/vm.txt</a></p>
<pre><code class="language-bash">man proc
man ulimit
cat /proc/sys/fs/file-max
cat /proc/sys/fs/inode-max
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="running-shadow"><a class="header" href="#running-shadow">Running Shadow</a></h1>
<p>When installing Shadow, the main executable was placed in <code>/bin</code> in your install
prefix (<code>~/.local/bin</code> by default). As a reminder, it would be helpful if this
location was included in your environment <code>PATH</code>.</p>
<p>The main Shadow binary executable, <code>shadow</code>, contains most of the simulator's
code, including events and the event engine, the network stack, and the routing
logic. Shadow's event engine supports multi-threading using the <code>-p</code> or
<code>--parallelism</code> flags (or their corresponding <a href="shadow_config_spec.html#generalparallelism">configuration file
option</a>) to simulate multiple hosts
in parallel.</p>
<p>In the following sections we provide some examples to help you get started, but
Shadow's configuration format is entirely specified in the <a href="shadow_config_spec.html">"Shadow Config
Specification"</a> and <a href="network_graph_spec.html">"Network Graph
Specification"</a> documents. You will find these useful
once you begin writing your own simulations.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="basic-file-transfer-example"><a class="header" href="#basic-file-transfer-example">Basic File Transfer Example</a></h1>
<p>Here we present a basic example that simulates the network traffic of an HTTP
server with 3 clients, each running on different virtual hosts. If you do not
have Python or cURL installed, you can download them through your distribution's
package manager.</p>
<h2 id="configuring-the-simulation"><a class="header" href="#configuring-the-simulation">Configuring the Simulation</a></h2>
<p>Each client uses cURL to make an HTTP request to a basic Python HTTP server.</p>
<p>Shadow requires a configuration file that specifies information about the
network graph and the processes to run within the simulation. This example uses
a <a href="shadow_config_spec.html#networkgraphtype">built-in network graph</a> for
simplicity.</p>
<p><code>shadow.yaml</code>:</p>
<pre><code class="language-yaml">general:
  # stop after 10 simulated seconds
  stop_time: 10s
  # old versions of cURL use a busy loop, so to avoid spinning in this busy
  # loop indefinitely, we add a system call latency to advance the simulated
  # time when running non-blocking system calls
  model_unblocked_syscall_latency: true

network:
  graph:
    # use a built-in network graph containing
    # a single vertex with a bandwidth of 1 Gbit
    type: 1_gbit_switch

hosts:
  # a host with the hostname 'server'
  server:
    network_node_id: 0
    processes:
    - path: python3
      args: -m http.server 80
      start_time: 3s
      # tell shadow to expect this process to still be running at the end of the
      # simulation
      expected_final_state: running
  # three hosts with hostnames 'client1', 'client2', and 'client3' using a yaml
  # anchor to avoid duplicating the options for each host
  client1: &amp;client_host
    network_node_id: 0
    processes:
    - path: curl
      args: -s server
      start_time: 5s
  client2: *client_host
  client3: *client_host
</code></pre>
<h2 id="running-the-simulation"><a class="header" href="#running-the-simulation">Running the Simulation</a></h2>
<p>Shadow stores simulation data to the <code>shadow.data/</code> directory by default. We
first remove this directory if it already exists, and then run Shadow.</p>
<pre><code class="language-bash"># delete any existing simulation data
rm -rf shadow.data/
shadow shadow.yaml &gt; shadow.log
</code></pre>
<p>This small Shadow simulation should complete almost immediately.</p>
<h2 id="viewing-the-simulation-output"><a class="header" href="#viewing-the-simulation-output">Viewing the Simulation Output</a></h2>
<p>Shadow will write simulation output to the data directory <code>shadow.data/</code>. Each
host has its own directory under <code>shadow.data/hosts/</code>. For example:</p>
<pre><code class="language-bash">$ ls -l shadow.data/hosts/
drwxrwxr-x 2 user user 4096 Jun  2 16:54 client1
drwxrwxr-x 2 user user 4096 Jun  2 16:54 client2
drwxrwxr-x 2 user user 4096 Jun  2 16:54 client3
drwxrwxr-x 2 user user 4096 Jun  2 16:54 server
</code></pre>
<p>Each host directory contains the output for each process running on that host.
For example:</p>
<pre><code class="language-bash">$ ls -l shadow.data/hosts/client1/
-rw-rw-r-- 1 user user   0 Jun  2 16:54 curl.1000.shimlog
-rw-r--r-- 1 user user   0 Jun  2 16:54 curl.1000.stderr
-rw-r--r-- 1 user user 542 Jun  2 16:54 curl.1000.stdout

$ cat shadow.data/hosts/client1/curl.1000.stdout
&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd"&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt;
&lt;title&gt;Directory listing for /&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Directory listing for /&lt;/h1&gt;
...
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="traffic-generation-example"><a class="header" href="#traffic-generation-example">Traffic Generation Example</a></h1>
<p><em>We recommend getting started with the <a href="getting_started_basic.html">basic file
transfer</a> before running this example. It contains
some basics about running Shadow simulations that are not covered here.</em></p>
<p>During Shadow simulations, it is often useful to generate background traffic
flows between your simulated hosts. This example uses the <a href="https://github.com/shadow/tgen">TGen traffic
generator</a> for this purpose.</p>
<p>TGen is capable of generating basic file transfers, where you can configure how
much data is transferred in each direction, how long to wait in between each
transfer, and how many transfers to perform. TGen also supports more complex
behavior models: you can use Markov models to configure a state machine with
precise inter-packet timing characteristics. We only make use of its basic
features in this example.</p>
<p>If you don't have it installed, you can follow the <a href="https://github.com/shadow/tgen/#setup">instructions
here</a>. The following example runs TGen
with 10 clients that each download 10 files from a server over a simple network
graph.</p>
<h2 id="a-shadow-simulation-using-tgen"><a class="header" href="#a-shadow-simulation-using-tgen">A Shadow Simulation using TGen</a></h2>
<p>The following examples simulates a network with 1 TGen server and 10 TGen clients
that are generating TCP traffic to and from the server.</p>
<h3 id="configuring-shadow"><a class="header" href="#configuring-shadow">Configuring Shadow</a></h3>
<p>The <code>shadow.yaml</code> file instructs Shadow how to model the network that is used to
carry the traffic between the hosts, and about the bandwidth available to each
of the hosts. It also specifies how many processes to run in the simulation, and
the configuration options for those applications.</p>
<p><code>shadow.yaml</code>:</p>
<pre><code class="language-yaml">general:
  stop_time: 10m
  # Needed to avoid deadlock in some configurations of tgen.
  # See below.
  model_unblocked_syscall_latency: true

network:
  graph:
    # a custom single-node graph
    type: gml
    inline: |
      graph [
        node [
          id 0
          host_bandwidth_down "140 Mbit"
          host_bandwidth_up "18 Mbit"
        ]
        edge [
          source 0
          target 0
          latency "50 ms"
          packet_loss 0.01
        ]
      ]
hosts:
  server:
    network_node_id: 0
    processes:
    # Assumes `tgen` is on your shell's `PATH`.
    # Otherwise use an absolute path here.
    - path: tgen
      # The ../../../ prefix assumes that tgen.server.graph.xml in the same
      # directory as the data directory (specified with the -d CLI argument).
      # See notes below explaining Shadow's directory structure.
      args: ../../../tgen.server.graphml.xml
      start_time: 1s
      # Tell shadow to expect this process to still be running at the end of the
      # simulation.
      expected_final_state: running
  client1: &amp;client_host
    network_node_id: 0
    processes:
    - path: tgen
      args: ../../../tgen.client.graphml.xml
      start_time: 2s
  client2: *client_host
  client3: *client_host
  client4: *client_host
  client5: *client_host
</code></pre>
<p>We can see that Shadow will be running 6 processes in total, and that those
processes are configured using <code>graphml.xml</code> files (the configuration file
format for TGen) as arguments.</p>
<p>Each host directory is also the <a href="https://en.wikipedia.org/wiki/Working_directory">working
directory</a> for the host's
processes, which is why we specified <code>../../../tgen.server.graphml.xml</code> as the
path to the TGen configuration in our Shadow configuration file
(<code>./shadow.data/hosts/server/../../../tgen.server.graphml.xml</code> →
<code>./tgen.server.graphml.xml</code>). The host directory structure is <em>stable</em>---it is
guaranteed not to change between minor releases, so the <code>../../../</code> prefix may
reliably be used to refer to files in the same directory as the data directory.</p>
<p><code>model_unblocked_syscall_latency</code> is used to avoid deadlock in case tgen was
compiled with <a href="compatibility_notes.html#libopenblas">libopenblas</a>.</p>
<h3 id="configuring-tgen"><a class="header" href="#configuring-tgen">Configuring TGen</a></h3>
<p>Each TGen process requires an action-dependency graph in order to configure the
behavior of the clients and server. See the <a href="https://github.com/shadow/tgen/tree/main/doc">TGen
documentation</a> for more
information about customizing TGen behaviors.</p>
<h4 id="our-tgen-server"><a class="header" href="#our-tgen-server">Our TGen Server</a></h4>
<p>The main configuration here is the port number on which the server will listen.</p>
<p><code>tgen.server.graphml.xml</code>:</p>
<pre><code class="language-xml">&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"&gt;
  &lt;key attr.name="serverport" attr.type="string" for="node" id="d1" /&gt;
  &lt;key attr.name="loglevel" attr.type="string" for="node" id="d0" /&gt;
  &lt;graph edgedefault="directed"&gt;
    &lt;node id="start"&gt;
      &lt;data key="d0"&gt;info&lt;/data&gt;
      &lt;data key="d1"&gt;8888&lt;/data&gt;
    &lt;/node&gt;
  &lt;/graph&gt;
&lt;/graphml&gt;
</code></pre>
<h4 id="our-tgen-clients"><a class="header" href="#our-tgen-clients">Our TGen Clients</a></h4>
<p>The client config specifies that we connect to the server using its name and
port <code>server:8888</code>, and that we download and upload <code>1 MiB</code> 10 times, pausing 1,
2, or 3 seconds between each transfer.</p>
<p><code>tgen.client.graphml.xml</code>:</p>
<pre><code class="language-xml">&lt;?xml version="1.0" encoding="utf-8"?&gt;&lt;graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"&gt;
  &lt;key attr.name="recvsize" attr.type="string" for="node" id="d5" /&gt;
  &lt;key attr.name="sendsize" attr.type="string" for="node" id="d4" /&gt;
  &lt;key attr.name="count" attr.type="string" for="node" id="d3" /&gt;
  &lt;key attr.name="time" attr.type="string" for="node" id="d2" /&gt;
  &lt;key attr.name="peers" attr.type="string" for="node" id="d1" /&gt;
  &lt;key attr.name="loglevel" attr.type="string" for="node" id="d0" /&gt;
  &lt;graph edgedefault="directed"&gt;
    &lt;node id="start"&gt;
      &lt;data key="d0"&gt;info&lt;/data&gt;
      &lt;data key="d1"&gt;server:8888&lt;/data&gt;
    &lt;/node&gt;
    &lt;node id="pause"&gt;
      &lt;data key="d2"&gt;1,2,3&lt;/data&gt;
    &lt;/node&gt;
    &lt;node id="end"&gt;
      &lt;data key="d3"&gt;10&lt;/data&gt;
    &lt;/node&gt;
    &lt;node id="stream"&gt;
      &lt;data key="d4"&gt;1 MiB&lt;/data&gt;
      &lt;data key="d5"&gt;1 MiB&lt;/data&gt;
    &lt;/node&gt;
    &lt;edge source="start" target="stream" /&gt;
    &lt;edge source="pause" target="start" /&gt;
    &lt;edge source="end" target="pause" /&gt;
    &lt;edge source="stream" target="end" /&gt;
  &lt;/graph&gt;
&lt;/graphml&gt;
</code></pre>
<h3 id="running-the-simulation-1"><a class="header" href="#running-the-simulation-1">Running the Simulation</a></h3>
<p>With the above three files saved in the same directory, you can start a
simulation. Shadow stores simulation data to the <code>shadow.data/</code> directory by
default. We first remove this directory if it already exists, and then run
Shadow. This example may take a few minutes.</p>
<pre><code class="language-bash"># delete any existing simulation data
rm -rf shadow.data/
shadow shadow.yaml &gt; shadow.log
</code></pre>
<h3 id="simulation-output"><a class="header" href="#simulation-output">Simulation Output</a></h3>
<p>Shadow will write simulation output to the data directory <code>shadow.data/</code>. Each
host has its own directory under <code>shadow.data/hosts/</code>.</p>
<p>In the TGen process output, lines containing <code>stream-success</code> represent
completed downloads and contain useful timing statistics. From these lines we
should see that clients have completed a total of <strong>50</strong> streams:</p>
<pre><code class="language-text">$ for d in shadow.data/hosts/client*; do grep "stream-success" "${d}"/*.stdout ; done | wc -l
50
</code></pre>
<p>We can also look at the transfers from the servers' perspective:</p>
<pre><code class="language-text">$ for d in shadow.data/hosts/server*; do grep "stream-success" "${d}"/*.stdout ; done | wc -l
50
</code></pre>
<p>You can also parse the TGen output logged to the stdout files using the
<code>tgentools</code> program from the TGen repo, and plot the data in graphical format to
visualize the performance characteristics of the transfers. <a href="https://github.com/shadow/tgen/blob/main/doc/Tools-Setup.md">This
page</a> describes how
to get started.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="simple-tor-network-example"><a class="header" href="#simple-tor-network-example">Simple Tor Network Example</a></h1>
<p><em>We recommend getting started with the <a href="getting_started_basic.html">basic file
transfer</a> and <a href="getting_started_tgen.html">traffic
generation</a> examples to orient yourself with Shadow
before running this slightly more complex Tor simulation.</em></p>
<p>This example requires that you have installed:</p>
<ul>
<li><a href="https://github.com/torproject/tor/blob/main/README"><code>tor</code></a>; can typically be installed
via your system package manager.</li>
<li><a href="https://github.com/shadow/tgen"><code>tgen</code></a>; will most likely need to be built from source.</li>
</ul>
<h2 id="configuring-shadow-1"><a class="header" href="#configuring-shadow-1">Configuring Shadow</a></h2>
<p>This simulation again uses <code>tgen</code> as both client and server. In addition to a
<code>tor</code>-oblivious client and server, we add a <code>tor</code> network and a client that uses
<code>tor</code> to connect to the server.</p>
<p><code>shadow.yaml</code>:</p>
<pre><code class="language-yaml">general:
  stop_time: 30 min
network:
  graph:
    type: gml
    inline: |
      graph [
        directed 0
        node [
          id 0
          host_bandwidth_down "1 Gbit"
          host_bandwidth_up "1 Gbit"
        ]
        edge [
          source 0
          target 0
          latency "50 ms"
          jitter "0 ms"
          packet_loss 0.0
        ]
      ]
hosts:
  fileserver:
    network_node_id: 0
    processes:
    - path: tgen
      # See https://shadow.github.io/docs/guide/compatibility_notes.html#libopenblas
      environment: { OPENBLAS_NUM_THREADS: "1" }
      args: ../../../conf/tgen.server.graphml.xml
      start_time: 1
      expected_final_state: running
  4uthority:
    network_node_id: 0
    ip_addr: 100.0.0.1
    processes:
    - path: tor
      args: --Address 4uthority --Nickname 4uthority
            --defaults-torrc torrc-defaults -f torrc
      start_time: 1
      expected_final_state: running
  exit1:
    network_node_id: 0
    processes:
    - path: tor
      args: --Address exit1 --Nickname exit1
            --defaults-torrc torrc-defaults -f torrc
      start_time: 60
      expected_final_state: running
  exit2:
    network_node_id: 0
    processes:
    - path: tor
      args: --Address exit2 --Nickname exit2
            --defaults-torrc torrc-defaults -f torrc
      start_time: 60
      expected_final_state: running
  relay1:
    network_node_id: 0
    processes:
    - path: tor
      args: --Address relay1 --Nickname relay1
            --defaults-torrc torrc-defaults -f torrc
      start_time: 60
      expected_final_state: running
  relay2:
    network_node_id: 0
    processes:
    - path: tor
      args: --Address relay2 --Nickname relay2
            --defaults-torrc torrc-defaults -f torrc
      start_time: 60
      expected_final_state: running
  relay3:
    network_node_id: 0
    processes:
    - path: tor
      args: --Address relay3 --Nickname relay3
            --defaults-torrc torrc-defaults -f torrc
      start_time: 60
      expected_final_state: running
  relay4:
    network_node_id: 0
    processes:
    - path: tor
      args: --Address relay4 --Nickname relay4
            --defaults-torrc torrc-defaults -f torrc
      start_time: 60
      expected_final_state: running
  client:
    network_node_id: 0
    processes:
    - path: tgen
      # See https://shadow.github.io/docs/guide/compatibility_notes.html#libopenblas
      environment: { OPENBLAS_NUM_THREADS: "1" }
      args: ../../../conf/tgen.client.graphml.xml
      start_time: 600
  torclient:
    network_node_id: 0
    processes:
    - path: tor
      args: --Address torclient --Nickname torclient
            --defaults-torrc torrc-defaults -f torrc
      start_time: 900
      expected_final_state: running
    - path: tgen
      # See https://shadow.github.io/docs/guide/compatibility_notes.html#libopenblas
      environment: { OPENBLAS_NUM_THREADS: "1" }
      args: ../../../conf/tgen.torclient.graphml.xml
      start_time: 1500
</code></pre>
<h2 id="running-the-simulation-2"><a class="header" href="#running-the-simulation-2">Running the Simulation</a></h2>
<p>We run this example similarly as before. Here we use an additional command-line
flag <code>--template-directory</code> to copy a template directory layout containing each
host's <code>tor</code> configuraton files into its host directory before the simulation
begins.</p>
<p>For brevity we omit the contents of our template directory, and configuration files that are referenced from it, but you can find them at <a href="https://github.com/shadow/shadow/blob/main/examples/docs/tor/shadow.data.template"><code>examples/docs/tor/shadow.data.template/</code></a> and <a href="https://github.com/shadow/shadow/blob/main/examples/docs/tor/conf"><code>examples/docs/tor/conf/</code></a>.</p>
<pre><code class="language-bash"># delete any existing simulation data
rm -rf shadow.data/
shadow --template-directory shadow.data.template shadow.yaml &gt; shadow.log
</code></pre>
<h2 id="simulation-output-1"><a class="header" href="#simulation-output-1">Simulation Output</a></h2>
<p>As before, Shadow will write simulation output to the data directory
<code>shadow.data/</code>. Each host has its own directory under <code>shadow.data/hosts/</code>.</p>
<p>In the TGen process output, lines containing <code>stream-success</code> represent
completed downloads and contain useful timing statistics. From these lines we
should see that clients have completed a total of <strong>20</strong> streams:</p>
<pre><code class="language-text">$ for d in shadow.data/hosts/*client*; do grep "stream-success" "${d}"/*.stdout ; done | wc -l
50
</code></pre>
<p>We can also look at the transfers from the servers' perspective:</p>
<pre><code class="language-text">$ for d in shadow.data/hosts/fileserver*; do grep "stream-success" "${d}"/*.stdout ; done | wc -l
50
</code></pre>
<p>You can also parse the TGen output logged to the stdout files using the
<code>tgentools</code> program from the TGen repo, and plot the data in graphical format to
visualize the performance characteristics of the transfers. <a href="https://github.com/shadow/tgen/blob/main/doc/Tools-Setup.md">This
page</a> describes how
to get started.</p>
<h2 id="more-realistic-simulations"><a class="header" href="#more-realistic-simulations">More Realistic Simulations</a></h2>
<p>You can use the <a href="https://github.com/shadow/tornettools">tornettools
toolkit</a> to run larger, more
complex Tor networks that are meant to more accurately resemble the
characteristics and state of the public Tor network.</p>
<h2 id="determinism"><a class="header" href="#determinism">Determinism</a></h2>
<p>To improve determinism for your simulation, Shadow preloads an auxiliary
library, libshadow_openssl_rng, which override's some of openssl's RNG
routines. This is enabled by default, but can be controlled using the
experimental
<a href="shadow_config_spec.html#experimentaluse_openssl_rng_preload">use_openssl_rng_preload</a>
option.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="shadow-configuration-overview"><a class="header" href="#shadow-configuration-overview">Shadow Configuration Overview</a></h1>
<p>Shadow requires a configuration file that provides a network graph and
information about the processes to run during the simulation. This configuration
file uses the YAML format. The options and their effect on the simulation are
described in more detail (alongside a simple example configuration file) on <a href="shadow_config_spec.html">the
configuration options page</a>.</p>
<p>Many of the configuration file options can also be overridden using command-line
options. For example, the configuration option
<a href="shadow_config_spec.html#generalstop_time"><code>general.stop_time</code></a> can be
overridden with shadow's <code>--stop-time</code> option, and
<a href="shadow_config_spec.html#generallog_level"><code>general.log_level</code></a> can be
overridden with <code>--log-level</code>. See <code>shadow --help</code> for other command-line
options.</p>
<p>The configuration file does not perform any shell expansion, other than home
directory <code>~/</code> expansion on some specific options.</p>
<h2 id="quantities-with-units"><a class="header" href="#quantities-with-units">Quantities with Units</a></h2>
<p>Some options such as
<a href="shadow_config_spec.html#hostshostnamebandwidth_down"><code>hosts.&lt;hostname&gt;.bandwidth_down</code></a>
accept quantity values containing a magnitude and a unit. For example bandwidth
values can be expressed as <code>1 Mbit</code>, <code>1000 Kbit</code>, <code>977 Kibit</code>, etc. The space
between the magnitude and unit is optional (for example <code>5Mbit</code>), and the unit
can be pluralized (for example <code>5 Mbits</code>). Units are case-sensitive.</p>
<h3 id="time"><a class="header" href="#time">Time</a></h3>
<p>Time values are expressed as either sub-second units, seconds, minutes, or
hours.</p>
<p>Acceptable units are:</p>
<ul>
<li>nanosecond / ns</li>
<li>microsecond / us / μs</li>
<li>millisecond / ms</li>
<li>second / sec / s</li>
<li>minute / min / m</li>
<li>hour / hr / h</li>
</ul>
<p>Examples: <code>30 s</code>, <code>2 hr</code>, <code>10 minutes</code>, <code>100 ms</code></p>
<h3 id="bandwidth"><a class="header" href="#bandwidth">Bandwidth</a></h3>
<p>Bandwidth values are expressed in bits-per-second with the unit <code>bit</code>. All
bandwidth values should be divisible by 8 bits-per-second (for example <code>30 bit</code>
is invalid, but <code>30 Kbit</code> is valid).</p>
<p>Acceptable unit <em>prefixes</em> are:</p>
<ul>
<li>kilo / K</li>
<li>kibi / Ki</li>
<li>mega / M</li>
<li>mebi / Mi</li>
<li>giga / G</li>
<li>gibi / Gi</li>
<li>tera / T</li>
<li>tebi / Ti</li>
</ul>
<p>Examples: <code>100 Mbit</code>, <code>100 Mbits</code>, <code>10 kilobits</code>, <code>128 bits</code></p>
<h3 id="byte-sizes"><a class="header" href="#byte-sizes">Byte Sizes</a></h3>
<p>Byte size values are expressed with the unit <code>byte</code> or <code>B</code>.</p>
<p>Acceptable unit <em>prefixes</em> are:</p>
<ul>
<li>kilo / K</li>
<li>kibi / Ki</li>
<li>mega / M</li>
<li>mebi / Mi</li>
<li>giga / G</li>
<li>gibi / Gi</li>
<li>tera / T</li>
<li>tebi / Ti</li>
</ul>
<p>Examples: <code>20 B</code>, <code>100 MB</code>, <code>100 megabyte</code>, <code>10 kibibytes</code>, <code>30 MiB</code>, <code>1024 Mbytes</code></p>
<h2 id="unix-signals"><a class="header" href="#unix-signals">Unix Signals</a></h2>
<p>Several options allow the user to specify a Unix Signal. These can be specified
either as a string signal name (e.g. <code>SIGKILL</code>), or an integer signal number (e.g. <code>9</code>).
String signal names must be capitalized and include the <code>SIG</code> prefix.</p>
<p>Realtime signals (signal numbers 32+) are not supported.</p>
<h2 id="yaml-extensions"><a class="header" href="#yaml-extensions">YAML Extensions</a></h2>
<p>Shadow supports the extended YAML conventions for <a href="https://yaml.org/type/merge.html">merge
keys</a> and <a href="https://docs.docker.com/compose/compose-file/#extension">extension
fields</a>).</p>
<p>For examples, see <a href="./shadow_config_complex.html">Managing Complex Configurations</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="shadow-configuration-specification"><a class="header" href="#shadow-configuration-specification">Shadow Configuration Specification</a></h1>
<p>Shadow uses the standard <a href="https://yaml.org/spec/1.2.2/">YAML 1.2</a> format to
accept configuration options, with the following extensions:</p>
<ul>
<li><a href="https://yaml.org/type/merge.html">merge keys</a></li>
<li><a href="https://docs.docker.com/compose/compose-file/compose-file-v3/#extension-fields">extension fields</a></li>
</ul>
<p>The following describes Shadow's YAML format and all of the options that Shadow
supports that can be used to customize a simulation.</p>
<p>Example:</p>
<pre><code class="language-yaml">general:
  stop_time: 2 min
network:
  graph:
    type: gml
    inline: |
      graph [
        node [
          id 0
          host_bandwidth_down "140 Mbit"
          host_bandwidth_up "18 Mbit"
        ]
        edge [
          source 0
          target 0
          latency "50 ms"
          packet_loss 0.01
        ]
      ]
hosts:
  server:
    network_node_id: 0
    processes:
    - path: /usr/sbin/nginx
      args: -c ../../../nginx.conf -p .
      start_time: 1
      expected_final_state: running
  client1: &amp;client_host
    network_node_id: 0
    host_options:
      log_level: debug
    processes:
    - path: /usr/bin/curl
      args: server --silent
      start_time: 5
  client2: *client_host
  client3: *client_host
</code></pre>
<h2 id="contents"><a class="header" href="#contents">Contents:</a></h2>
<ul>
<li><a href="shadow_config_spec.html#general"><code>general</code></a></li>
<li><a href="shadow_config_spec.html#generalbootstrap_end_time"><code>general.bootstrap_end_time</code></a></li>
<li><a href="shadow_config_spec.html#generaldata_directory"><code>general.data_directory</code></a></li>
<li><a href="shadow_config_spec.html#generalheartbeat_interval"><code>general.heartbeat_interval</code></a></li>
<li><a href="shadow_config_spec.html#generallog_level"><code>general.log_level</code></a></li>
<li><a href="shadow_config_spec.html#generalmodel_unblocked_syscall_latency"><code>general.model_unblocked_syscall_latency</code></a></li>
<li><a href="shadow_config_spec.html#generalparallelism"><code>general.parallelism</code></a></li>
<li><a href="shadow_config_spec.html#generalprogress"><code>general.progress</code></a></li>
<li><a href="shadow_config_spec.html#generalseed"><code>general.seed</code></a></li>
<li><a href="shadow_config_spec.html#generalstop_time"><code>general.stop_time</code></a></li>
<li><a href="shadow_config_spec.html#generaltemplate_directory"><code>general.template_directory</code></a></li>
<li><a href="shadow_config_spec.html#network"><code>network</code></a></li>
<li><a href="shadow_config_spec.html#networkgraph"><code>network.graph</code></a></li>
<li><a href="shadow_config_spec.html#networkgraphtype"><code>network.graph.type</code></a></li>
<li><a href="shadow_config_spec.html#networkgraphfileinline"><code>network.graph.&lt;file|inline&gt;</code></a></li>
<li><a href="shadow_config_spec.html#networkgraphfilepath"><code>network.graph.file.path</code></a></li>
<li><a href="shadow_config_spec.html#networkgraphfilecompression"><code>network.graph.file.compression</code></a></li>
<li><a href="shadow_config_spec.html#networkuse_shortest_path"><code>network.use_shortest_path</code></a></li>
<li><a href="shadow_config_spec.html#experimental"><code>experimental</code></a></li>
<li><a href="shadow_config_spec.html#experimentalinterface_qdisc"><code>experimental.interface_qdisc</code></a></li>
<li><a href="shadow_config_spec.html#experimentalmax_unapplied_cpu_latency"><code>experimental.max_unapplied_cpu_latency</code></a></li>
<li><a href="shadow_config_spec.html#experimentalreport_errors_to_stderr"><code>experimental.report_errors_to_stderr</code></a></li>
<li><a href="shadow_config_spec.html#experimentalrunahead"><code>experimental.runahead</code></a></li>
<li><a href="shadow_config_spec.html#experimentalscheduler"><code>experimental.scheduler</code></a></li>
<li><a href="shadow_config_spec.html#experimentalsocket_recv_autotune"><code>experimental.socket_recv_autotune</code></a></li>
<li><a href="shadow_config_spec.html#experimentalsocket_recv_buffer"><code>experimental.socket_recv_buffer</code></a></li>
<li><a href="shadow_config_spec.html#experimentalsocket_send_autotune"><code>experimental.socket_send_autotune</code></a></li>
<li><a href="shadow_config_spec.html#experimentalsocket_send_buffer"><code>experimental.socket_send_buffer</code></a></li>
<li><a href="shadow_config_spec.html#experimentalstrace_logging_mode"><code>experimental.strace_logging_mode</code></a></li>
<li><a href="shadow_config_spec.html#experimentalunblocked_syscall_latency"><code>experimental.unblocked_syscall_latency</code></a></li>
<li><a href="shadow_config_spec.html#experimentalunblocked_vdso_latency"><code>experimental.unblocked_vdso_latency</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_cpu_pinning"><code>experimental.use_cpu_pinning</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_dynamic_runahead"><code>experimental.use_dynamic_runahead</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_memory_manager"><code>experimental.use_memory_manager</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_new_tcp"><code>experimental.use_new_tcp</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_object_counters"><code>experimental.use_object_counters</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_preload_libc"><code>experimental.use_preload_libc</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_preload_openssl_crypto"><code>experimental.use_preload_openssl_crypto</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_preload_openssl_rng"><code>experimental.use_preload_openssl_rng</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_sched_fifo"><code>experimental.use_sched_fifo</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_syscall_counters"><code>experimental.use_syscall_counters</code></a></li>
<li><a href="shadow_config_spec.html#experimentaluse_worker_spinning"><code>experimental.use_worker_spinning</code></a></li>
<li><a href="shadow_config_spec.html#host_option_defaults"><code>host_option_defaults</code></a></li>
<li><a href="shadow_config_spec.html#host_option_defaultslog_level"><code>host_option_defaults.log_level</code></a></li>
<li><a href="shadow_config_spec.html#host_option_defaultspcap_capture_size"><code>host_option_defaults.pcap_capture_size</code></a></li>
<li><a href="shadow_config_spec.html#host_option_defaultspcap_enabled"><code>host_option_defaults.pcap_enabled</code></a></li>
<li><a href="shadow_config_spec.html#hosts"><code>hosts</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnamebandwidth_down"><code>hosts.&lt;hostname&gt;.bandwidth_down</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnamebandwidth_up"><code>hosts.&lt;hostname&gt;.bandwidth_up</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameip_addr"><code>hosts.&lt;hostname&gt;.ip_addr</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnamenetwork_node_id"><code>hosts.&lt;hostname&gt;.network_node_id</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnamehost_options"><code>hosts.&lt;hostname&gt;.host_options</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocesses"><code>hosts.&lt;hostname&gt;.processes</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocessesargs"><code>hosts.&lt;hostname&gt;.processes[*].args</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocessesenvironment"><code>hosts.&lt;hostname&gt;.processes[*].environment</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocessesexpected_final_state"><code>hosts.&lt;hostname&gt;.processes[*].expected_final_state</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocessespath"><code>hosts.&lt;hostname&gt;.processes[*].path</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocessesshutdown_signal"><code>hosts.&lt;hostname&gt;.processes[*].shutdown_signal</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocessesshutdown_time"><code>hosts.&lt;hostname&gt;.processes[*].shutdown_time</code></a></li>
<li><a href="shadow_config_spec.html#hostshostnameprocessesstart_time"><code>hosts.&lt;hostname&gt;.processes[*].start_time</code></a></li>
</ul>
<h4 id="general"><a class="header" href="#general"><code>general</code></a></h4>
<p><em>Required</em></p>
<p>General experiment settings.</p>
<h4 id="generalbootstrap_end_time"><a class="header" href="#generalbootstrap_end_time"><code>general.bootstrap_end_time</code></a></h4>
<p>Default: "0 sec"<br />
Type: String OR Integer</p>
<p>The simulated time that ends Shadow's high network bandwidth/reliability
bootstrap period.</p>
<p>If the bootstrap end time is greater than 0, Shadow uses a simulation
bootstrapping period where hosts have unrestricted network bandwidth and no
packet drop. This can help to bootstrap large networks quickly when the network
hosts have low network bandwidth or low network reliability.</p>
<h4 id="generaldata_directory"><a class="header" href="#generaldata_directory"><code>general.data_directory</code></a></h4>
<p>Default: "shadow.data"<br />
Type: String</p>
<p>Path to store simulation output.</p>
<h4 id="generalheartbeat_interval"><a class="header" href="#generalheartbeat_interval"><code>general.heartbeat_interval</code></a></h4>
<p>Default: "1 sec"<br />
Type: String OR Integer OR null</p>
<p>Interval at which to print simulation heartbeat messages.</p>
<h4 id="generallog_level"><a class="header" href="#generallog_level"><code>general.log_level</code></a></h4>
<p>Default: "info"<br />
Type: "error" OR "warning" OR "info" OR "debug" OR "trace"</p>
<p>Log level of output written on stdout. If Shadow was built in release mode, then
messages at level 'trace' will always be dropped.</p>
<h4 id="generalmodel_unblocked_syscall_latency"><a class="header" href="#generalmodel_unblocked_syscall_latency"><code>general.model_unblocked_syscall_latency</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Whether to model syscalls and VDSO functions that don't block as having some
latency. This should have minimal effect on typical simulations, but can be
helpful for programs with "busy loops" that otherwise deadlock under Shadow.</p>
<h4 id="generalparallelism"><a class="header" href="#generalparallelism"><code>general.parallelism</code></a></h4>
<p>Default: 0<br />
Type: Integer</p>
<p>How many parallel threads to use to run the simulation. Optimal performance is usually obtained with
the number of <em>physical</em> CPU cores (<code>nproc</code> without hyperthreading or <code>nproc</code>/2 with
hyperthreading).</p>
<p>A value of 0 will allow Shadow to choose the number of threads, typically the number of physical CPU
cores available in the current CPU affinity mask and cgroup.</p>
<p>Virtual hosts depend on network packets that can potentially arrive from other
virtual hosts, so each worker can only advance according to the propagation
delay to avoid dependency violations. Therefore, not all threads will have 100%
CPU utilization.</p>
<h4 id="generalprogress"><a class="header" href="#generalprogress"><code>general.progress</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Show the simulation progress on stderr.</p>
<p>When running in a tty, the progress will be updated every second and shown at
the bottom of the terminal. Otherwise the progress will be printed without ANSI
escape codes at intervals which increase as the simulation progresses.</p>
<h4 id="generalseed"><a class="header" href="#generalseed"><code>general.seed</code></a></h4>
<p>Default: 1<br />
Type: Integer</p>
<p>Initialize randomness using seed N.</p>
<h4 id="generalstop_time"><a class="header" href="#generalstop_time"><code>general.stop_time</code></a></h4>
<p><em>Required</em><br />
Type: String OR Integer</p>
<p>The simulated time at which the simulation ends.</p>
<h4 id="generaltemplate_directory"><a class="header" href="#generaltemplate_directory"><code>general.template_directory</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>Path to recursively copy during startup and use as the data-directory.</p>
<h4 id="network"><a class="header" href="#network"><code>network</code></a></h4>
<p><em>Required</em></p>
<p>Network settings.</p>
<h4 id="networkgraph"><a class="header" href="#networkgraph"><code>network.graph</code></a></h4>
<p><em>Required</em></p>
<p>The network topology graph.</p>
<p>A network topology represented by a connected graph with certain attributes
specified on the network nodes and edges. For more information on how to
structure this data, see the <a href="network_graph_overview.html">Network Graph Overview</a>.</p>
<p>Example:</p>
<pre><code class="language-yaml">network:
  graph:
    type: gml
    inline: |
      graph [
        ...
      ]
</code></pre>
<h4 id="networkgraphtype"><a class="header" href="#networkgraphtype"><code>network.graph.type</code></a></h4>
<p><em>Required</em><br />
Type: "gml" OR "1_gbit_switch"</p>
<p>The network graph can be specified in the GML format, or a built-in
"1_gbit_switch" graph with a single network node can be used instead.</p>
<p>The built-in "1_gbit_switch" graph contains the following:</p>
<pre><code class="language-text">graph [
  directed 0
  node [
    id 0
    host_bandwidth_up "1 Gbit"
    host_bandwidth_down "1 Gbit"
  ]
  edge [
    source 0
    target 0
    latency "1 ms"
    packet_loss 0.0
  ]
]
</code></pre>
<h4 id="networkgraphfileinline"><a class="header" href="#networkgraphfileinline"><code>network.graph.&lt;file|inline&gt;</code></a></h4>
<p><em>Required if <code>network.graph.type</code> is "gml"</em><br />
Type: Object OR String</p>
<p>If the network graph type is not a built-in network graph, the graph data can be
specified as a path to an external file, or as an inline string.</p>
<h4 id="networkgraphfilepath"><a class="header" href="#networkgraphfilepath"><code>network.graph.file.path</code></a></h4>
<p><em>Required</em><br />
Type: String</p>
<p>The path to the file.</p>
<p>If the path begins with <code>~/</code>, it will be considered relative to the current
user's home directory. No other shell expansion is performed on the path.</p>
<h4 id="networkgraphfilecompression"><a class="header" href="#networkgraphfilecompression"><code>network.graph.file.compression</code></a></h4>
<p>Default: null<br />
Type: "xz" OR null</p>
<p>The file's compression format.</p>
<h4 id="networkuse_shortest_path"><a class="header" href="#networkuse_shortest_path"><code>network.use_shortest_path</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>When routing packets, follow the shortest path rather than following a direct
edge between network nodes. If false, the network graph is required to be
complete (including self-loops) and to have exactly one edge between any two
nodes.</p>
<h4 id="experimental"><a class="header" href="#experimental"><code>experimental</code></a></h4>
<p>Experimental experiment settings. Unstable and may change or be removed at any
time, regardless of Shadow version.</p>
<h4 id="experimentalinterface_qdisc"><a class="header" href="#experimentalinterface_qdisc"><code>experimental.interface_qdisc</code></a></h4>
<p>Default: "fifo"<br />
Type: "fifo" OR "round-robin"</p>
<p>The queueing discipline to use at the network interface.</p>
<h4 id="experimentalmax_unapplied_cpu_latency"><a class="header" href="#experimentalmax_unapplied_cpu_latency"><code>experimental.max_unapplied_cpu_latency</code></a></h4>
<p>Default: "1 microsecond"<br />
Type: String</p>
<p>Max amount of execution-time latency allowed to accumulate before the clock is
moved forward. Moving the clock forward is a potentially expensive operation, so
larger values reduce simulation overhead, at the cost of coarser time jumps.</p>
<p>Note also that accumulated-but-unapplied latency is discarded when a thread is
blocked on a syscall.</p>
<p>Ignored when
<a href="shadow_config_spec.html#generalmodel_unblocked_syscall_latency"><code>general.model_unblocked_syscall_latency</code></a>
is false.</p>
<h4 id="experimentalreport_errors_to_stderr"><a class="header" href="#experimentalreport_errors_to_stderr"><code>experimental.report_errors_to_stderr</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Report <code>Error</code>-level log messages to shadow's <code>stderr</code> in addition to logging
them to <code>stdout</code>.</p>
<h4 id="experimentalrunahead"><a class="header" href="#experimentalrunahead"><code>experimental.runahead</code></a></h4>
<p>Default: "1 ms"<br />
Type: String OR null</p>
<p>If set, overrides the automatically calculated minimum time workers may run
ahead when sending events between virtual hosts.</p>
<h4 id="experimentalscheduler"><a class="header" href="#experimentalscheduler"><code>experimental.scheduler</code></a></h4>
<p>Default: "thread-per-core"<br />
Type: "thread-per-core" OR "thread-per-host"</p>
<p>The host scheduler implementation, which decides how to assign hosts to threads
and threads to CPU cores.</p>
<h4 id="experimentalsocket_recv_autotune"><a class="header" href="#experimentalsocket_recv_autotune"><code>experimental.socket_recv_autotune</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Enable receive window autotuning.</p>
<h4 id="experimentalsocket_recv_buffer"><a class="header" href="#experimentalsocket_recv_buffer"><code>experimental.socket_recv_buffer</code></a></h4>
<p>Default: "174760 B"<br />
Type: String OR Integer</p>
<p>Initial size of the socket's receive buffer.</p>
<h4 id="experimentalsocket_send_autotune"><a class="header" href="#experimentalsocket_send_autotune"><code>experimental.socket_send_autotune</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Enable send window autotuning.</p>
<h4 id="experimentalsocket_send_buffer"><a class="header" href="#experimentalsocket_send_buffer"><code>experimental.socket_send_buffer</code></a></h4>
<p>Default: "131072 B"<br />
Type: String OR Integer</p>
<p>Initial size of the socket's send buffer.</p>
<h4 id="experimentalstrace_logging_mode"><a class="header" href="#experimentalstrace_logging_mode"><code>experimental.strace_logging_mode</code></a></h4>
<p>Default: "off"<br />
Type: "off" OR "standard" OR "deterministic"</p>
<p>Log the syscalls for each process to individual "strace" files.</p>
<p>The mode determines the format that the syscalls are logged in. For example,
the "deterministic" mode will avoid logging memory addresses or potentially
uninitialized memory.</p>
<p>The logs will be stored at
<code>shadow.data/hosts/&lt;hostname&gt;/&lt;procname&gt;.&lt;pid&gt;.strace</code>.</p>
<p>Limitations:</p>
<ul>
<li>Syscalls run natively will not log the syscall arguments or return value (for
example <code>SYS_getcwd</code>).</li>
<li>Syscalls processed within Shadow's C code will not log the syscall arguments.</li>
<li>Syscalls that are interrupted by a signal may not be logged (for example
<code>SYS_read</code>).</li>
<li>Syscalls that are interrupted by a signal may be logged inaccurately. For
example, the log may show <code>syscall(...) = -1 (EINTR)</code>, but the managed
process may not actually see this return value. Instead the syscall may be
restarted.</li>
</ul>
<h4 id="experimentalunblocked_syscall_latency"><a class="header" href="#experimentalunblocked_syscall_latency"><code>experimental.unblocked_syscall_latency</code></a></h4>
<p>Default: "1 microseconds"<br />
Type: String</p>
<p>The simulated latency of an unblocked syscall. For simulation efficiency, this
latency is only added when <code>max_unapplied_cpu_latency</code> is reached.</p>
<p>Ignored when
<a href="shadow_config_spec.html#generalmodel_unblocked_syscall_latency"><code>general.model_unblocked_syscall_latency</code></a>
is false.</p>
<h4 id="experimentalunblocked_vdso_latency"><a class="header" href="#experimentalunblocked_vdso_latency"><code>experimental.unblocked_vdso_latency</code></a></h4>
<p>Default: "10 nanoseconds"<br />
Type: String</p>
<p>The simulated latency of an unblocked vdso function. For simulation efficiency, this
latency is only added when <code>max_unapplied_cpu_latency</code> is reached.</p>
<p>Ignored when
<a href="shadow_config_spec.html#generalmodel_unblocked_syscall_latency"><code>general.model_unblocked_syscall_latency</code></a>
is false.</p>
<h4 id="experimentaluse_cpu_pinning"><a class="header" href="#experimentaluse_cpu_pinning"><code>experimental.use_cpu_pinning</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Pin each thread and any processes it executes to the same logical CPU Core to
improve cache affinity.</p>
<h4 id="experimentaluse_dynamic_runahead"><a class="header" href="#experimentaluse_dynamic_runahead"><code>experimental.use_dynamic_runahead</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Update the minimum runahead dynamically throughout the simulation.</p>
<h4 id="experimentaluse_memory_manager"><a class="header" href="#experimentaluse_memory_manager"><code>experimental.use_memory_manager</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Use the MemoryManager in memory-mapping mode. This can improve
performance, but disables support for dynamically spawning processes
inside the simulation (e.g. the <code>fork</code> syscall).</p>
<h4 id="experimentaluse_new_tcp"><a class="header" href="#experimentaluse_new_tcp"><code>experimental.use_new_tcp</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Use the rust TCP implementation.</p>
<h4 id="experimentaluse_object_counters"><a class="header" href="#experimentaluse_object_counters"><code>experimental.use_object_counters</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Count object allocations and deallocations. If disabled, we will not be able to
detect object memory leaks.</p>
<h4 id="experimentaluse_preload_libc"><a class="header" href="#experimentaluse_preload_libc"><code>experimental.use_preload_libc</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Preload our libc library for all managed processes for fast syscall
interposition when possible.</p>
<h4 id="experimentaluse_preload_openssl_crypto"><a class="header" href="#experimentaluse_preload_openssl_crypto"><code>experimental.use_preload_openssl_crypto</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Preload our OpenSSL crypto library for all managed processes to skip some AES
crypto operations, which may speed up simulation if your CPU lacks AES-NI
support. However, it changes the behavior of your application and can cause bugs
in OpenSSL that are hard to notice. You should probably not use this option
unless you really know what you're doing.</p>
<h4 id="experimentaluse_preload_openssl_rng"><a class="header" href="#experimentaluse_preload_openssl_rng"><code>experimental.use_preload_openssl_rng</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Preload our OpenSSL RNG library for all managed processes to mitigate
non-deterministic use of OpenSSL.</p>
<h4 id="experimentaluse_sched_fifo"><a class="header" href="#experimentaluse_sched_fifo"><code>experimental.use_sched_fifo</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Use the <code>SCHED_FIFO</code> scheduler. Requires <code>CAP_SYS_NICE</code>. See sched(7),
capabilities(7).</p>
<h4 id="experimentaluse_syscall_counters"><a class="header" href="#experimentaluse_syscall_counters"><code>experimental.use_syscall_counters</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Count the number of occurrences for individual syscalls.</p>
<h4 id="experimentaluse_worker_spinning"><a class="header" href="#experimentaluse_worker_spinning"><code>experimental.use_worker_spinning</code></a></h4>
<p>Default: true<br />
Type: Bool</p>
<p>Each worker thread will spin in a <code>sched_yield</code> loop while waiting for a new task. This is ignored
if not using the thread-per-core scheduler.</p>
<p>This may improve runtime performance in some environments.</p>
<h4 id="host_option_defaults"><a class="header" href="#host_option_defaults"><code>host_option_defaults</code></a></h4>
<p>Default options for all hosts. These options can also be overridden for each
host individually in the host's <a href="shadow_config_spec.html#hostshostnamehost_options"><code>hosts.&lt;hostname&gt;.host_options</code></a>
section.</p>
<h4 id="host_option_defaultslog_level"><a class="header" href="#host_option_defaultslog_level"><code>host_option_defaults.log_level</code></a></h4>
<p>Default: null<br />
Type: "error" OR "warning" OR "info" OR "debug" OR "trace" OR null</p>
<p>Log level at which to print host log messages.</p>
<h4 id="host_option_defaultspcap_capture_size"><a class="header" href="#host_option_defaultspcap_capture_size"><code>host_option_defaults.pcap_capture_size</code></a></h4>
<p>Default: "65535 B"<br />
Type: String OR Integer</p>
<p>How much data to capture per packet (header and payload) if pcap logging is
enabled.</p>
<p>The default of 65535 bytes is the maximum length of an IP packet.</p>
<h4 id="host_option_defaultspcap_enabled"><a class="header" href="#host_option_defaultspcap_enabled"><code>host_option_defaults.pcap_enabled</code></a></h4>
<p>Default: false<br />
Type: Bool</p>
<p>Should Shadow generate pcap files?</p>
<p>Logs all network input and output for this host in PCAP format (for viewing in
e.g. wireshark). The pcap files will be stored in the host's data directory,
for example <code>shadow.data/hosts/myhost/eth0.pcap</code>.</p>
<h4 id="hosts"><a class="header" href="#hosts"><code>hosts</code></a></h4>
<p><em>Required</em><br />
Type: Object</p>
<p>The simulated hosts which execute processes. Each field corresponds to a host
configuration, with the field name being used as the network hostname. A
hostname must follow the character requirements of
<a href="https://man7.org/linux/man-pages/man7/hostname.7.html">hostname(7)</a>.</p>
<p>Shadow assigns each host to a network node in the <a href="network_graph_overview.html">network graph</a>.</p>
<p>In Shadow, each host is given an RNG whose seed is derived from the global seed
(<a href="shadow_config_spec.html#generalseed"><code>general.seed</code></a>) and the hostname. This means that changing a
host's name will change that host's RNG seed, subtly affecting the simulation
results.</p>
<h4 id="hostshostnamebandwidth_down"><a class="header" href="#hostshostnamebandwidth_down"><code>hosts.&lt;hostname&gt;.bandwidth_down</code></a></h4>
<p>Default: null<br />
Type: String OR Integer OR null</p>
<p>Downstream bandwidth capacity of the host.</p>
<p>Overrides any default bandwidth values set in the assigned network graph
node.</p>
<h4 id="hostshostnamebandwidth_up"><a class="header" href="#hostshostnamebandwidth_up"><code>hosts.&lt;hostname&gt;.bandwidth_up</code></a></h4>
<p>Default: null<br />
Type: String OR Integer OR null</p>
<p>Upstream bandwidth capacity of the host.</p>
<p>Overrides any default bandwidth values set in the assigned network graph
node.</p>
<h4 id="hostshostnameip_addr"><a class="header" href="#hostshostnameip_addr"><code>hosts.&lt;hostname&gt;.ip_addr</code></a></h4>
<p>Default: null<br />
Type: String OR null</p>
<p>IP address to assign to the host.</p>
<p>This IP address must not conflict with the address of any other host (two hosts
must not have the same IP address).</p>
<h4 id="hostshostnamenetwork_node_id"><a class="header" href="#hostshostnamenetwork_node_id"><code>hosts.&lt;hostname&gt;.network_node_id</code></a></h4>
<p><em>Required</em><br />
Type: Integer</p>
<p>Network graph node ID to assign the host to.</p>
<h4 id="hostshostnamehost_options"><a class="header" href="#hostshostnamehost_options"><code>hosts.&lt;hostname&gt;.host_options</code></a></h4>
<p>See <a href="shadow_config_spec.html#host_option_defaults"><code>host_option_defaults</code></a> for supported fields.</p>
<p>Example:</p>
<pre><code class="language-yaml">hosts:
  client:
    ...
    host_options:
      log_level: debug
</code></pre>
<h4 id="hostshostnameprocesses"><a class="header" href="#hostshostnameprocesses"><code>hosts.&lt;hostname&gt;.processes</code></a></h4>
<p><em>Required</em><br />
Type: Array</p>
<p>Virtual software processes that the host will run.</p>
<h4 id="hostshostnameprocessesargs"><a class="header" href="#hostshostnameprocessesargs"><code>hosts.&lt;hostname&gt;.processes[*].args</code></a></h4>
<p>Default: ""<br />
Type: String OR Array of String</p>
<p>Process arguments.</p>
<p>The arguments can be specified as a string in a shell command-line format:</p>
<pre><code class="language-yaml">args: "--user-agent 'Mozilla/5.0 (compatible; ...)' http://myserver:8080"
</code></pre>
<p>Or as an array of strings:</p>
<pre><code class="language-yaml">args: ['--user-agent', 'Mozilla/5.0 (compatible; ...)', 'http://myserver:8080']
</code></pre>
<p>Shell expansion (which includes <code>~/</code> expansion) is not performed on either
format. In the command-line format, the string is parsed as an argument vector
following typical shell quotation parsing rules.</p>
<h4 id="hostshostnameprocessesenvironment"><a class="header" href="#hostshostnameprocessesenvironment"><code>hosts.&lt;hostname&gt;.processes[*].environment</code></a></h4>
<p>Default: ""<br />
Type: Object</p>
<p>Environment variables passed when executing this process.</p>
<p>Shell expansion (which includes <code>~/</code> expansion) is not performed on any fields.</p>
<p>Examples:</p>
<pre><code class="language-yaml">environment:
  ENV_A: "1"
  ENV_B: foo
</code></pre>
<pre><code class="language-yaml">environment: { ENV_A: "1", ENV_B: foo }
</code></pre>
<h4 id="hostshostnameprocessesexpected_final_state"><a class="header" href="#hostshostnameprocessesexpected_final_state"><code>hosts.&lt;hostname&gt;.processes[*].expected_final_state</code></a></h4>
<p>Default: {exited: 0}<br />
Type: {"exited": &lt;Integer&gt;} OR {"signaled": <a href="./shadow_config_overview.html#unix-signals">Unix Signal</a>} OR "running"</p>
<p>The expected state of the process at the end of the simulation. If the process
exits before the end of the simulation with an unexpected state, or is still running
at the end of the simulation when this was not <code>running</code>, shadow will log an error
and return a non-zero status for the simulation.</p>
<p>Use <code>exited</code> to indicate that a process should have exited normally; e.g. by returning
from <code>main</code> or calling <code>exit</code>.</p>
<p>Use <code>signaled</code> to indicate that a process should have been killed by a signal.</p>
<p>Use <code>running</code> for a process expected to still be running at the end of the simulation,
such as a server process that you didn't arrange to shutdown before the end of the simulation.
(All processes will be killed by Shadow when the simulation ends).</p>
<p>Examples:</p>
<ul>
<li><code>{exited: 0}</code></li>
<li><code>{exited: 1}</code></li>
<li><code>{signaled: SIGINT}</code></li>
<li><code>{signaled: 9}</code></li>
<li><code>running</code></li>
</ul>
<p>Only processes started directly from the configuration have an
<code>expected_final_state</code>. Processes that <em>those</em> processes start (e.g. via <code>fork</code>
in C, or running an executable in a shell script) don't have one. Generally it's
the parent process's responsibility to do any necessary validation of the exit
status of its children (e.g. via <code>waitpid</code> in C, or checking <code>$?</code> in a bash
script).</p>
<h4 id="hostshostnameprocessespath"><a class="header" href="#hostshostnameprocessespath"><code>hosts.&lt;hostname&gt;.processes[*].path</code></a></h4>
<p><em>Required</em><br />
Type: String</p>
<p>If the path begins with <code>~/</code>, it will be considered relative to the current
user's home directory. No other shell expansion is performed on the path.</p>
<p>Bare file basenames like <code>sleep</code> will be located using Shadow's <code>PATH</code>
environment variable (e.g. to <code>/usr/bin/sleep</code>).</p>
<h4 id="hostshostnameprocessesshutdown_signal"><a class="header" href="#hostshostnameprocessesshutdown_signal"><code>hosts.&lt;hostname&gt;.processes[*].shutdown_signal</code></a></h4>
<p>Default: "SIGTERM"<br />
Type: <a href="./shadow_config_overview.html#unix-signals">Unix Signal</a></p>
<p>The signal that will be sent to the process at
<a href="shadow_config_spec.html#hostshostnameprocessesshutdown_time"><code>hosts.&lt;hostname&gt;.processes[*].shutdown_time</code></a>.
Signals specified by name should be all-caps and include the SIG prefix; e.g.
"SIGTERM".</p>
<p>Many long-running processes support exiting cleanly when sent <code>SIGTERM</code> or
<code>SIGINT</code>.</p>
<p>If the process is expected to be killed directly by the signal instead of
catching it and exiting cleanly, you can set
<a href="shadow_config_spec.html#hostshostnameprocessesexpected_final_state"><code>expected_final_state</code></a> to prevent
Shadow from interpreting this as an error. e.g. <code>SIGKILL</code> cannot be caught, so
will always result in an end state of <code>{signaled: SIGKILL}</code> if the process didn't
already exit before the signal was sent.</p>
<pre><code class="language-yaml">path: sleep
args: "1000"
start_time: 1s
shutdown_time: 2s
shutdown_signal: SIGKILL
expected_final_state: {signaled: SIGKILL}
</code></pre>
<h4 id="hostshostnameprocessesshutdown_time"><a class="header" href="#hostshostnameprocessesshutdown_time"><code>hosts.&lt;hostname&gt;.processes[*].shutdown_time</code></a></h4>
<p>Default: null<br />
Type: String OR Integer OR null</p>
<p>The simulated time at which to send
<a href="shadow_config_spec.html#hostshostnameprocessesshutdown_signal"><code>hosts.&lt;hostname&gt;.processes[*].shutdown_signal</code></a>
to the process. This must be before <a href="shadow_config_spec.html#generalstop_time"><code>general.stop_time</code></a>.</p>
<h4 id="hostshostnameprocessesstart_time"><a class="header" href="#hostshostnameprocessesstart_time"><code>hosts.&lt;hostname&gt;.processes[*].start_time</code></a></h4>
<p>Default: "0 sec"<br />
Type: String OR Integer</p>
<p>The simulated time at which to execute the process. This must be before
<a href="shadow_config_spec.html#generalstop_time"><code>general.stop_time</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="managing-complex-configurations"><a class="header" href="#managing-complex-configurations">Managing Complex Configurations</a></h1>
<p>It is sometimes useful to generate shadow configuration files dynamically.
Since Shadow accepts configuration files in <a href="https://yaml.org/spec/1.2.2/">YAML
1.2</a> format, there are many options
available; even more so since <a href="https://en.wikipedia.org/wiki/JSON">JSON</a> is
also valid YAML 1.2.</p>
<h2 id="yaml-templating"><a class="header" href="#yaml-templating">YAML templating</a></h2>
<p>YAML itself has some features to help avoid repetition. When using these
features, it can be helpful to use shadow's <code>--show-config</code> flag to examine the
"flat" generated config.</p>
<p>An individual node can be made into an <em>anchor</em> (<code>&amp;AnchorName x</code>), and
referenced via an <em>alias</em> (<code>*AnchorName</code>). For example, here we create
and use the anchors <code>Node</code>, <code>Fast</code>, <code>Slow</code>, <code>ClientPath</code>, and <code>ServerPath</code>:</p>
<pre><code class="language-yaml">general:
  stop_time: 10s
network:
  graph:
    type: 1_gbit_switch
hosts:
  fast_client:
    network_node_id: &amp;Node 0
    bandwidth_up: &amp;Fast "100 Mbit"
    bandwidth_down: *Fast
    processes:
    - path: &amp;ClientPath "/path/to/client"
    # ...
  slow_client:
    network_node_id: *Node
    bandwidth_up: &amp;Slow "1 Mbit"
    bandwidth_down: *Slow
    processes:
    - path: *ClientPath
    # ...
  fast_server:
    network_node_id: *Node
    bandwidth_up: *Fast
    bandwidth_down: *Fast
    processes:
    - path: &amp;ServerPath "/path/to/server"
    # ...
  slow_server:
    network_node_id: *Node
    bandwidth_up: *Slow
    bandwidth_down: *Slow
    processes:
    - path: *ServerPath
</code></pre>
<p>We can use <a href="https://docs.docker.com/compose/compose-file/#extension">extension
fields</a> to move our
constants into one place:</p>
<pre><code class="language-yaml">x-constants:
  - &amp;Node 0
  - &amp;Fast "100 Mbit"
  - &amp;Slow "1 Mbit"
  - &amp;ClientPath "/path/to/client"
  - &amp;ServerPath "/path/to/server"
general:
  stop_time: 10s
network:
  graph:
    type: 1_gbit_switch
hosts:
  fast_client:
    network_node_id: *Node
    bandwidth_up: *Fast
    bandwidth_down: *Fast
    processes:
    - path: *ClientPath
  slow_client:
    network_node_id: *Node
    bandwidth_up: *Slow
    bandwidth_down: *Slow
    processes:
    - path: *ClientPath
  fast_server:
    network_node_id: *Node
    bandwidth_up: *Fast
    bandwidth_down: *Fast
    processes:
    - path: *ServerPath
  slow_server:
    network_node_id: *Node
    bandwidth_up: *Slow
    bandwidth_down: *Slow
    processes:
    - path: *ServerPath
</code></pre>
<p>We can also use <a href="https://yaml.org/type/merge.html">merge keys</a> to make
extendable templates for fast and slow hosts:</p>
<pre><code class="language-yaml">x-constants:
  - &amp;Node 0
  - &amp;Fast "100 Mbit"
  - &amp;Slow "1 Mbit"
  - &amp;ClientPath "/path/to/client"
  - &amp;ServerPath "/path/to/server"
  - &amp;FastHost
    network_node_id: *Node
    bandwidth_up: *Fast
    bandwidth_down: *Fast
  - &amp;SlowHost
    network_node_id: *Node
    bandwidth_up: *Slow
    bandwidth_down: *Slow
general:
  stop_time: 10s
network:
  graph:
    type: 1_gbit_switch
hosts:
  fast_client:
    &lt;&lt;: *FastHost
    processes:
    - path: *ClientPath
  slow_client:
    &lt;&lt;: *SlowHost
    processes:
    - path: *ClientPath
  fast_server:
    &lt;&lt;: *FastHost
    processes:
    - path: *ServerPath
  slow_server:
    &lt;&lt;: *SlowHost
    processes:
    - path: *ServerPath
</code></pre>
<h2 id="dynamic-generation"><a class="header" href="#dynamic-generation">Dynamic Generation</a></h2>
<p>There are many tools and libraries for generating YAML and JSON. These can be helpful for
representing more complex relationships between parameter values.</p>
<p>Suppose we want to add a cleanup process to each host that runs one second
before the simulation ends. Since YAML doesn't support arithmetic, the
following <em>doesn't</em> work:</p>
<pre><code class="language-yaml">x-constants:
  - &amp;StopTimeSec 10
  - &amp;CleanupProcess
    # This will evaluate to the invalid time string "10 - 1"; not "9"
    start_time: *StopTimeSec - 1
    ...
# ...
</code></pre>
<p>In such cases it may be helpful to write your configuration in a language that does support
more advanced features that can generate YAML or JSON.</p>
<h3 id="python-example"><a class="header" href="#python-example">Python example</a></h3>
<p>We can achieve the desired effect in Python like so:</p>
<pre><code class="language-python">#!/usr/bin/env python3

Node = 0
StopTimeSec = 10
Fast = "100 Mbit"
Slow = "1 Mbit"
ClientPath = "/path/to/client"
ServerPath = "/path/to/server"
FastHost = {
  'network_node_id': Node,
  'bandwidth_up': Fast,
  'bandwidth_down': Fast,
}
SlowHost = {
  'network_node_id': Node,
  'bandwidth_up': Slow,
  'bandwidth_down': Slow,
}
CleanupProcess = {
  'start_time': f'{StopTimeSec - 1}s',
  'path': '/path/to/cleanup',
}
config = {
  'general': {
    'stop_time': '10s',
  },
  'network': {
    'graph': {
      'type': '1_gbit_switch'
    },
  },
  'hosts': {
    'fast_client': {
      **FastHost,
      'processes': [
        {'path': ClientPath},
        CleanupProcess,
      ],
    },
    'slow_client': {
      **SlowHost,
      'processes': [
        {'path': ClientPath},
        CleanupProcess,
      ],
    },
    'fast_server': {
      **FastHost,
      'processes': [
        {'path': ServerPath},
        CleanupProcess,
      ],
    },
    'slow_server': {
      **SlowHost,
      'processes': [
        {'path': ServerPath},
        CleanupProcess,
      ],
    },
  },
}

import yaml
print(yaml.safe_dump(config))
</code></pre>
<h3 id="nix-example"><a class="header" href="#nix-example">Nix example</a></h3>
<p>There are also languages that specialize in doing this kind of advanced configuration generation.
For example, using <a href="https://nixos.org/manual/nix/stable/language/index.html">NixOs's config language</a>:</p>
<pre><code class="language-nix">let
  Node = 0;
  StopTimeSec = 10;
  Fast = "100 Mbit";
  Slow = "1 Mbit";
  ClientPath = "/path/to/client";
  ServerPath = "/path/to/server";
  FastHost = {
    network_node_id = Node;
    bandwidth_up = Fast;
    bandwidth_down = Fast;
  };
  SlowHost = {
    network_node_id = Node;
    bandwidth_up = Slow;
    bandwidth_down = Slow;
  };
  CleanupProcess = {
    start_time = (toString (StopTimeSec - 1)) + "s";
    path = "/path/to/cleanup";
  };
in
{
  general = {
    stop_time = (toString StopTimeSec) + "s";
  };
  network = {
    graph = {
      type = "1_gbit_switch";
    };
  };
  hosts = {
    fast_client = FastHost // {
      processes = [
        {path = ClientPath;}
        CleanupProcess
      ];
    };
    slow_client = SlowHost // {
      processes = [
        {path = ClientPath;}
        CleanupProcess
      ];
    };
    fast_server = FastHost // {
      processes = [
        {path = ServerPath;}
        CleanupProcess
      ];
    };
    slow_server = SlowHost // {
      processes = [
        {path = ServerPath;}
        CleanupProcess
      ];
    };
  };
}
</code></pre>
<p>This can be converted to JSON, which is also valid YAML, with:</p>
<pre><code>nix eval -f example.nix --json
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="network-graph-overview"><a class="header" href="#network-graph-overview">Network Graph Overview</a></h1>
<p>Processes running in Shadow do not have access to the internet; instead,
processes running on Shadow virtual hosts utilize an internal routing module to
communicate with other processes running on other virtual hosts in the
simulation. The routing module is used to position virtual hosts within a
network topology, to compute communication paths between virtual hosts, and to
enforce network path characteristics like latency and packet loss.</p>
<p>Importantly, the routing module is currently used to <em>model</em> the performance
characteristics of internet paths; we do not <em>simulate</em> the behavior of network
routers (we do not run routing protocols like
<a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol">BGP</a>).</p>
<p>This page describes the routing module and how it can be configured.</p>
<h2 id="graph"><a class="header" href="#graph">Graph</a></h2>
<p>Shadow represents a network topology over which processes can communicate using
a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">weighted graph</a>.
The graph contains <em>vertices</em> that abstractly represent network locations, and
<em>edges</em> representing network paths between those locations.</p>
<p>When referring to a network graph, the terms <em>vertices</em> and <em>nodes</em> are
interchangeable. In our documentation, we refer to these as <em>nodes</em>. Note that
nodes in the network graph are distinct from virtual hosts in the Shadow config
file: a virtual host models an end-host machine, whereas a network node
represents a location at which a host can connect to the simulated network.</p>
<p>Shadow requires that the network graph is
<a href="https://en.wikipedia.org/wiki/Connectivity_(graph_theory)">connected</a> such that
there exists at least one <em>path</em> (a series of one or more edges) between every
pair of nodes.</p>
<h2 id="behavior"><a class="header" href="#behavior">Behavior</a></h2>
<p>The graph encodes network positioning and path characteristics as attributes on
the nodes and edges. Shadow uses the connectivity graph along with the
information encoded in node and edge attributes to:</p>
<ul>
<li>attach virtual hosts to specific nodes (i.e., locations) in the network
graph;</li>
<li>assign the bandwidth allowed for each attached virtual host;</li>
<li>compute the shortest path (weighted by edge <code>latency</code>) between two virtual
hosts using <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">Dijkstra's
algorithm</a>; and</li>
<li>compute the end-to-end latency and packet loss for the shortest path.</li>
</ul>
<p>The bandwidth of the virtual hosts and the end-to-end latency and packet loss
for a shortest path between two virtual hosts are then enforced for all network
communication.</p>
<h2 id="important-notes"><a class="header" href="#important-notes">Important Notes</a></h2>
<ul>
<li>The network graph may be directed or undirected, as long as the graph is
structured such that every node can reach every other node through a
series of edges.</li>
<li>If the network graph is a <a href="https://en.wikipedia.org/wiki/Complete_graph">complete
graph</a> (there exists a single
unique edge between every pair of nodes), then we can avoid running the
shortest path algorithm as a performance optimization by setting the
<a href="shadow_config_spec.html#networkuse_shortest_path">use_shortest_path
option</a> to <code>False</code>.</li>
<li>Each node in the graph must have a self-loop (an edge from the node to
itself). This edge will be used for communication between two hosts
attached to the same node, regardless of if a shorter path exists.</li>
</ul>
<h2 id="network-graph-attributes"><a class="header" href="#network-graph-attributes">Network Graph Attributes</a></h2>
<p>We encode attributes on the nodes and edges that allow for configuring the
simulated network characteristics. The attributes and their effect on the
simulated network are described in more detail (alongside a simple example
graph) on <a href="network_graph_spec.html">the network graph specification page</a>.</p>
<h2 id="using-an-existing-graph"><a class="header" href="#using-an-existing-graph">Using an Existing Graph</a></h2>
<p>We created a large network graph representing worldwide latencies and
bandwidths as of 2018 using the <a href="https://atlas.ripe.net">RIPE Atlas measurement platform</a>.  The
graph contains network bandwidths and latencies in and between major cities
around the world, and is suitable for general usage for most types of Shadow
simualtions. The graph (updated for Shadow version 2.x) is <a href="https://tmodel-ccs2018.github.io/data/shadow/network/atlas_v201801.shadow_v2.gml.xz">available for
download as a research artifact</a> and more details about the
measurement methodology is available on <a href="https://tmodel-ccs2018.github.io">the research artifacts site</a>.</p>
<p>Note: <a href="https://github.com/shadow/atlas">the scripts we used to create the graph</a> are also
available, but are not recommended for general use. The scripts require
advanced knowledge of RIPE Atlas and also require that you possess RIPE Atlas
credits to conduct the measurements needed to create a new graph. We recommend
using our existing graph linked above instead, which we may periodically
update.</p>
<h2 id="creating-your-own-graph"><a class="header" href="#creating-your-own-graph">Creating Your Own Graph</a></h2>
<p>The python module <a href="https://networkx.github.io/">networkx</a> can be used to create
and manipulate more complicated graphs.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="network-graph-specification"><a class="header" href="#network-graph-specification">Network Graph Specification</a></h1>
<p>The <a href="network_graph_overview.html">network graph overview</a> provides a general
summary of Shadow's use of a network graph to abstractly model network position
and to connect virtual hosts in a network topology while enforcing network
characteristics on paths between hosts. This page describes the specific
attributes that can be configured in the network graph, and the effect that each
attribute has on the simulation.</p>
<h3 id="example-graph"><a class="header" href="#example-graph">Example Graph</a></h3>
<p>Below is an example of a simple network graph in the Shadow-supported GML format
(note that GML calls graph <em>vertices</em> as <em>nodes</em>, but these terms are generally
interchangeable).</p>
<pre><code class="language-gml">graph [
  directed 0
  node [
    id 0
    label "node at 1.2.3.4"
    host_bandwidth_down "100 Mbit"
    host_bandwidth_up "100 Mbit"
  ]
  edge [
    source 0
    target 0
    label "path from 1.2.3.4 to 1.2.3.4"
    latency "10 ms"
    jitter "0 ms"
    packet_loss 0.0
  ]
]
</code></pre>
<h3 id="configurable-attributes"><a class="header" href="#configurable-attributes">Configurable Attributes</a></h3>
<ul>
<li><a href="network_graph_spec.html#graphdirected"><code>graph.directed</code></a></li>
<li><a href="network_graph_spec.html#nodeid"><code>node.id</code></a></li>
<li><a href="network_graph_spec.html#nodelabel"><code>node.label</code></a></li>
<li><a href="network_graph_spec.html#nodehost_bandwidth_down"><code>node.host_bandwidth_down</code></a></li>
<li><a href="network_graph_spec.html#nodehost_bandwidth_up"><code>node.host_bandwidth_up</code></a></li>
<li><a href="network_graph_spec.html#edgesource"><code>edge.source</code></a></li>
<li><a href="network_graph_spec.html#edgetarget"><code>edge.target</code></a></li>
<li><a href="network_graph_spec.html#edgelabel"><code>edge.label</code></a></li>
<li><a href="network_graph_spec.html#edgelatency"><code>edge.latency</code></a></li>
<li><a href="network_graph_spec.html#edgejitter"><code>edge.jitter</code></a></li>
<li><a href="network_graph_spec.html#edgepacket_loss"><code>edge.packet_loss</code></a></li>
</ul>
<h4 id="graphdirected"><a class="header" href="#graphdirected"><code>graph.directed</code></a></h4>
<p>Required: False<br />
Default: <code>0</code><br />
Type: Integer</p>
<p>Specifies the symmetry of the edges in the graph. If set to <code>0</code> (the default),
the graph is an <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">undirected
graph</a>: an edge
between node <code>u</code> and node <code>v</code> is symmetric and can be used to construct a
path both from <code>u</code> to <code>v</code> and from <code>v</code> to <code>u</code>. If set to <code>1</code>, the graph is a
<a href="https://en.wikipedia.org/wiki/Directed_graph">directed graph</a>: an edge from
node <code>u</code> to node <code>v</code> is assymmetric and can only be used to construct a path
from <code>u</code> to <code>v</code> (a separate edge from <code>v</code> to <code>u</code> must be specified to compose a
path in the reverse direction).</p>
<h4 id="nodeid"><a class="header" href="#nodeid"><code>node.id</code></a></h4>
<p>Required: True<br />
Type: Integer</p>
<p>A unique integer identifier for a given node.</p>
<h4 id="nodelabel"><a class="header" href="#nodelabel"><code>node.label</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: String</p>
<p>An optional, human-meaningful string description of the node. The string may
be used in log messages printed by Shadow.</p>
<h4 id="nodehost_bandwidth_down"><a class="header" href="#nodehost_bandwidth_down"><code>node.host_bandwidth_down</code></a></h4>
<p>Required: True<br />
Type: String</p>
<p>A string defining the downstream (receive) bandwidth that will be allowed for
any host attached to this node. Hosts may individually override this value in
<a href="shadow_config_spec.html#hostshostnamebandwidth_down">the Shadow config file</a>.
The format of the string specifies the bandwidth and its unit as described in
the <a href="shadow_config_spec.html">config documentation</a>, e.g., <code>10 Mbit</code>. Note that
this bandwidth is allowed for every host that is attached to this node; it is
<strong>not</strong> the total bandwidth logically available at the node (which is not
defined).</p>
<h4 id="nodehost_bandwidth_up"><a class="header" href="#nodehost_bandwidth_up"><code>node.host_bandwidth_up</code></a></h4>
<p>Required: True<br />
Type: String</p>
<p>A string defining the upstream (send) bandwidth that will be allowed for any
host attached to this node. Hosts may individually override this value in <a href="shadow_config_spec.html#hostshostnamebandwidth_up">the
Shadow config file</a>. The
format of the string specifies the bandwidth and its unit as described in the
<a href="shadow_config_spec.html">config documentation</a>, e.g., <code>10 Mbit</code>. Note that
this bandwidth is allowed for every host that is attached to this node; it is
<strong>not</strong> the total bandwidth logically available at the node (which is not
defined).</p>
<h4 id="edgesource"><a class="header" href="#edgesource"><code>edge.source</code></a></h4>
<p>Required: True<br />
Type: Integer</p>
<p>The unique integer identifier of the first of two nodes of the edge. The
node must exist in the graph. If the graph is directed, this node is treated
as the source or start of the edge.</p>
<h4 id="edgetarget"><a class="header" href="#edgetarget"><code>edge.target</code></a></h4>
<p>Required: True<br />
Type: Integer</p>
<p>The unique integer identifier of the second of two nodes of the edge. The
node must exist in the graph. If the graph is directed, this node is treated
as the target or end of the edge.</p>
<h4 id="edgelabel"><a class="header" href="#edgelabel"><code>edge.label</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: String</p>
<p>An optional, human-meaningful string description of the edge. The string may be
used in log messages printed by Shadow.</p>
<h4 id="edgelatency"><a class="header" href="#edgelatency"><code>edge.latency</code></a></h4>
<p>Required: True<br />
Type: String</p>
<p>The latency that will be added to packets traversing this edge. This value is
used as a weight while running Dijkstra's shortest path algorithm. The format of
the string specifies the latency and its unit, e.g., <code>10 ms</code>. If a unit is not
specified, it will be assumed that it is in the base unit of "seconds". The
latency must not be 0.</p>
<h4 id="edgejitter"><a class="header" href="#edgejitter"><code>edge.jitter</code></a></h4>
<p>Required: False<br />
Default: n/a<br />
Type: String</p>
<p>This keyword is allowed but currently nonfunctional; it is reserved for future
use.</p>
<h4 id="edgepacket_loss"><a class="header" href="#edgepacket_loss"><code>edge.packet_loss</code></a></h4>
<p>Required: True<br />
Type: Float</p>
<p>A fractional value between 0 and 1 representing the chance that a packet
traversing this edge will get dropped.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="disabling-sidechannel-mitigations"><a class="header" href="#disabling-sidechannel-mitigations">Disabling Sidechannel Mitigations</a></h1>
<p>Sidechannel attacks in the style of
<a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre</a> and
<a href="https://en.wikipedia.org/wiki/Meltdown_(security_vulnerability)">Meltdown</a>
allow malicious code to access data it otherwise wouldn't be able to. Modern
systems employ countermeasures to prevent these attacks, which typically incur
some performance cost, and may not be necessary when running Shadow simulations.
i.e. Shadow's performance can be improved by disabling these mitigations.</p>
<p>Keep in mind that Shadow already isn't designed to protect itself or its host
system from malicious software. See <a href="security.html">Security</a>.</p>
<h2 id="speculative-store-bypass"><a class="header" href="#speculative-store-bypass">Speculative Store Bypass</a></h2>
<p>The Speculative Store Bypass attack allows malicious code to read data it
otherwise wouldn't be able to, e.g. due to software sandboxing such as in a
javascript engine.  For a high-level overview of this attack and mitigations,
see:
<a href="https://www.redhat.com/en/blog/speculative-store-bypass-explained-what-it-how-it-works">https://www.redhat.com/en/blog/speculative-store-bypass-explained-what-it-how-it-works</a>.
For a more technical overview, see
<a href="https://software.intel.com/content/dam/develop/external/us/en/documents/336996-speculative-execution-side-channel-mitigations.pdf">https://software.intel.com/content/dam/develop/external/us/en/documents/336996-speculative-execution-side-channel-mitigations.pdf</a>.</p>
<p>We have observed the mitigation for this vulnerability to add roughly a <a href="https://github.com/shadow/shadow/issues/1489#issuecomment-871445482">30%
performance overhead</a> to Shadow simulations. Because process isolation is
already sufficient to mitigate this vulnerability (See <a href="https://software.intel.com/content/dam/develop/external/us/en/documents/336996-speculative-execution-side-channel-mitigations.pdf">"Process
Isolation"</a>),
and because Shadow already makes <a href="security.html">no attempt</a> to protect itself
from malicious code within its own processes, and isn't designed to run in a
managed-code environment itself, enabling this mitigation in Shadow and its
managed processes doesn't have any clear benefit.</p>
<p>Shadow itself makes use of <code>seccomp</code>, but uses the
<code>SECCOMP_FILTER_FLAG_SPEC_ALLOW</code> flag to avoid turning on this mitigation.  It
also logs a warning if it detects this mitigation is already enabled.</p>
<p>One common way this mitigation can be turned on inadvertently is by running
inside a Docker container, with seccomp enabled (which is the default).  You can
avoid this by turning off seccomp entirely (using <a href="https://docs.docker.com/engine/security/seccomp/#run-without-the-default-seccomp-profile"><code>--security-opt seccomp=unconfined</code></a>, but this might not be an option when running in a
shared environment. Unfortunately, Docker currently <a href="https://github.com/moby/moby/issues/42619">doesn't
expose</a> an option to use its seccomp
functionality without turning on this mitigation.</p>
<p>Another way to avoid enabling this mitigation is by changing the <a href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html">kernel
parameter</a>
<code>spec_store_bypass_disable</code>. Overriding its default value of <code>seccomp</code> to
<code>prctl</code> will still allow software sandboxes such as javascript engines to enable
this mitigation, but will no longer enable it by default when installing a
<code>seccomp</code> filter. In principle this could create a vulnerability if there's code
running on the system that relies on the default behavior without explicitly
opting in via <code>prctl</code>, so use some caution. For more discussion on this
parameter, see this discussion on the kernel mailing list about whether the
kernel default ought to be changed from <code>seccomp</code> to <code>prctl</code>:
<a href="https://lore.kernel.org/lkml/20201104215702.GG24993@redhat.com/">https://lore.kernel.org/lkml/20201104215702.GG24993@redhat.com/</a></p>
<h2 id="other-mitigations"><a class="header" href="#other-mitigations">Other mitigations</a></h2>
<p>In some ad-hoc measurements we've found that disabling <em>all</em> sidechannel
mitigations with
<a href="https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html"><code>mitigations=off</code></a>
also provides a significant performance boost. We haven't thoroughly evaluated
the exact benefits though, and this setting could expose your system to attack.
At a minimum, this isn't advised on a system that runs <em>any</em> untrusted code at
<em>any</em> privilege level, including in managed environments such as running
javascript in a web browser.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parallel-simulations"><a class="header" href="#parallel-simulations">Parallel simulations</a></h1>
<p>Some care must be taken when running multiple Shadow simulations on the same
hardware at the same time. By default, Shadow pins threads to specific CPUs to
avoid CPU migrations. The CPU selection logic isn't aware of other processes
that may be using substantial CPU time and/or pinning, <em>including other Shadow
simulations</em>. i.e. without some care, multiple Shadow simulations running on the
same machine at the same time will generally end up trying to use the same set
of CPUs, even if other CPUs on the machine are idle.</p>
<h2 id="disabling-pinning"><a class="header" href="#disabling-pinning">Disabling pinning</a></h2>
<p>The simplest solution is to disable CPU pinning entirely. This has a substantial
performance penalty (with some reports as high as 3x), but can be a reasonable
solution for small simulations. Pinning can be disabled by passing
<code>--use-cpu-pinning=false</code> to Shadow.</p>
<h2 id="setting-an-initial-cpu-affinity"><a class="header" href="#setting-an-initial-cpu-affinity">Setting an initial CPU affinity</a></h2>
<p>Shadow checks the initial CPU affinity assigned to it, and only assigns to CPUs
within that set. The easiest way to run Shadow with a subset of CPUs is with the
<code>taskset</code> utility. e.g. to start one Shadow simulation using CPUs 0-9 and
another using CPUs 10-19, you could use:</p>
<pre><code>$ (cd sim1 &amp;&amp; taskset --cpu-list 0-9 shadow sim1config.yml) &amp;
$ (cd sim2 &amp;&amp; taskset --cpu-list 10-19 shadow sim2config.yml) &amp;
</code></pre>
<p>Shadow similarly avoids trying to pin to CPUs outside of its cgroup cpuset (see
cpuset(7)). This allows Shadow to work correctly in such scenarios (such as
running in a container on a shared machine that only has access to some CPUs),
but is generally more complex and requires higher privilege than setting the CPU
affinity with <code>taskset</code>.</p>
<h2 id="choosing-a-cpu-set"><a class="header" href="#choosing-a-cpu-set">Choosing a CPU set</a></h2>
<p>When assigning Shadow a subset of CPUs, some care must be taken to get optimal
performance. You can use the <code>lscpu</code> utility to see the layout of the CPUs on
your machine.</p>
<ul>
<li>Avoid using multiple CPUs on the same core (aka hyperthreading). Such CPUs
compete with each-other for resources.</li>
<li>Prefer CPUs on the same socket and (NUMA) node. Such CPUs share cache, which
is typically beneficial in Shadow simulations.</li>
</ul>
<p>For example, given the <code>lscpu</code> output:</p>
<pre><code>$ lscpu --parse=cpu,core,socket,node
# The following is the parsable format, which can be fed to other
# programs. Each different item in every column has an unique ID
# starting from zero.
# CPU,Core,Socket,Node
0,0,0,0
1,1,1,1
2,2,0,0
3,3,1,1
4,4,0,0
5,5,1,1
6,6,0,0
7,7,1,1
8,8,0,0
9,9,1,1
10,10,0,0
11,11,1,1
12,12,0,0
13,13,1,1
14,14,0,0
15,15,1,1
16,16,0,0
17,17,1,1
18,18,0,0
19,19,1,1
20,20,0,0
21,21,1,1
22,22,0,0
23,23,1,1
24,24,0,0
25,25,1,1
26,26,0,0
27,27,1,1
28,28,0,0
29,29,1,1
30,30,0,0
31,31,1,1
32,32,0,0
33,33,1,1
34,34,0,0
35,35,1,1
36,36,0,0
37,37,1,1
38,38,0,0
39,39,1,1
40,0,0,0
41,1,1,1
42,2,0,0
43,3,1,1
44,4,0,0
45,5,1,1
46,6,0,0
47,7,1,1
48,8,0,0
49,9,1,1
50,10,0,0
51,11,1,1
52,12,0,0
53,13,1,1
54,14,0,0
55,15,1,1
56,16,0,0
57,17,1,1
58,18,0,0
59,19,1,1
60,20,0,0
61,21,1,1
62,22,0,0
63,23,1,1
64,24,0,0
65,25,1,1
66,26,0,0
67,27,1,1
68,28,0,0
69,29,1,1
70,30,0,0
71,31,1,1
72,32,0,0
73,33,1,1
74,34,0,0
75,35,1,1
76,36,0,0
77,37,1,1
78,38,0,0
79,39,1,1
</code></pre>
<p>A reasonable configuration for two simulations might be <code>taskset --cpu-list 0-39:2</code> (CPUs 0,2,...,38) and <code>taskset --cpu-list 1-39:2</code>. (CPUs 1,3,...,39).
This assignment leaves CPUs 40-79 idle, since those share the same physical
cores at CPUs 0-39, puts the first simulation on socket 0 and numa node 0, and
the second simulation on socket 1 and numa node 1.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuration-options"><a class="header" href="#configuration-options">Configuration options</a></h1>
<p>Shadow's configuration options are generally tuned for optimal performance
using Tor benchmarks, but not all system architectures and simulation workloads
are the same. Shadow has several configuration options that may improve the
simulation performance. Many of these options are considered "experimental",
which means that they may be changed or removed at any time. If you find any of
these options useful, <a href="https://github.com/shadow/shadow/discussions">let us know</a>.</p>
<p>Be careful as these options may also <em>worsen</em> the simulation performance or in
some cases alter the simulation behaviour. Also remember that Shadow's
<code>--debug</code> build flag will significantly reduce the simulation performance, so
don't use this flag when running long simulations.</p>
<h3 id="bootstrap_end_time"><a class="header" href="#bootstrap_end_time"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#generalbootstrap_end_time"><code>bootstrap_end_time</code></a></a></h3>
<p>Shadow supports an optional "bootstrapping period" of high network
bandwidth and reliability for simulations which require network-related
bootstrapping (for example Tor). While the network performance characteristics
will be unrealistic during this time period, it can significantly reduce the
simulation's wall clock time. After this bootstrapping period ends, the network
bandwidth/reliability is reverted back to the values specified in the
simulation and network configuration.</p>
<h3 id="log_level"><a class="header" href="#log_level"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#generallog_level"><code>log_level</code></a></a></h3>
<p>Using lower log levels such as <code>debug</code> or <code>trace</code> will lead to a much greater
volume of log messages. Writing these messages to disk can significantly impact
the simulation run time performance, even if you're writing to an SSD. Unless
you're actively debugging an issue in Shadow, you should use <code>info</code> level or
higher.</p>
<p>Along these same lines, you should try to reduce the amount of disk I/O of the
managed applications running within Shadow. Even if they each write a
reasonably small amount, it can add up to a lot of disk I/O when running
simulations with thousands of processes.</p>
<h3 id="heartbeat_interval"><a class="header" href="#heartbeat_interval"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#generalheartbeat_interval"><code>heartbeat_interval</code></a></a></h3>
<p>Shadow logs simulation statistics at given simulation time intervals. If any of
these time intervals are small relative to the <a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#generalstop_time">total time</a> of the
simulation, a large number of log lines will be written. If the log is being
written to disk, this increased disk I/O may slow down the simulation
dramatically.</p>
<h3 id="parallelism"><a class="header" href="#parallelism"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#generalparallelism"><code>parallelism</code></a></a></h3>
<p>Simulations with multiple hosts can be parallelized across multiple threads. By
default Shadow tries to choose an optimal number of threads to run in parallel,
but a different number of threads may yield better run time performance.</p>
<h3 id="use_cpu_pinning"><a class="header" href="#use_cpu_pinning"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#experimentaluse_cpu_pinning"><code>use_cpu_pinning</code></a></a></h3>
<p>CPU pinning is enabled by default and should improve the simulation
performance, but in shared computing environments it might be beneficial to
disable this option.</p>
<h3 id="scheduler"><a class="header" href="#scheduler"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#experimentalscheduler"><code>scheduler</code></a></a></h3>
<p>Shadow supports two different types of work schedulers. The default
<code>thread_per_core</code> scheduler has been found to be significantly faster on most
machines, but may perform worse than the <code>thread_per_host</code> scheduler in rare
circumstances.</p>
<h3 id="use_memory_manager"><a class="header" href="#use_memory_manager"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#experimentaluse_memory_manager"><code>use_memory_manager</code></a></a></h3>
<p>Shadow supports a memory manager that uses shared memory maps to reduce the
overhead of accessing a managed process' data from Shadow's main process, but
this is disabled by default as it does not support other Shadow features such
as emulating the fork/exec syscalls. If you do not need support for these
features, enabling this memory manager may slightly improve simulation
performance.</p>
<h3 id="use_worker_spinning"><a class="header" href="#use_worker_spinning"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#experimentaluse_worker_spinning"><code>use_worker_spinning</code></a></a></h3>
<p>Shadow's thread-per-core scheduler uses a spinloop by default. While this
results in significant performance improvements in our benchmarks, it may be
worth testing Shadow's performance with this disabled.</p>
<h3 id="max_unapplied_cpu_latency"><a class="header" href="#max_unapplied_cpu_latency"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#experimentalmax_unapplied_cpu_latency"><code>max_unapplied_cpu_latency</code></a></a></h3>
<p>If <a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#generalmodel_unblocked_syscall_latency"><code>model_unblocked_syscall_latency</code></a> is
enabled, increasing the max unapplied CPU latency may improve the simulation
run time performance.</p>
<h3 id="runahead"><a class="header" href="#runahead"><a href="https://shadow.github.io/docs/guide/shadow_config_spec.html#experimentalrunahead"><code>runahead</code></a></a></h3>
<p>This option effectively sets a minimum network latency. Increasing this value
will allow for better simulation parallelisation and possibly better run time
performance, but will affect the network characteristics of the simulation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="profiling"><a class="header" href="#profiling">Profiling</a></h1>
<p>Profiling can be useful for improving the performance of experiments, either as
improvements to the implementation of Shadow itself, or in altering the
configuration of the experiments you are running.</p>
<h2 id="profiling-with-tophtop"><a class="header" href="#profiling-with-tophtop">Profiling with <code>top</code>/<code>htop</code></a></h2>
<p>Tools like <code>top</code> and <code>htop</code> will give good first-order approximations for what
Shadow is doing. While they can only give system-wide to thread-level
granularity, this can often still tell you important details such as whether
Shadow, the simulated processes, or the kernel are consuming memory and
processor cycles. E.g., if you're running into memory constraints, the <code>RES</code> or
<code>MEM</code> column of these tools can tell you where to start looking for ways to
address that. If execution time is too long, sorting by <code>CPU</code> or <code>TIME</code> can
provide insight into where that time is being spent.</p>
<p>One limitation to note is that Shadow relies on spinlocks in barriers for some
of its operation. Especially when running with many threads, these spinlocks
will show as consuming most of the CPU anytime the simulation is bottlenecked
on few simulated processes. Telling when this is happening can be difficult in
these tools, because no symbol information is available.</p>
<h2 id="profiling-with-perf"><a class="header" href="#profiling-with-perf">Profiling with <code>perf</code></a></h2>
<p>The <code>perf</code> tool is a powerful interface to the Linux kernel's performance
counter subsystem. See <code>man perf</code> or <a href="https://perf.wiki.kernel.org/index.php/Tutorial">the perf
wiki</a> for full details on how
to use it, but some highlights most relevant to Shadow execution time are given
here.</p>
<p>Regardless of how you are using <code>perf</code>, the aforementioned complication of
spinlocks in Shadow apply. Namely, when there is any bottleneck on the barrier,
the symbols associated with the spinlocks will dominate the sample
counts. Improving the performance of the spinlocks will not improve the
performance of the experiment, but improving the performance of whatever is
causing the bottleneck (likely something towards the top of non-spinlock
symbols) can.</p>
<h3 id="perf-top"><a class="header" href="#perf-top"><code>perf top</code></a></h3>
<p>The <code>perf top</code> command will likely be the most practical mode of
<code>perf</code> for profiling all parts of a Shadow experiment. It requires one
of: root access, appropriately set up Linux capabilities, or a system
configured to allow performance monitoring (similar to attaching to
processes with <code>gdb</code>), so isn't always available, but is very simple
when it is. The interface is similar to <code>top</code>'s, but provides
information on the granularity of symbols, across the entire
system. This means you will be able to tell which specific functions
in Shadow, the simulated processes, and the kernel are consuming CPU
time.</p>
<p>When <code>perf top</code> can't find symbol information for a process, it will display
the offset of the instruction as hex instead. (Note this means it will be
ranked by instruction, rather than the entire function.) If you know where the
respective executable or shared object file is, you can look up the name of the
symbol for that instruction's function by opening the file with <code>gdb</code> and
running <code>info symbol [ADDRESS]</code>. If <code>gdb</code> can't find the symbols either, you
can look it up manually using <code>readelf -s</code> and finding the symbol with the
largest address smaller than the offset you are looking for (note that
<code>readelf</code> does not output the symbols in order of address; you can pipe the
output to <code>awk '{$1=""; print $0}' | sort</code> to get a sorted list).</p>
<p>Details on more options (e.g., for filtering the sampled CPUs or processes) can
be found in <code>man perf top</code>.</p>
<h3 id="perf-record"><a class="header" href="#perf-record"><code>perf record</code></a></h3>
<p>If you know which particular process you wish to profile, <code>perf record</code> can
give far greater detail than other options. To use it for Shadow, either run it
when starting Shadow:</p>
<pre><code class="language-bash">perf record shadow shadow.config.yaml &gt; shadow.log
</code></pre>
<p>Or, attach to a running Shadow process:</p>
<pre><code class="language-bash">perf record -p &lt;PID&gt;
</code></pre>
<p>Attaching to a process requires similar permissions as <code>perf top</code>, but can be
used to profile any process, including the simulated processes launched by
Shadow.</p>
<p>The <code>perf record</code> process will write a <code>perf.data</code> file when you press Ctrl-c,
or Shadow ends. You can then analyze the report:</p>
<pre><code class="language-bash">perf report
</code></pre>
<p>More details are available in <code>man perf record</code> and <code>man perf report</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stability-guarantees"><a class="header" href="#stability-guarantees">Stability Guarantees</a></h1>
<p>Shadow generally follows the <a href="https://semver.org/">semantic versioning</a>
principles:</p>
<ul>
<li>PATCH version increases (ex: <code>2.0.1</code> to <code>2.0.2</code>) are intended for bug fixes.</li>
<li>MINOR version increases (ex: <code>2.0.2</code> to <code>2.1.0</code>) are intended for new
backwards-compatible features and changes.</li>
<li>MAJOR version increases (ex: <code>1.2.2</code> to <code>2.0.0</code>) are intended for
incompatible changes.</li>
</ul>
<p>More specifically, we aim to provide the following guarantees between MINOR
versions:</p>
<ul>
<li>Command line and configuration option changes and additions will be
backwards-compatible.
<ul>
<li>Default values for existing options will not change.</li>
</ul>
</li>
<li>File and directory names in Shadow's data directory
(<a href="shadow_config_spec.html#generaldata_directory"><code>general.data_directory</code></a>)
will not change.</li>
<li>Support for any of Shadow's <a href="supported_platforms.html">supported platforms</a>
will not be dropped, unless those platforms no longer receive free updates
and support from the distribution's developer.</li>
<li>We will not change the criteria for the minimum supported Linux kernel version
as documented in <a href="supported_platforms.html">supported platforms</a>. (Note though
that this still allows us to increase the minimum kernel version as a result of
dropping support for a platform, which we may do as noted above).</li>
</ul>
<p>The following may change between ANY versions (MAJOR, MINOR, or PATCH):</p>
<ul>
<li>The log format and messages.</li>
<li>Experimental options may change or be removed.</li>
<li>The simulation may produce different results.</li>
<li>New files may be added in Shadow's data directory
(<a href="shadow_config_spec.html#generaldata_directory"><code>general.data_directory</code></a>).
<ul>
<li>If new files are added in Shadow's host-data directories, they will begin
with the prefix <code>&lt;process name&gt;.&lt;pid&gt;</code>.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="non-goal-security"><a class="header" href="#non-goal-security">Non-goal: Security</a></h1>
<p>Never run code under Shadow that you wouldn't trust enough to run outside of
Shadow on the same system at the same level of privilege.</p>
<p>While Shadow uses some of the same techniques used by other systems to isolate
potentially vulnerable or malicious software, this is <em>not</em> a design goal of
Shadow. A managed program in a Shadow simulation can, if it tries to, detect
that it's running under such a simulation and break out of the "sandbox" to
issue native system calls.</p>
<p>For example:</p>
<ul>
<li>Shadow currently doesn't restrict access to the host file
system. A malicious managed program can read and modify the same files that
Shadow itself can.</li>
<li>Shadow inserts some code via <code>LD_PRELOAD</code> into managed processes. This code
intentionally has the ability to make non-interposed system calls (which it uses
to communicate with the Shadow process), and makes no effort to protect itself
from the managed code running in the same process.</li>
</ul>
<h2 id="reporting-security-issues"><a class="header" href="#reporting-security-issues">Reporting security issues</a></h2>
<p>Security issues can be reported to
unique_halberd_0m@icloud.com
.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="limitations-and-workarounds"><a class="header" href="#limitations-and-workarounds">Limitations and workarounds</a></h1>
<p>Shadow can typically run applications without modification, but there are a few
limitations to be aware of.</p>
<p>If you are severely affected by one of these limitations (or another not listed
here) let us know, as this can help us prioritize our improvements to Shadow.
You may reach out in our
<a href="https://github.com/shadow/shadow/discussions">discussions</a> or
<a href="https://github.com/shadow/shadow/issues">issues</a>.</p>
<h2 id="unimplemented-system-calls-and-options"><a class="header" href="#unimplemented-system-calls-and-options">Unimplemented system calls and options</a></h2>
<p>When Shadow encounters a syscall or a syscall option that it hasn't implemented,
it will generally return <code>ENOSYS</code> and log at <code>warn</code> level or higher. In many
such cases the application is able to recover, and this has little or no effect
on the ultimate results of the simulation.</p>
<p>There are some syscalls that shadow doesn't quite emulate faithfully, but has a
"best effort" implementation. As with unimplemented sysalls, shadow logs at
<code>warn</code> level when encountering such a syscall.</p>
<h3 id="vfork"><a class="header" href="#vfork">vfork</a></h3>
<p>A notable example of a not-quite faithfully implemented syscall is
<a href="https://www.man7.org/linux/man-pages/man2/vfork.2.html"><code>vfork</code></a>, which shadow
effectively implements as a synonym for <code>fork</code>. Usage of <code>vfork</code> that is
compliant with the POSIX.1 specification that "behavior is undefined if the
process created by vfork() either modifies any data other than a variable of
type pid_t used to store the return value...". However, usage that relies on
specific Linux implementation details of <code>vfork</code> (e.g. that a write to a global
variable from the child will be observed by the parent) won't work correctly.</p>
<p>As in other such cases, shadow logs a warning when it encounters <code>vfork</code>, so
that users can identify it as the potential source of problems if a simulation
doesn't work as expected.</p>
<h2 id="ipv6"><a class="header" href="#ipv6">IPv6</a></h2>
<p>Shadow does not yet implement IPv6. Most applications can be configured to use IPv4
instead. Tracking issue: <a href="https://github.com/shadow/shadow/issues/2216%5D">#2216</a>.</p>
<h2 id="statically-linked-executables"><a class="header" href="#statically-linked-executables">Statically linked executables</a></h2>
<p>Shadow relies on <code>LD_PRELOAD</code> to inject code into the managed processes. This
doesn't work for statically linked executables. Tracking issue:
<a href="https://github.com/shadow/shadow/issues/1839">#1839</a>.</p>
<p>Most applications can be dynamically linked, though occasionally you may need to
edit build scripts and/or recompile.</p>
<h3 id="golang"><a class="header" href="#golang">golang</a></h3>
<p><code>golang</code> typically defaults to producing statically linked executables, unless
the application uses <code>cgo</code>. Using the networking functionality of <code>golang</code>'s
standard library usually pulls in <code>cgo</code> by default and thus results in a
dynamically linked executable.</p>
<p>You can also explicitly force <code>go</code> to produce a dynamically linked executable. e.g.</p>
<pre><code># Install a dynamically linked `std`
go install -buildmode=shared std
# Build your application with dynamic linking
go build -linkshared myapp.go
</code></pre>
<h2 id="busy-loops"><a class="header" href="#busy-loops">Busy loops</a></h2>
<p>By default, Shadow runs each thread of managed processes until it's blocked by a
syscall such as <code>nanosleep</code>,  <code>read</code>, <code>select</code>, <code>futex</code>, or <code>epoll</code>. Likewise,
time only moves forward when Shadow is blocked on such a call - Shadow
effectively models the CPU as being infinitely fast. This model is generally
sufficient for modeling non-CPU-bound network applications.</p>
<p>Unfortunately this model can lead to deadlock in the case of "busy loops", where
a thread repeatedly checks for something to happen indefinitely or until some
amount of wall-clock-time has passed. e.g., a worker thread might repeatedly
check whether work is available for some amount of time before going to sleep on
a <code>futex</code>, to avoid the latency of going to sleep and waking back up in cases
where work arrives quickly. However since Shadow normally doesn't advance time
when making non-blocking syscalls or allow other threads to run, such a loop can
run indefinitely, deadlocking the whole simulation.</p>
<p>When feasible, it's usually good practice to modify such loops to have a bound
on the number of iterations instead of or in addition to a bound on wallclock
time.</p>
<p>For cases where modifying the loop is infeasible, Shadow provides the option
<code>--model-unblocked-syscall-latency</code>. When this option is enabled, Shadow moves
time forward a small amount on <em>every</em> syscall (and VDSO function call), and
switches to another thread if one becomes runnable in the meantime (e.g. because
network data arrived when the clock moved forward, unblocking it).</p>
<p>This feature should only be used when it's needed to get around such loops. Some
limitations:</p>
<ul>
<li>
<p>It may cause the simulation to run slower.</p>
<ul>
<li>
<p>Enabling this feature forces Shadow to switch between threads more
frequently, which is costly and hurts cache performance. We have minimized
this effect to the extent that we can, but it can especially hurt performance
when there are multiple unblocked threads on a single simulated Host, forcing
Shadow to keep switching between them to keep the simulated time synchronized.</p>
</li>
<li>
<p>Busy loops intrinsically waste some CPU cycles. Outside of Shadow this can
be a tradeoff for improved latency by avoiding a thread switch. However, in a
Shadow simulation this latency isn't modeled, so busy-looping instead of
blocking immediately has no benefit to simulated performance; only cost to
simulation performance. If feasible, changing the busy-loop to block
immediately instead of spinning should improve simulation performance without
substantially affecting simulation results.</p>
</li>
</ul>
</li>
<li>
<p>It's not meant as an accurate model of syscall latency. It generally models
syscalls as being somewhat faster than they would be on a real system to minimize
the impact on simulation results.</p>
</li>
<li>
<p>Nonetheless it <em>does</em> affect simulation results. Arguably this model
is more accurate, since syscalls on real systems <em>do</em> take non-zero time, but it
makes the time model more complex to understand and reason about.</p>
</li>
<li>
<p>It still doesn't account for time spent by the CPU executing code,
which also means that a busy-loop that makes no syscalls at all can still lead
to deadlock. Fortunately such busy loops are rare and are generally agreed upon
to be bugs, since they'd also potentially monopolize a CPU indefinitely when run
natively.</p>
</li>
</ul>
<p>For more about this topic, see <a href="https://github.com/shadow/shadow/issues/1792">#1792</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="compatibility-notes"><a class="header" href="#compatibility-notes">Compatibility Notes</a></h1>
<ul>
<li><a href="compatibility_notes.html#libopenblas">libopenblas</a></li>
<li><a href="compatibility_notes.html#curl">cURL</a></li>
<li><a href="compatibility_notes.html#wget2">Wget2</a></li>
<li><a href="compatibility_notes.html#nginx">Nginx</a></li>
<li><a href="compatibility_notes.html#iperf-2">iPerf 2</a></li>
<li><a href="compatibility_notes.html#iperf-3">iPerf 3</a></li>
<li><a href="compatibility_notes.html#jetty">Jetty</a></li>
<li><a href="compatibility_notes.html#etcd-distributed-key-value-store">etcd (distributed key-value store)</a></li>
<li><a href="compatibility_notes.html#ctorrent-and-opentracker">CTorrent and opentracker</a></li>
<li><a href="compatibility_notes.html#http-server">http-server</a></li>
</ul>
<h2 id="libopenblas"><a class="header" href="#libopenblas">libopenblas</a></h2>
<p>libopenblas is a fairly low-level library, and can get pulled in transitively
via dependencies. e.g., <a href="https://github.com/shadow/tgen">tgen</a> uses libigraph,
which links against liblapack, which links against blas.</p>
<p>libopenblas, when compiled with pthread support, uses
<a href="limitations.html#busy-loops">busy-loops</a> in its worker threads.</p>
<p>There are several known workarounds:</p>
<ul>
<li>
<p>Use Shadow's <code>--model-unblocked-syscall-latency</code> feature. See
<a href="limitations.html#busy-loops">busy-loops</a> for details and caveats.</p>
</li>
<li>
<p>Use a different implementation of libblas. e.g. on Ubuntu, there are several
alternative packages that can <a href="https://packages.ubuntu.com/hirsute/libblas.so.3">provide
libblas</a>.  In particular,
<a href="https://packages.ubuntu.com/hirsute/libblas3">libblas3</a> doesn't have this issue.</p>
</li>
<li>
<p>Install libopenblas compiled without pthread support. e.g. on Ubuntu this can
be obtained by installing
<a href="https://packages.ubuntu.com/hirsute/libopenblas0-serial">libopenblas0-serial</a>
instead of
<a href="https://packages.ubuntu.com/hirsute/libopenblas0-pthread">libopenblas0-pthread</a>.</p>
</li>
<li>
<p>Configure libopenblas to not use threads at runtime. This can be done by
setting the environment variable <code>OPENBLAS_NUM_THREADS=1</code>, in the process's
<a href="shadow_config_spec.html#hostshostnameprocessesenvironment">environment</a>
attribute in the Shadow config. Example:
<a href="https://github.com/shadow/shadow/blob/7ceb8b7793f1e525c7278e1893aa247ad224af76/src/test/tor/minimal/tor-minimal.yaml#L109">tor-minimal.yaml:109</a></p>
</li>
</ul>
<p>See also:</p>
<ul>
<li><a href="https://github.com/shadow/shadow/issues/1788">libopenblas deadlocks</a></li>
</ul>
<h2 id="curl"><a class="header" href="#curl">cURL</a></h2>
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<pre><code class="language-yaml">general:
  stop_time: 10s
  model_unblocked_syscall_latency: true

network:
  graph:
    type: 1_gbit_switch

hosts:
  server:
    network_node_id: 0
    processes:
    - path: python3
      args: -m http.server 80
      start_time: 0s
      expected_final_state: running
  client1: &amp;client_host
    network_node_id: 0
    processes:
    - path: curl
      args: -s server
      start_time: 2s
  client2: *client_host
  client3: *client_host
</code></pre>
<pre><code class="language-bash">rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
cat shadow.data/hosts/client1/curl.1000.stdout
</code></pre>
<h3 id="notes"><a class="header" href="#notes">Notes</a></h3>
<ol>
<li>Older versions of cURL use a busy loop that is incompatible with Shadow and
will cause Shadow to deadlock. <code>model_unblocked_syscall_latency</code> works around
this (see <a href="limitations.html#busy-loops">busy-loops</a>). Newer versions of cURL, such as the
version provided in Ubuntu 20.04, don't have this issue. See issue
<a href="https://github.com/shadow/shadow/issues/1794">#1794</a> for details.</li>
</ol>
<h2 id="wget2"><a class="header" href="#wget2">Wget2</a></h2>
<h3 id="example-1"><a class="header" href="#example-1">Example</a></h3>
<pre><code class="language-yaml">general:
  stop_time: 10s

network:
  graph:
    type: 1_gbit_switch

hosts:
  server:
    network_node_id: 0
    processes:
    - path: python3
      args: -m http.server 80
      start_time: 0s
      expected_final_state: running
  client1: &amp;client_host
    network_node_id: 0
    processes:
    - path: wget2
      args: --no-tcp-fastopen server
      start_time: 2s
  client2: *client_host
  client3: *client_host
</code></pre>
<pre><code class="language-bash">rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
cat shadow.data/hosts/client1/index.html
</code></pre>
<h3 id="notes-1"><a class="header" href="#notes-1">Notes</a></h3>
<ol>
<li>Shadow doesn't support <code>TCP_FASTOPEN</code> so you must run Wget2 using the <code>--no-tcp-fastopen</code> option.</li>
</ol>
<h2 id="nginx"><a class="header" href="#nginx">Nginx</a></h2>
<h3 id="example-2"><a class="header" href="#example-2">Example</a></h3>
<h4 id="shadowyaml"><a class="header" href="#shadowyaml"><code>shadow.yaml</code></a></h4>
<pre><code class="language-yaml">general:
  stop_time: 10s

network:
  graph:
    type: 1_gbit_switch

hosts:
  server:
    network_node_id: 0
    processes:
    - path: nginx
      args: -c ../../../nginx.conf -p .
      start_time: 0s
      expected_final_state: running
  client1: &amp;client_host
    network_node_id: 0
    processes:
    - path: curl
      args: -s server
      start_time: 2s
  client2: *client_host
  client3: *client_host
</code></pre>
<h4 id="nginxconf"><a class="header" href="#nginxconf"><code>nginx.conf</code></a></h4>
<pre><code class="language-nginx">error_log stderr;

# shadow wants to run nginx in the foreground
daemon off;

# shadow doesn't support some syscalls that nginx uses to set up and control
# worker child processes.
# https://github.com/shadow/shadow/issues/3174
master_process off;
worker_processes 0;

# don't use the system pid file
pid nginx.pid;

events {
  # we're not using any workers, so this is the maximum number
  # of simultaneous connections we can support
  worker_connections 1024;
}

http {
  include             /etc/nginx/mime.types;
  default_type        application/octet-stream;

  # shadow does not support sendfile()
  sendfile off;

  access_log off;

  server {
    listen 80;

    location / {
      root /var/www/html;
      index index.nginx-debian.html;
    }
  }
}
</code></pre>
<pre><code class="language-bash">rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
cat shadow.data/hosts/client1/curl.1000.stdout
</code></pre>
<h3 id="notes-2"><a class="header" href="#notes-2">Notes</a></h3>
<ol>
<li>
<p>Shadow currently doesn't support some syscalls that nginx uses to set up and control worker child processes, so you must disable additional processes
using <code>master_process off</code> and <code>worker_processes 0</code>. See https://github.com/shadow/shadow/issues/3174.</p>
</li>
<li>
<p>Shadow doesn't support <code>sendfile()</code> so you must disable it using <code>sendfile off</code>.</p>
</li>
</ol>
<h2 id="iperf-2"><a class="header" href="#iperf-2">iPerf 2</a></h2>
<h3 id="example-3"><a class="header" href="#example-3">Example</a></h3>
<pre><code class="language-yaml">general:
  stop_time: 10s

network:
  graph:
    type: 1_gbit_switch

hosts:
  server:
    network_node_id: 0
    processes:
    - path: iperf
      args: -s
      start_time: 0s
      expected_final_state: running
  client:
    network_node_id: 0
    processes:
    - path: iperf
      args: -c server -t 5
      start_time: 2s
</code></pre>
<pre><code class="language-bash">rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
</code></pre>
<h3 id="notes-3"><a class="header" href="#notes-3">Notes</a></h3>
<ol>
<li>You must use an iPerf 2 version &gt;= <code>2.1.1</code>. Older versions of iPerf have a
<a href="https://sourceforge.net/p/iperf2/code/ci/41bfc67a9d2c654c360953575ee5160ee4d798e7/tree/src/Reporter.c#l506">no-syscall busy loop</a> that is <a href="limitations.html#busy-loops">incompatible with Shadow</a>.</li>
</ol>
<h2 id="iperf-3"><a class="header" href="#iperf-3">iPerf 3</a></h2>
<h3 id="example-4"><a class="header" href="#example-4">Example</a></h3>
<pre><code class="language-yaml">general:
  stop_time: 10s
  model_unblocked_syscall_latency: true

network:
  graph:
    type: 1_gbit_switch

hosts:
  server:
    network_node_id: 0
    processes:
    - path: iperf3
      args: -s --bind 0.0.0.0
      start_time: 0s
      # Tell shadow to expect this process to still be running at the end of the
      # simulation.
      expected_final_state: running
  client:
    network_node_id: 0
    processes:
    - path: iperf3
      args: -c server -t 5
      start_time: 2s
</code></pre>
<pre><code class="language-bash">rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
</code></pre>
<h3 id="notes-4"><a class="header" href="#notes-4">Notes</a></h3>
<ol>
<li>
<p>By default iPerf 3 servers bind to an IPv6 address, but <a href="limitations.html#ipv6">Shadow doesn't
support IPv6</a>. Instead you need to bind the server to an IPv4 address such as
0.0.0.0.</p>
</li>
<li>
<p>The iPerf 3 server exits with a non-zero error code and the message "unable
to start listener for connections: Address already in use" after the client
disconnects. This is likely due to Shadow not supporting the <code>SO_REUSEADDR</code>
socket option.</p>
</li>
<li>
<p>iPerf 3 uses a <a href="limitations.html#busy-loops">busy loop</a> that is incompatible
with Shadow and will cause Shadow to deadlock. A workaround is to use the
<code>model_unblocked_syscall_latency</code> option.</p>
</li>
</ol>
<h2 id="jetty"><a class="header" href="#jetty">Jetty</a></h2>
<p>Running Jetty with the http module works, but we haven't tested anything more
than this.</p>
<h3 id="example-5"><a class="header" href="#example-5">Example</a></h3>
<h4 id="shadowyaml-1"><a class="header" href="#shadowyaml-1"><code>shadow.yaml</code></a></h4>
<pre><code class="language-yaml">general:
  stop_time: 10s

network:
  graph:
    type: 1_gbit_switch

hosts:
  server:
    network_node_id: 0
    processes:
    - path: java
      args: -jar ../../../jetty-home-12.0.12/start.jar jetty.http.port=80 --modules=http
      expected_final_state: running
  client1: &amp;client_host
    network_node_id: 0
    processes:
    - path: curl
      args: -s server
      start_time: 2s
  client2: *client_host
  client3: *client_host
</code></pre>
<pre><code class="language-bash">if [ ! -d jetty-home-12.0.12/ ]; then
  wget https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-home/12.0.12/jetty-home-12.0.12.zip
  echo "2dc2c60a8a3cb84df64134bed4df1c45598118e9a228604eaeb8b9b42d80bc07  jetty-home-12.0.12.zip" | sha256sum -c
  unzip -q jetty-home-12.0.12.zip &amp;&amp; rm jetty-home-12.0.12.zip
fi

rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
cat shadow.data/hosts/client1/curl.1000.stdout
</code></pre>
<h2 id="etcd-distributed-key-value-store"><a class="header" href="#etcd-distributed-key-value-store">etcd (distributed key-value store)</a></h2>
<h3 id="example-6"><a class="header" href="#example-6">Example</a></h3>
<p>Example for etcd version 3.3.x.</p>
<pre><code class="language-yaml">general:
  stop_time: 30s

network:
  graph:
    type: gml
    inline: |
      graph [
        node [
          id 0
          host_bandwidth_down "20 Mbit"
          host_bandwidth_up "20 Mbit"
        ]
        edge [
          source 0
          target 0
          latency "150 ms"
          packet_loss 0.01
        ]
      ]

hosts:
  server1:
    network_node_id: 0
    processes:
    - path: etcd
      args:
        --name server1
        --log-output=stdout
        --initial-cluster-token etcd-cluster-1
        --initial-cluster 'server1=http://server1:2380,server2=http://server2:2380,server3=http://server3:2380'
        --listen-client-urls http://0.0.0.0:2379
        --advertise-client-urls http://server1:2379
        --listen-peer-urls http://0.0.0.0:2380
        --initial-advertise-peer-urls http://server1:2380
      expected_final_state: running
    - path: etcdctl
      args: set my-key my-value
      start_time: 10s
  server2:
    network_node_id: 0
    processes:
    - path: etcd
      # each etcd peer must have a different start time
      # https://github.com/shadow/shadow/issues/2858
      start_time: 1ms
      args:
        --name server2
        --log-output=stdout
        --initial-cluster-token etcd-cluster-1
        --initial-cluster 'server1=http://server1:2380,server2=http://server2:2380,server3=http://server3:2380'
        --listen-client-urls http://0.0.0.0:2379
        --advertise-client-urls http://server2:2379
        --listen-peer-urls http://0.0.0.0:2380
        --initial-advertise-peer-urls http://server2:2380
      expected_final_state: running
    - path: etcdctl
      args: get my-key
      start_time: 12s
  server3:
    network_node_id: 0
    processes:
    - path: etcd
      start_time: 2ms
      args:
        --name server3
        --log-output=stdout
        --initial-cluster-token etcd-cluster-1
        --initial-cluster 'server1=http://server1:2380,server2=http://server2:2380,server3=http://server3:2380'
        --listen-client-urls http://0.0.0.0:2379
        --advertise-client-urls http://server3:2379
        --listen-peer-urls http://0.0.0.0:2380
        --initial-advertise-peer-urls http://server3:2380
      expected_final_state: running
    - path: etcdctl
      args: get my-key
      start_time: 12s
</code></pre>
<pre><code class="language-bash">rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
cat shadow.data/hosts/*/etcdctl.*.stdout
</code></pre>
<h3 id="notes-5"><a class="header" href="#notes-5">Notes</a></h3>
<ol>
<li>
<p>The etcd binary <a href="limitations.html#statically-linked-executables">must not be statically
linked</a>. You can build a
dynamically linked version by replacing <code>CGO_ENABLED=0</code> with <code>CGO_ENABLED=1</code> in
etcd's <code>scripts/build.sh</code> and <code>scripts/build_lib.sh</code> scripts. The etcd packages
included in the Debian and Ubuntu APT repositories are dynamically linked, so
they can be used directly.</p>
</li>
<li>
<p>Each etcd peer must be started at a different time since etcd uses the
current time as an RNG seed. See <a href="https://github.com/shadow/shadow/issues/2858">issue
#2858</a> for details.</p>
</li>
<li>
<p>If using etcd version greater than 3.5.4, you must build etcd from source
and comment out the <a href="https://github.com/etcd-io/etcd/blob/4485db379e80cc9955c3fdd6a776fc630c32cc36/client/pkg/transport/keepalive_listener.go#L68-L70">keepalive period
assignment</a>
as Shadow does not support this.</p>
</li>
</ol>
<h2 id="ctorrent-and-opentracker"><a class="header" href="#ctorrent-and-opentracker">CTorrent and opentracker</a></h2>
<h3 id="example-7"><a class="header" href="#example-7">Example</a></h3>
<pre><code class="language-yaml">general:
  stop_time: 60s

network:
  graph:
    type: 1_gbit_switch

hosts:
  tracker:
    network_node_id: 0
    processes:
    - path: opentracker
      # Tell shadow to expect this process to still be running at the end of the
      # simulation.
      expected_final_state: running
  uploader:
    network_node_id: 0
    processes:
    - path: cp
      args: ../../../foo .
      start_time: 10s
    # Create the torrent file
    - path: ctorrent
      args: -t foo -s example.torrent -u http://tracker:6969/announce
      start_time: 11s
    # Serve the torrent
    - path: ctorrent
      args: example.torrent
      start_time: 12s
      expected_final_state: running
  downloader1: &amp;downloader_host
    network_node_id: 0
    processes:
    # Download and share the torrent
    - path: ctorrent
      args: ../uploader/example.torrent
      start_time: 30s
      expected_final_state: running
  downloader2: *downloader_host
  downloader3: *downloader_host
  downloader4: *downloader_host
  downloader5: *downloader_host
</code></pre>
<pre><code class="language-bash">echo "bar" &gt; foo
rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
cat shadow.data/hosts/downloader1/foo
</code></pre>
<h3 id="notes-6"><a class="header" href="#notes-6">Notes</a></h3>
<ol>
<li>Shadow must be run as a non-root user since opentracker will attempt to drop
privileges if it detects that the effective user is root.</li>
</ol>
<h2 id="http-server"><a class="header" href="#http-server">http-server</a></h2>
<h3 id="example-8"><a class="header" href="#example-8">Example</a></h3>
<pre><code class="language-yaml">general:
  stop_time: 10s
  model_unblocked_syscall_latency: true

network:
  graph:
    type: 1_gbit_switch

hosts:
  server:
    network_node_id: 0
    processes:
    - path: node
      args: /usr/local/bin/http-server -p 80 -d
      start_time: 3s
      expected_final_state: running
  client:
    network_node_id: 0
    processes:
    - path: curl
      args: -s server
      start_time: 5s
</code></pre>
<pre><code class="language-bash">rm -rf shadow.data; shadow shadow.yaml &gt; shadow.log
cat shadow.data/hosts/client/curl.1000.stdout
</code></pre>
<h3 id="notes-7"><a class="header" href="#notes-7">Notes</a></h3>
<ol>
<li>Either the Node.js runtime or http-server uses a busy loop that is
incompatible with Shadow and will cause Shadow to deadlock.
<code>model_unblocked_syscall_latency</code> works around this (see
<a href="limitations.html#busy-loops">busy-loops</a>).</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributing"><a class="header" href="#contributing">Contributing</a></h1>
<p><strong>Summary:</strong></p>
<ul>
<li>contribute changes through <a href="https://github.com/shadow/shadow/pulls">pull requests</a></li>
<li>encouraged to use <a href="https://github.com/shadow/shadow/issues">issue</a> and <a href="https://github.com/shadow/shadow/discussions">discussion</a> posts to
notify us beforehand</li>
<li>changes must include <a href="writing_tests.html">tests</a>
<ul>
<li>System call tests (domain-specific and fuzz tests) (<strong>required</strong>)</li>
<li>Unit tests (preferred when possible)</li>
<li>Regression tests (as needed)</li>
<li>Application tests (as needed)</li>
</ul>
</li>
<li>pull requests should be easy to review</li>
<li>changes should be easy to maintain</li>
<li>new code should be written in <a href="https://www.rust-lang.org/">Rust</a></li>
<li>see our <a href="coding.html">coding guide and best practices</a> for Shadow</li>
</ul>
<p>New features, bug fixes, documentation changes, etc. can be submitted through a
<a href="https://github.com/shadow/shadow/pulls">GitHub pull request</a>. For large changes we encourage you to
post an <a href="https://github.com/shadow/shadow/issues">issue</a> or <a href="https://github.com/shadow/shadow/discussions">discussion</a> before submitting your
pull request so that you can make sure your changes fit well with the direction
of the project. This is especially applicable to large changes. This way you
won't spend time writing a pull request that we can't merge into Shadow. For
details about how to draft pull requests and respond to reviewer feedback, see
our <a href="pull_requests.html">additional documentation</a>.</p>
<p>All pull requests with new or changed features should contain tests to validate
that they work as expected and that they mirror similar behaviour in Linux. If
changes or additions are made that affect Shadow's system call support, the
pull request <strong>must</strong> also include <a href="writing_tests.html#system-call-tests">system call tests</a> that
test the new or changed behaviour. The more tests that you include, the more
confident that we'll be that the changes are correct, and the more likely it
will be that your changes can be merged. We know that tests aren't very
exciting to write, but Shadow relies heavily on tests to catch broken features
and discrepancies with Linux. For more information about writing tests for
Shadow, see our <a href="writing_tests.html">"Writing Tests"</a> documentation.</p>
<p>Shadow is a community-supported project and the maintainers might not have a
lot of time to review pull requests. Submitting pull requests with good
documentation, tests, clear commit messages, and concise changes will help the
maintainers with their reviews, and also help increase the likelihood that we
will be able to merge your changes.</p>
<p>A core principle of Shadow development is that the project should be easy to
maintain. This means that we try to reduce the number of dependencies when
possible, and when we need to add new dependencies they should be popular
well-used dependencies with community support. This also means that it is
unlikely that we will add new dependencies for non-rust packages (for example
distro packages). Shadow is supported on multiple Linux platforms with
different packaging styles (APT and DNF) and different package versions, so
distro packages are difficult to support and maintain across all of our
supported platforms.</p>
<p>The main Shadow code base currently consists of both Rust and C code. We have
been migrating our C code to Rust, but this migration is still in progress. All
new code should be written in Rust. This includes the main Shadow application,
the shim, and tests. Exceptions may be made for bug fixes or when the change is
small and is in existing C code.</p>
<p>While we've been moving Shadow to Rust, we've learned a lot and have changed
some designs. This means that the existing Shadow code is not always consistent
in the way that it designs features or uses third-party libraries. For best
practices and details about writing new code for Shadow, see our
<a href="coding.html">coding</a> documentation.</p>
<p>If you have any questions about contributing to Shadow, feel free to ask us by
making a new <a href="https://github.com/shadow/shadow/discussions">discussion</a> post.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="coding-style"><a class="header" href="#coding-style">Coding style</a></h1>
<h2 id="logging"><a class="header" href="#logging">Logging</a></h2>
<p>In Rust code, we use the <a href="https://docs.rs/log/latest/log/">log</a> framework for
logging. In C code we use a wrapper library that <em>also</em> uses Rust's
<a href="https://docs.rs/log/latest/log/">log</a> framework internally.</p>
<p>For general guidance on what levels to log at, see <a href="https://docs.rs/log/latest/log/enum.Level.html#variants">log::Level</a>.</p>
<p>Some shadow-specific log level policies:</p>
<ul>
<li>
<p>We reserve the <code>Error</code> level for situations in which the <code>shadow</code>
process as a whole will exit with a non-zero code. Conversely, when <code>shadow</code> exits
with a non-zero code, the user should be able to get some idea of what caused it by
looking at the <code>Error</code>-level log entries.</p>
</li>
<li>
<p><code>Warning</code> should be used for messages that ought to be checked by the user
before trusting the results of a simulation. For example, we use these in
syscall handlers when an unimplemented syscall or option is used, and shadow is
forced to return something like <code>ENOTSUP</code>, <code>EINVAL</code> or <code>ENOSYS</code>. In such cases
the simulation is able to continue, and <em>might</em> still be representative of what
would happen on a real Linux system; e.g. libc will often fall back to an older
syscall, resulting in minimal impact on the simulated behavior of the managed
process.</p>
</li>
</ul>
<h2 id="clang-format"><a class="header" href="#clang-format">Clang-format</a></h2>
<p>Our C code formatting style is defined in our
<a href="https://clang.llvm.org/docs/ClangFormat.html">clang-format</a> <a href="../.clang-format">configuration
file</a>. We try to avoid mass re-formatting, but generally any
lines you modify should be reformatted using <code>clang-format</code>.</p>
<p>To add Ctrl-k as a "format region" in visual and select modes of vim, add the
following to your .vimrc:</p>
<pre><code>vmap &lt;C-K&gt; :py3f /usr/share/vim/addons/syntax/clang-format.py&lt;cr&gt;
</code></pre>
<p>Alternatively you can use the
<a href="https://github.com/llvm-mirror/clang/blob/master/tools/clang-format/git-clang-format">git-clang-format</a>
tool on the command-line to modify the lines touched by your commits.</p>
<h3 id="rustfmt"><a class="header" href="#rustfmt">Rustfmt</a></h3>
<p>To format your Rust code, run <code>cargo fmt</code> in the <code>src</code> directory.</p>
<pre><code class="language-bash">(cd src &amp;&amp; cargo fmt)
</code></pre>
<h3 id="clippy"><a class="header" href="#clippy">Clippy</a></h3>
<p>We use <a href="https://doc.rust-lang.org/stable/clippy/index.html">Clippy</a> to help
detect errors and non-idiomatic Rust code. You can run <code>clippy</code> locally with:</p>
<pre><code class="language-bash">(cd src &amp;&amp; cargo clippy)
</code></pre>
<h2 id="including-headers"><a class="header" href="#including-headers">Including headers</a></h2>
<h3 id="which-headers-to-include"><a class="header" href="#which-headers-to-include">Which headers to include</a></h3>
<p>Every source and header file should directly include the headers that export
all referenced symbols and macros.</p>
<p>In a C file, includes should be broken into blocks, with the includes sorted
alphabetically within each block. The blocks should occur in this order:</p>
<ul>
<li>The C file's corresponding header; e.g. <code>foo.h</code> for <code>foo.c</code>. This enforces
that the header is self-contained; i.e. doesn't depend on other headers to
be included before it.</li>
<li>System headers are included next to minimize unintentionally exposing any
macros we define to them.</li>
<li>Any other necessary internal headers.</li>
</ul>
<p>This style is loosely based on that used in
<a href="https://wiki.gnome.org/Projects/GTK/BestPractices/GlibIncludes">glib</a> and
supported by the <a href="https://include-what-you-use.org/">include what you use</a>
tool.</p>
<h3 id="inclusion-style"><a class="header" href="#inclusion-style">Inclusion style</a></h3>
<p>Headers included from within the project should use quote-includes, and should
use paths relative to <code>src/</code>. e.g. <code>#include "main/utility/byte_queue.h"</code>, not
<code>#include "byte_queue.h"</code> (even from within the same directory), and not
<code>#include &lt;main/utility/byte_queue.h&gt;</code>.</p>
<p>Headers included external to this repository should use angle-bracket includes.
e.g. <code>#include &lt;glib.h&gt;</code>, not <code>#include "glib.h"</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="writing-tests"><a class="header" href="#writing-tests">Writing Tests</a></h1>
<p>Tests for Shadow generally fall into four categories:</p>
<ul>
<li>system call tests</li>
<li>regression tests</li>
<li>application tests</li>
<li>unit tests</li>
</ul>
<p>Some of these tests may be marked as "extra" tests, which means they are not
run by default.</p>
<h2 id="system-call-tests"><a class="header" href="#system-call-tests">System call tests</a></h2>
<p>Shadow executes real unmodified applications and co-opts them by intercepting
and interposing at the system call API. This means that Shadow must try to
emulate Linux system calls. Shadow doesn't always need to emulate every system
call exactly as Linux does, but it's usually good to try to emulate Linux as
closely as possible. When Shadow deviates from Linux behaviour, Shadow is less
likely to accurately represent real-world behaviour in its simulation.</p>
<p>When writing new system call handlers or modifying the behaviour of existing
ones, it's important to write tests that verify the correctness of the new
behaviour. These system call tests are <strong>required</strong> in pull requests that add
to or modify the behaviour of Shadow's system calls. Usually this means that
tests are written which execute the system call with a variety of arguments,
and we verify that the system call returns the same values in both Linux and
Shadow.</p>
<p>These tests fall into two categories: domain-specific system call tests and
fuzzing tests. The <a href="writing_tests.html#domain-specific-system-call-tests">domain-specific tests</a> should test the system
call under a variety of typical use cases, as well as some edge cases (for
example passing NULL pointers, negative lengths, etc). The <a href="writing_tests.html#fuzz-tests">fuzz
tests</a> should test many various combinations of the possible
argument values. These two types of tests are discussed further below.</p>
<p>Our existing tests are not always consistent in how the tests are organized or
designed, so you don't need to follow the exact same design as other tests in
the Shadow repository. If you're adding new tests to an existing file, you
should try to write the tests in a similar style to the existing tests.</p>
<p>These tests typically use the <a href="https://docs.rs/libc/latest/libc/">libc</a> library to test the system calls;
for example <code>libc::listen(fd, 10)</code>. For the most part the tests assume that the
libc system call wrappers are the same as the kernel system calls themselves,
but this is not always the case. Sometimes they differ and you might want to
make the system call directly (for example the glibc <code>fork()</code> system call
wrapper usually makes a <code>clone</code> system call, not a <code>fork</code> system call), or
there might not be a libc wrapper for the system call that you wish to test
(for example <code>set_tid_address</code>). In this case you probably want to use the
<a href="https://shadow.github.io/docs/rust/linux_api/">linux-api</a> library which makes the system call directly without
using a third-party library like glibc. The linux-api library only implements a
handful of system calls, and we've been adding more as we need them. You may
need to add support for the system call you wish to test to linux-api.</p>
<p>These tests are run emulated within Shadow and natively outside of Shadow. This
is done using the CMake <code>add_linux_tests</code> and <code>add_shadow_tests</code> macros. The
tests are built by Cargo and then run by CMake. For example the <code>listen</code> tests
use:</p>
<pre><code class="language-cmake">add_linux_tests(BASENAME listen COMMAND sh -c "../../../target/debug/test_listen --libc-passing")
add_shadow_tests(BASENAME listen)
</code></pre>
<p>which results in the CMake tests:</p>
<pre><code class="language-text">1/2 Test #110: listen-shadow ....................   Passed    0.56 sec
2/2 Test #109: listen-linux .....................   Passed   10.12 sec
</code></pre>
<h3 id="domain-specific-system-call-tests"><a class="header" href="#domain-specific-system-call-tests">Domain-specific system call tests</a></h3>
<p>Here is an example of an existing test for the
<a href="https://man7.org/linux/man-pages/man2/listen.2.html"><code>listen</code></a> system call:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Test listen using a backlog of 0.
fn test_zero_backlog(
    domain: libc::c_int,
    sock_type: libc::c_int,
    flag: libc::c_int,
    bind: Option&lt;SockAddr&gt;,
) -&gt; Result&lt;(), String&gt; {
    let fd = unsafe { libc::socket(domain, sock_type | flag, 0) };
    assert!(fd &gt;= 0);

    if let Some(address) = bind {
        bind_fd(fd, address);
    }

    let args = ListenArguments { fd, backlog: 0 };

    let expected_errno = match (domain, sock_type, bind) {
        (libc::AF_INET, libc::SOCK_STREAM, _) =&gt; None,
        (libc::AF_UNIX, libc::SOCK_STREAM | libc::SOCK_SEQPACKET, Some(_)) =&gt; None,
        (libc::AF_UNIX, libc::SOCK_STREAM | libc::SOCK_SEQPACKET, None) =&gt; Some(libc::EINVAL),
        (_, libc::SOCK_DGRAM, _) =&gt; Some(libc::EOPNOTSUPP),
        _ =&gt; unimplemented!(),
    };

    test_utils::run_and_close_fds(&amp;[fd], || check_listen_call(&amp;args, expected_errno))
}
<span class="boring">}</span></code></pre></pre>
<p>There are many <code>listen</code> tests including the one above, such as
<code>test_zero_backlog</code>, <code>test_negative_backlog</code>, <code>test_large_backlog</code>,
<code>test_listen_twice</code>, <code>test_reduced_backlog</code>, and more.</p>
<h3 id="fuzz-tests"><a class="header" href="#fuzz-tests">Fuzz tests</a></h3>
<p>"Fuzz"-style testing is another way we test syscalls: they use some <a href="https://github.com/shadow/shadow/blob/main/src/test/test_utils.rs">support
code</a> to test many various combinations of the possible argument
values expected by a syscall, and verify that the return value for each
combination of arguments is the same as what Linux returns. Because the
developer usually writes these tests to cover most or all possible argument
combinations, it ensures that Shadow's emulation of the syscall is highly
accurate.</p>
<p>Fuzz tests can be a bit trickier to write, especially for more complicated
syscalls, and sometimes they don't make sense (e.g., when testing what happens
when trying to <code>connect()</code> to a TCP server with a full accept queue). They
often help us find inconsistent behavior between Shadow and Linux and help us
make Shadow more accurate, so we prefer that fuzz tests are included with pull
requests when possible.</p>
<p>There are some good examples of writing fuzz tests in our time-related test
code in <a href="https://github.com/shadow/shadow/tree/main/src/test/time"><code>src/test/time</code></a>. For example, the
<a href="https://github.com/shadow/shadow/tree/main/src/test/time/clock_nanosleep/test_clock_nanosleep.rs"><code>clock_nanosleep</code></a> test demonstrates how to test the syscall
with all combinations of its arguments with both valid and invalid values.</p>
<h2 id="unit-tests"><a class="header" href="#unit-tests">Unit tests</a></h2>
<p>Shadow supports unit tests for rust code. These can be written as standard rust
unit tests. These tests run natively and not under Shadow, but they are also
run under <a href="https://github.com/rust-lang/miri">Miri</a> and <a href="https://github.com/tokio-rs/loom">Loom</a> as "extra" tests.</p>
<p>For example see the <a href="https://github.com/shadow/shadow/blob/main/src/main/utility/interval_map.rs"><code>IntervalMap</code></a> tests.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;

    // ...

    #[test]
    fn test_insert_into_empty() {
        let mut m = IntervalMap::new();
        insert_and_validate(&amp;mut m, 10..20, "x", &amp;[], &amp;[(10..20, "x")]);
    }

    // ...
}
<span class="boring">}</span></code></pre></pre>
<pre><code class="language-text">1/1 Test #1: rust-unit-tests ..................   Passed  149.52 sec
</code></pre>
<h2 id="regression-tests"><a class="header" href="#regression-tests">Regression tests</a></h2>
<p>Sometimes it's useful to write a regression test that doesn't belong under any
specific system call tests. These tests can be written like the system call
tests above, but are stored in the <a href="https://github.com/shadow/shadow/tree/main/src/test/regression"><code>src/test/regression/</code></a>
directory.</p>
<h2 id="application-tests"><a class="header" href="#application-tests">Application tests</a></h2>
<p>It's often useful to test that applications behave correctly in Shadow. These
tests do not replace the need for the system call tests above, but can
complement them. For example we have <a href="https://github.com/shadow/shadow/tree/main/src/test/tor">tor</a> and <a href="https://github.com/shadow/shadow/tree/main/src/test/tgen">tgen</a>
tests. These help prevent regressions where we accidentally break Tor
behaviour.</p>
<p>We also run our <a href="https://github.com/shadow/shadow/tree/main/examples">examples</a> as tests. These examples include those in
our documentation (for example see the <a href="https://github.com/shadow/shadow/blob/main/docs/getting_started_basic.md#configuring-the-simulation">"getting started"
example</a>) as well as other application examples.</p>
<h2 id="extra-tests"><a class="header" href="#extra-tests">Extra tests</a></h2>
<p>Any of the tests above may be configured as an "extra" test. These tests are
not run by default and require that Shadow is built and tested using the
<code>--extra</code> flag.</p>
<pre><code class="language-bash">./setup build --test --extra
./setup test --extra
</code></pre>
<p>These are usually tests that require extra dependencies, tests which take a
long time to build or run, or tests which might be difficult to maintain. These
tests may be removed at any time if they become difficult to maintain or they
update to require features that Shadow doesn't or can't support. An example
could be if an application is using epoll, but then updates to use io_uring
which Shadow doesn't support (and would take a lot of effort to support), we
would need to remove the test.</p>
<p>Extra tests currently run in the CI environment but only under a single
platform, so they're not as well tested as non-"extra" tests.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pull-requests-prs"><a class="header" href="#pull-requests-prs">Pull requests (PRs)</a></h1>
<h2 id="clean-commits"><a class="header" href="#clean-commits">Clean commits</a></h2>
<p>Ideally, every commit in history of the <code>main</code> branch should:</p>
<ul>
<li>Be a focused, self-contained change.</li>
<li>Have a commit message that summarizes the change and explains <em>why</em> the change
is being made, if not self-evident.</li>
<li>Build (<code>./setup build --test</code>).</li>
<li>Pass tests (<code>./setup test</code>).</li>
</ul>
<h2 id="drafting-a-pr"><a class="header" href="#drafting-a-pr">Drafting a PR</a></h2>
<p>PRs should be split into smaller, more focused, changes when feasible.
However, we also want to avoid polluting the history with commits that don't
build or pass tests, or commits within a single PR that fix a mistake earlier in
the PR. While iterating on the PR, the <code>--fixup</code> and
<code>--squash</code> flags are useful for committing changes that should ultimately be
merged with one of the earlier commits.</p>
<p>When creating a pull request, we suggest you first create it as a
<a href="https://github.blog/2019-02-14-introducing-draft-pull-requests/">draft</a>.  This
will still trigger our continuous-integration checks, and give you a chance
resolve any issues with those (i.e. broken tests) before requesting review.</p>
<p>Once done iterating, first consider using <code>git rebase -i --autosquash</code> to clean
up your commit history, and then force pushing to update your PR.  Finally, take
the pull request out of draft mode to signal that you're ready for review.</p>
<h2 id="responding-to-review-feedback"><a class="header" href="#responding-to-review-feedback">Responding to review feedback</a></h2>
<p><em>During</em> PR review, please do not rebase or force-push, since this makes it
difficult to see what's changed between rounds of review. Consider using
<code>--fixup</code> and <code>--squash</code> for commits responding to review feedback, so that they
can be appropriately squashed before the final merge. <a href="https://github.com/torbiak/git-autofixup/">git autofixup</a> can also be useful for generating
<code>--fixup</code> commits.</p>
<h2 id="merging"><a class="header" href="#merging">Merging</a></h2>
<p>When the PR is ready to be merged, the reviewer might ask you to <code>git rebase</code>
and force push to clean up history, or might do it themselves.</p>
<p>For the maintainer doing the merge:</p>
<p>If the PR is relatively small, or if it's not worth the effort of rewriting
history into clean commits, use the "squash and merge" strategy.</p>
<p>If the individual commits appear to be useful to keep around in our history,
instead use the "create a merge commit" strategy. There's no need to review
every individual commit when using this strategy, but if the intermediate
commits are obviously low quality consider using the "squash and merge strategy"
instead. Note that since this strategy creates a merge commit, we can still
later identify and filter out the intermediate commits if desired, e.g. with
<code>git log --first-parent main</code>.</p>
<p>We've disabled the "Rebase and merge" option, since it does a fast-forward
merge, which makes the intermediate commits indistingishuable from the validated
and reviewed final state of the PR.</p>
<p>A common task is to rebase a PR on main so that it is up to date, perhaps fix
some conflicts or add some changes to the PR, and then push the updated branch
to test it in the CI before merging. Suppose a user <code>contributor</code> submitted a
branch <code>bugfix</code> as PR <code>1234</code>, and has allowed the maintainers to update the PR.
Then you could fetch the branch to perform work on the PR locally:</p>
<pre><code>git fetch origin pull/1234/head:pr-1234
git checkout pr-1234
git rebase main
&lt;fix conflicts or commit other changes&gt;
git push -f git@github.com:contributor/shadow.git pr-1234:bugfix
git checkout main
git branch -D pr-1234
</code></pre>
<p>If it passes the tests, you can merge the PR in the Github interface as usual.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="coding"><a class="header" href="#coding">Coding</a></h1>
<h2 id="building-the-guide"><a class="header" href="#building-the-guide">Building the guide</a></h2>
<pre><code class="language-bash">cargo install mdbook
(cd mdbook &amp;&amp; mdbook build)
firefox build/guide/index.html
</code></pre>
<h2 id="building-the-rust-docs"><a class="header" href="#building-the-rust-docs">Building the rust docs</a></h2>
<pre><code class="language-bash">(cd src &amp;&amp; cargo doc --workspace --exclude shadow-tests)
</code></pre>
<h2 id="generating-compiler-command-database"><a class="header" href="#generating-compiler-command-database">Generating compiler command database</a></h2>
<p>Many tools benefit from a <a href="https://clangd.llvm.org/design/compile-commands">compiler command
database</a>, conventionally in a
file called <code>compile_commands.json</code>. If shadow's <code>setup</code> script finds the
<a href="https://github.com/rizsotto/Bear">bear</a> tool on your <code>PATH</code>, it will
automatically use it to create and update <code>build/compile_commands.json</code> when
running <code>setup build</code>.</p>
<h2 id="files-and-descriptors"><a class="header" href="#files-and-descriptors">Files and descriptors</a></h2>
<img class="color-adapting-image" style="width: 100%;" src="assets/files-and-descriptors.svg">
<p>Shadow currently has two ways of simulating descriptors. The first is
<a href="https://github.com/shadow/shadow/blob/ff671ffdf038597334ae467c56fe774c40b7864a/src/main/host/descriptor/descriptor_types.h#L48-L60"><code>LegacyDescriptor</code></a> which is written in C and is used for
most descriptor/file types (IP sockets, epoll, files, etc). With this type, the
epoll file / posix description and its descriptor live in the same object. The
second way of simulating descriptors is in Rust, where we have a <a href="https://shadow.github.io/docs/rust/shadow_rs/host/descriptor/enum.File.html"><code>File</code></a>
type that can be referenced by many <a href="https://shadow.github.io/docs/rust/shadow_rs/host/descriptor/struct.Descriptor.html"><code>Descriptor</code></a> objects.  This
allows us to easily implement <a href="https://shadow.github.io/docs/rust/shadow_rs/host/descriptor/struct.Descriptor.html#method.dup"><code>dup()</code></a> for descriptors implemented with
this new code. Our plan is to move existing legacy descriptors over to these
new Rust file types.</p>
<h2 id="platform-libc-and-linux-crates"><a class="header" href="#platform-libc-and-linux-crates">Platform (libc and Linux) crates</a></h2>
<p>We use several Rust crates for accessing platform functionality and definitions.
Roughly from lowest-level to highest-level:</p>
<ul>
<li>
<p>Our <a href="https://github.com/shadow/shadow/tree/main/src/lib/linux-api"><code>linux-api</code></a>
crate provides fairly low-level bindings over the Linux kernel headers, and a
few <code>nix</code>-style higher-level wrappers. It does not depend on <code>std</code> or <code>libc</code>.
It also re-exports these definitions as a C library that can be used without
creating conflicts with libc headers or linux system headers.
Use this when working with the syscall ABI (such as when implementing syscall
handlers), for internal parameters and state that are likely to interact with
the syscall ABI (such as file states), and for making syscalls when none of the
higher-level crates are suitable (see below).</p>
</li>
<li>
<p><a href="https://docs.rs/libc/latest/libc/"><code>libc</code></a> provides fairly low-level bindings
of system libc standard headers. If you need syscall-level ABI-compatibility,
use <code>linux-api</code> instead. If you don't, prefer one of the higher-level crates.</p>
</li>
<li>
<p><a href="https://docs.rs/nix/latest/nix/"><code>nix</code></a> provides a safer and more Rust-idiomatic
layer on top of the <code>libc</code> crate, as well as adapters for underlying <code>libc</code> definitions.
There's currently a lot of usage of this in Shadow, but we're working on moving
away from it (see <a href="https://github.com/shadow/shadow/issues/3345">#3345</a>).
In most scenarios, one of the other crates mentioned here is a more appropriate choice.</p>
</li>
<li>
<p><a href="https://docs.rs/rustix/latest/rustix/"><code>rustix</code></a> provides a similar API to <code>nix</code>, but
can be configured not to depend on <code>std</code> or <code>libc</code>. This is useful in code that's linked
into Shadow's shim, where we don't want to depend on <code>std</code> or <code>libc</code>.</p>
</li>
<li>
<p>Rust's <a href="https://doc.rust-lang.org/std/"><code>std</code></a> crate provides, well, the standard
way of interacting with the platform, in a portable and Rust-idiomatic way. This is
generally the right choice for code that <em>doesn't</em> run in Shadow's shim, in places
we're not concerned about the precise syscalls that get executed.</p>
</li>
</ul>
<p>When choosing which one to use:</p>
<ul>
<li>
<p>For code that will be linked into shadow's
<a href="https://github.com/shadow/shadow/tree/main/src/lib/shim">shim</a>, prefer
<code>rustix</code>. In cases where <code>rustix</code> doesn't provide the desired
functionality, or in C code, or when we need precise control over what
syscall is made with what parameters, use <code>linux-api</code>.</p>
<p>We want to minimize, and ideally eliminate, usage of <code>libc</code> from the shim. <code>libc</code> has
global state that can easily become corrupted when we use it from the shim,
which is <code>LD_PRELOAD</code>ed into managed programs. This is especially because
much of the shim executes in the context of <code>SIGSYS</code> signal handlers, meaning we might already
be in a non-reentrant, non-<a href="https://man7.org/linux/man-pages/man7/signal-safety.7.html">async-signal-safe</a> libc function higher in the stack. See also <a href="https://github.com/shadow/shadow/milestone/54">https://github.com/shadow/shadow/milestone/54</a>.</p>
</li>
<li>
<p>For shadow's syscall handler implementations, prefer <code>linux-api</code>.</p>
<p>Since we are intercepting and implementing at the syscall level, the interface
we are implementing is the Linux syscall ABI interface. Therefore we should
be careful to use Linux's definitions for the parameters and return values.
While types and constants in libc are <em>often</em> equivalent to kernel types and
constants with the same names, there are many known cases where they
aren't, and in general there's no guarantee even that one that is consistent
today will remain consistent tomorrow. See also
<a href="https://github.com/shadow/shadow/issues/3007">https://github.com/shadow/shadow/issues/3007</a>.</p>
<p>This also applies when implementing a syscall by delegating to the host
system.  For example suppose we implement a <code>fcntl</code> syscall by by making a
native <code>fcntl</code> syscall on the native file descriptor. Making the syscall
directly is the most straightforward way to "pass through" exactly the
original intended semantics. If we use a higher level interface, even
<code>libc</code>, we have to be careful about translating the parameters and return
values back and forth between the two different API layers.</p>
</li>
<li>
<p>For code that runs in the shadow process, where we are acting as a "normal" program
that wants to interact with the kernel, generally prefer the highest-level
interface that provides the necessary functionality. e.g. when creating worker
threads in Rust, we generally use <code>std::thread</code>; there's no reason to use one of the lower
level crates. Occasionally we need some functionality not provided in <code>std</code> though, in which case it makes sense to drop down to one of the lower level crates.</p>
</li>
<li>
<p>In tests, any of the above can make sense. In places we're specifically trying
to test shadow's emulation of some functionality, making direct syscalls,
e.g. with the <code>linux-api</code> crate or <code>libc</code>'s <code>syscall</code> function, is the most
direct and precise approach. On the other hand, we often want to test higher
level interfaces as a form of integration testing, since those are more
typically what managed programs use.  We usually focus on testing at the
<code>libc</code> interface, since most managed programs use that interface, and it's
low-level enough to be able to control and understand what's happening at
the syscall level. For incidental system functionality in tests (e.g.
creating a temp file, in a test that isn't specifically trying to test that
functionality) it usually makes sense to use whatever interface is most
idiomatic and convenient.</p>
</li>
</ul>
<h2 id="denyunsafe_op_in_unsafe_fn"><a class="header" href="#denyunsafe_op_in_unsafe_fn"><code>deny(unsafe_op_in_unsafe_fn)</code></a></h2>
<p>All crates should use <code>#![deny(unsafe_op_in_unsafe_fn)]</code>. When adding a new
crate, remember to add this to the <code>lib.rs</code> or <code>main.rs</code>.</p>
<p>[https://github.com/rust-lang/rfcs/blob/master/text/2585-unsafe-block-in-unsafe-fn.md]</p>
<blockquote>
<p>No longer treat the body of an unsafe fn as being an unsafe block. To avoid a
breaking change, this is a warning now and may become an error in a future
edition.</p>
</blockquote>
<p>This helps make it clearer where "unsafe" code is being used and can make
reviewing code easier.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debugging"><a class="header" href="#debugging">Debugging</a></h1>
<h2 id="debugging-the-shadow-process"><a class="header" href="#debugging-the-shadow-process">Debugging the Shadow process</a></h2>
<p>Shadow is currently built with debugging symbols in both debug and release
builds, though it may be easier to debug a debug build (generated by passing
the <code>--debug</code> flag to <code>setup build</code>).</p>
<p>Shadow can be run under GDB by prepending <code>gdb --args</code> to its command-line.
e.g.:</p>
<pre><code>gdb --args shadow shadow.yaml
</code></pre>
<p>An alternative is to run Shadow with the <code>--gdb</code> flag, which will pause shadow
after startup and print its PID. You can then simply attach GDB to Shadow in a
new terminal and continue the experiment.</p>
<p>Example:</p>
<pre><code># terminal 1
# shadow will print its PID and pause
$ shadow --gdb shadow.yaml &gt; shadow.log
** Starting Shadow
** Pausing with SIGTSTP to enable debugger attachment (pid 1234)

# terminal 2
$ gdb --pid=1234
&gt; continue
</code></pre>
<h3 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h3>
<p>If when loading the shadow binary in gdb you see the error:</p>
<pre><code class="language-text">Reading symbols from /my/binary...
Dwarf Error: DW_FORM_strx1 found in non-DWO CU [in module /my/binary]
(No debugging symbols found in /my/binary)
</code></pre>
<p>It's likely that the version of Rust that you're building Shadow with is
incompatible with your version of GDB. You can read more at
<a href="https://github.com/rust-lang/rust/issues/98746#issuecomment-1224954019">Rust issue #98746</a>.</p>
<h2 id="debugging-managed-processes"><a class="header" href="#debugging-managed-processes">Debugging managed processes</a></h2>
<p>A simulation's managed processes are implemented as native OS processes, with
their syscalls interposed by Shadow. Since they are native processes, many
normal tools for inspecting native processes can be used on those as well. e.g.
<code>top</code> will show how much CPU and memory they are using.</p>
<h3 id="generating-a-core-file"><a class="header" href="#generating-a-core-file">Generating a core file</a></h3>
<p>If a managed process is crashing, it is sometimes easiest to let the native
process to generate a core file, and then use GDB to inspect it afterwards.</p>
<pre><code># Enable core dumps.
ulimit -c unlimited

# Ensure core dumps are written to a file.
# e.g. this is sometimes needed in Ubuntu to override the default behavior of
# piping the core file to the system crash handler.
echo core | sudo tee /proc/sys/kernel/core_pattern

# Run the simulation in which a process is crashing.
shadow shadow.yaml

# Tell gdb to inspect the core file. From within gdb you'll be able to
# inspect the state of the process when it was killed.
gdb &lt;path-to-process-executable&gt; &lt;path-to-core-file&gt;
</code></pre>
<h3 id="attaching-with-gdb"><a class="header" href="#attaching-with-gdb">Attaching with GDB</a></h3>
<p>You can attach GDB directly to the managed process. To make this easier you can
use the <code>--debug-hosts</code> option to pause Shadow after it launches each managed
process on the given hosts. Shadow will print the native process' PID before
stopping. For example, <code>--debug-hosts client,server</code> will pause Shadow after
launching any managed processees on hosts "client" and "server". This allows
you to attach GDB directly to those managed processes before resuming Shadow.</p>
<pre><code># terminal 1
$ shadow --debug-hosts client,server shadow.yaml &gt; shadow.log
** Starting Shadow
** Pausing with SIGTSTP to enable debugger attachment to managed process 'server.nginx.1000' (pid 1234)
** If running Shadow under Bash, resume Shadow by pressing Ctrl-Z to background this task and then typing "fg".
** (If you wish to kill Shadow, type "kill %%" instead.)
** If running Shadow under GDB, resume Shadow by typing "signal SIGCONT".

# terminal 2
$ gdb --pid=1234
</code></pre>
<h3 id="debugging-with-gdb"><a class="header" href="#debugging-with-gdb">Debugging with GDB</a></h3>
<p>In managed processes, Shadow uses <code>SIGSYS</code> and <code>SIGSEGV</code> to intercept system
calls and some CPU instructions. By default, GDB stops every time these signals
are raised. In most cases you'll want to override this behavior to silently
continue executing instead:</p>
<pre><code>(gdb) handle SIGSYS noprint
(gdb) handle SIGSEGV noprint
</code></pre>
<p>Once you have reached a point of interest, it's often useful to look at the
backtrace for the current stack:</p>
<pre><code>(gdb) bt
</code></pre>
<p>In multi-threaded applications, you can get a backtrace for all stacks:</p>
<pre><code>(gdb) thread apply all bt
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="profiling-1"><a class="header" href="#profiling-1">Profiling</a></h1>
<p>Profiling can be useful for improving the performance of experiments, either as
improvements to the implementation of Shadow itself, or in altering the
configuration of the experiments you are running.</p>
<h2 id="profiling-with-tophtop-1"><a class="header" href="#profiling-with-tophtop-1">Profiling with <code>top</code>/<code>htop</code></a></h2>
<p>Tools like <code>top</code> and <code>htop</code> will give good first-order approximations for what
Shadow is doing. While they can only give system-wide to thread-level
granularity, this can often still tell you important details such as whether
Shadow, the simulated processes, or the kernel are consuming memory and
processor cycles. E.g., if you're running into memory constraints, the <code>RES</code> or
<code>MEM</code> column of these tools can tell you where to start looking for ways to
address that. If execution time is too long, sorting by <code>CPU</code> or <code>TIME</code> can
provide insight into where that time is being spent.</p>
<p>One limitation to note is that Shadow relies on spinlocks in barriers for some
of its operation. Especially when running with many threads, these spinlocks
will show as consuming most of the CPU anytime the simulation is bottlenecked
on few simulated processes. Telling when this is happening can be difficult in
these tools, because no symbol information is available.</p>
<h2 id="profiling-with-perf-1"><a class="header" href="#profiling-with-perf-1">Profiling with <code>perf</code></a></h2>
<p>The <code>perf</code> tool is a powerful interface to the Linux kernel's performance
counter subsystem. See <code>man perf</code> or <a href="https://perf.wiki.kernel.org/index.php/Tutorial">the perf
wiki</a> for full details on how
to use it, but some highlights most relevant to Shadow execution time are given
here.</p>
<p>Regardless of how you are using <code>perf</code>, the aforementioned complication of
spinlocks in Shadow apply. Namely, when there is any bottleneck on the barrier,
the symbols associated with the spinlocks will dominate the sample
counts. Improving the performance of the spinlocks will not improve the
performance of the experiment, but improving the performance of whatever is
causing the bottleneck (likely something towards the top of non-spinlock
symbols) can.</p>
<h3 id="perf-top-1"><a class="header" href="#perf-top-1"><code>perf top</code></a></h3>
<p>The <code>perf top</code> command will likely be the most practical mode of
<code>perf</code> for profiling all parts of a Shadow experiment. It requires one
of: root access, appropriately set up Linux capabilities, or a system
configured to allow performance monitoring (similar to attaching to
processes with <code>gdb</code>), so isn't always available, but is very simple
when it is. The interface is similar to <code>top</code>'s, but provides
information on the granularity of symbols, across the entire
system. This means you will be able to tell which specific functions
in Shadow, the simulated processes, and the kernel are consuming CPU
time.</p>
<p>When <code>perf top</code> can't find symbol information for a process, it will display
the offset of the instruction as hex instead. (Note this means it will be
ranked by instruction, rather than the entire function.) If you know where the
respective executable or shared object file is, you can look up the name of the
symbol for that instruction's function by opening the file with <code>gdb</code> and
running <code>info symbol [ADDRESS]</code>. If <code>gdb</code> can't find the symbols either, you
can look it up manually using <code>readelf -s</code> and finding the symbol with the
largest address smaller than the offset you are looking for (note that
<code>readelf</code> does not output the symbols in order of address; you can pipe the
output to <code>awk '{$1=""; print $0}' | sort</code> to get a sorted list).</p>
<p>Details on more options (e.g., for filtering the sampled CPUs or processes) can
be found in <code>man perf top</code>.</p>
<h3 id="perf-record-1"><a class="header" href="#perf-record-1"><code>perf record</code></a></h3>
<p>If you know which particular process you wish to profile, <code>perf record</code> can
give far greater detail than other options. To use it for Shadow, either run it
when starting Shadow:</p>
<pre><code class="language-bash">perf record shadow shadow.config.yaml &gt; shadow.log
</code></pre>
<p>Or, attach to a running Shadow process:</p>
<pre><code class="language-bash">perf record -p &lt;PID&gt;
</code></pre>
<p>Attaching to a process requires similar permissions as <code>perf top</code>, but can be
used to profile any process, including the simulated processes launched by
Shadow.</p>
<p>The <code>perf record</code> process will write a <code>perf.data</code> file when you press Ctrl-c,
or Shadow ends. You can then analyze the report:</p>
<pre><code class="language-bash">perf report
</code></pre>
<p>More details are available in <code>man perf record</code> and <code>man perf report</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-for-nondeterminism"><a class="header" href="#testing-for-nondeterminism">Testing for Nondeterminism</a></h1>
<p>If you run Shadow twice with the same seed (the <code>-s</code> or <code>--seed</code> command line
options), then it <em>should</em> produce deterministic results (it's a bug if it
doesn't).</p>
<p>If you find non-deterministic behavior in your Shadow experiment, please
consider helping to diagnose the problem by opening a <a href="https://github.com/shadow/shadow/issues/new">new
issue</a>.</p>
<h2 id="comparing-strace-output-experimental"><a class="header" href="#comparing-strace-output-experimental">Comparing strace output (experimental)</a></h2>
<p>Shadow has an experimental feature for logging most system calls made by the
managed process in a format similar to the strace tool. You can enable this
with the <a href="shadow_config_spec.html#experimentalstrace_logging_mode"><code>strace_logging_mode</code> option</a>. You can compare
this strace log from two simulations to look for non-deterministic behaviour.
To avoid capturing memory addresses and uninitialized memory in the log, you
should use the <code>deterministic</code> logging mode.</p>
<p>For example, after running two simulations with <code>--strace-logging-mode deterministic</code> where the results are in the <code>shadow.data.1</code> and <code>shadow.data.2</code>
directories, you could run something like the following bash script:</p>
<pre><code class="language-bash">#!/bin/bash

found_difference=0

for SUFFIX in \
    hosts/fileserver/tgen.1000.strace \
    hosts/client/tgen.1000.strace
do
    diff --brief shadow.data.1/${SUFFIX} shadow.data.2/${SUFFIX}
    exit_code=$?

    if (($exit_code != 0)); then
      found_difference=1
    fi
done

if (($found_difference == 1)); then
  echo -e "\033[0;31mDetected difference in output (Shadow may be non-deterministic).\033[0m"
else
  echo -e "\033[0;32mDid not detect difference in Shadow output (Shadow may be deterministic).\033[0m"
fi
</code></pre>
<h2 id="comparing-application-output"><a class="header" href="#comparing-application-output">Comparing application output</a></h2>
<p>A good way to check this is to compare the log output of an application that
was run in Shadow. For example, after running two TGen simulations where the
results are in the <code>shadow.data.1</code> and <code>shadow.data.2</code> directories, you could
run something like the following bash script:</p>
<pre><code class="language-bash">#!/bin/bash

found_difference=0

for SUFFIX in \
    hosts/fileserver/tgen.1000.stdout \
    hosts/client/tgen.1000.stdout
do
    ## ignore memory addresses in log file with `sed 's/0x[0-9a-f]*/HEX/g' FILENAME`
    sed -i 's/0x[0-9a-f]*/HEX/g' shadow.data.1/${SUFFIX}
    sed -i 's/0x[0-9a-f]*/HEX/g' shadow.data.2/${SUFFIX}

    diff --brief shadow.data.1/${SUFFIX} shadow.data.2/${SUFFIX}
    exit_code=$?

    if (($exit_code != 0)); then
      found_difference=1
    fi
done

if (($found_difference == 1)); then
  echo -e "\033[0;31mDetected difference in output (Shadow may be non-deterministic).\033[0m"
else
  echo -e "\033[0;32mDid not detect difference in Shadow output (Shadow may be deterministic).\033[0m"
fi
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="extra-tests-1"><a class="header" href="#extra-tests-1">Extra Tests</a></h1>
<p>Shadow includes tests that require additional dependencies, such as Tor, TGen,
networkx, obfs4proxy, and golang. These aren't run by default, but are run as
part of the CI tests.</p>
<p>To run them locally, first make sure that both tor and tgen are located on your
shell's <code>PATH</code> You should also install all of Shadow's optional dependencies.</p>
<p>To run the golang tests you will need to both install golang, and install
a dynamic version of the golang standard library. The latter can be done with
<code>go install -buildmode=shared -linkshared std</code>.</p>
<p>It is recommended to build Shadow in release mode, otherwise the Tor tests may
not complete before the timeout.</p>
<pre><code class="language-bash">./setup build --test --extra
./setup test --extra
# To exclude the TGen and Tor tests (for example if you built Shadow in debug mode)
./setup test --extra -- --label-exclude "tgen|tor"
# To include only the TGen tests
./setup test --extra tgen
# To run a specific TGen test
./setup test --extra tgen-duration-1mbit_300ms-1000streams-shadow
</code></pre>
<p>If you change the version of tor located at <code>~/.local/bin/tor</code>, make sure to
re-run <code>./setup build --test</code>.</p>
<h2 id="miri"><a class="header" href="#miri">Miri</a></h2>
<pre><code class="language-bash">rustup toolchain install nightly
rustup +nightly component add miri

# Disable isolation for some tests that use the current time (Instant::now).
# Disable leak-checking for now. Some tests intentionally panic, causing leaks.
export MIRIFLAGS="-Zmiri-disable-isolation -Zmiri-ignore-leaks"

(cd src &amp;&amp; cargo +nightly miri test --workspace)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="continuous-integration-tests"><a class="header" href="#continuous-integration-tests">Continuous integration tests</a></h1>
<h2 id="on-github"><a class="header" href="#on-github">On GitHub</a></h2>
<p>Our continuous integration tests build and test Shadow on every supported
platform and configuration. GitHub runs these tests automatically when making
or modifying a pull request, in the <a href="../.github/workflows/build_shadow.yml">build and test
workflow</a>. Pull requests without passing
integration tests are blocked from merging.</p>
<h2 id="running-locally"><a class="header" href="#running-locally">Running locally</a></h2>
<p>We also have scripts for running the continuous integration tests locally,
inside Docker containers. This can be useful for debugging and for quickly
iterating on a test that's failing in GitHub's test runs.</p>
<p>The <a href="../ci/run.sh"><code>run.sh</code></a> script builds shadow inside a Docker image, and
runs our tests in it.</p>
<p>By default, the script will attempt to use a Docker image with already shadow
built, perform an incremental build on top of that, and then run shadow's tests.
If you don't already have a local image, the script will implicitly try to pull
from the <a href="https://hub.docker.com/r/shadowsim/shadow-ci">shadowsim/shadow-ci</a> on
dockerhub. You can override this repo with <code>-r</code> or force the script to build a
new image locally with <code>-i</code>.</p>
<p>For example, to perform an incremental build and test on ubuntu 24.04,
with the gcc compiler in debug mode:</p>
<pre><code class="language-{.bash}">ci/run.sh -c ubuntu:24.04 -C gcc -b debug
</code></pre>
<p>If the tests fail, shadow's build directory, including test outputs, will be copied
from the ephemeral Docker container into <code>ci/build</code>.</p>
<p>For additional options, run <code>ci/run.sh -h</code>.</p>
<h2 id="debugging-locally"><a class="header" href="#debugging-locally">Debugging locally</a></h2>
<p>After a local run fails, you can use Docker to help debug it. If you previously
ran the tests without the <code>-i</code> option, re-run with the <code>-i</code> option to rebuild
the Docker image(s). If Shadow was built successfully and the failure happened
at the testing step, then the Docker image was built and tagged, and you can
run an interactive shell in a container built from that image.</p>
<p>e.g.:</p>
<pre><code class="language-{.bash}">docker run --shm-size=1024g --security-opt=seccomp=unconfined -it shadowsim/shadow-ci:ubuntu-24.04-gcc-debug /bin/bash
</code></pre>
<p>If the failure happened in the middle of building the Docker image, you can do
the same with the last intermediate layer that was built successfully. e.g.
given the output:</p>
<pre><code class="language-{.bash}">$ ci/run.sh -i -c ubuntu:24.04 -C gcc -b debug
&lt;snip&gt;
Step 13/13 : RUN . ci/container_scripts/build_and_install.sh
 ---&gt; Running in a11c4a554ef8
&lt;snip&gt;
    516 [ERROR] Non - zero return code from make.
</code></pre>
<p>You can start a container from the image where Docker tried (and failed) to run
<code>ci/the build_and_install.sh</code> script was executed with:</p>
<pre><code class="language-{.bash}">docker run --shm-size=1024g --security-opt=seccomp=unconfined -it a11c4a554ef8 /bin/bash
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="maintainer-playbook"><a class="header" href="#maintainer-playbook">Maintainer playbook</a></h1>
<h2 id="tagging-shadow-releases"><a class="header" href="#tagging-shadow-releases">Tagging Shadow releases</a></h2>
<p>Before creating a new release, be sure to handle all issues in its
<a href="https://github.com/shadow/shadow/projects?type=classic">GitHub Project</a>.
Issues that can wait until the next release
can be moved to the next release's project (which you may need to create).
Remaining issues should be resolved before continuing with the release process.</p>
<p>We use <a href="https://semver.org/">Semantic Versioning</a>, and increment version
numbers with the <a href="https://pypi.org/project/bumpversion/">bumpversion</a> tool.</p>
<p>The following commands can be used to tag a new version of Shadow, after which
an archive will be available on github's <a href="https://github.com/shadow/shadow/releases">releases
page</a>.</p>
<p>Install bumpversion if needed:</p>
<pre><code>python3 -m venv bumpenv
source bumpenv/bin/activate
pip install -U pip
pip install bumpversion
</code></pre>
<p>Make sure main is up to date:</p>
<pre><code>git checkout main
git pull
</code></pre>
<p>The bumpversion command is run like this (it is recommended to add
<code>--dry-run --verbose</code> until you are confident in the result):</p>
<pre><code>bumpversion --dry-run --verbose &lt;major|minor|patch|release|build&gt;
</code></pre>
<p>Decide which part of the version you are bumping. Our format is
<code>{major}.{minor}.{patch}-{release}.{build}</code>. Bumping earlier parts of the
version will cause later parts to get reset to 0 (or 'pre' for the release
part). For example, if you are at <code>2.0.0</code>, going to <code>2.1.0-pre</code> is easy:</p>
<pre><code>bumpversion minor --tag --commit
</code></pre>
<p>In the above case, we can just tag and commit immediately. But if you are going
from <code>2.0.0</code> to <code>2.1.0</code>, you'll need to either run twice (first to bump the
minor from 0 to 2, then to bump the release from 'pre' to the invisible
'stable'):</p>
<pre><code>bumpversion minor
bumpversion --allow-dirty release --commit --tag
</code></pre>
<p>or use the serialize option to specify the intended format of the next version:</p>
<pre><code>bumpversion minor --serialize '{major}.{minor}.{patch}' --commit --tag
</code></pre>
<p>Now check that things worked and get the new version number:</p>
<pre><code>git log -1 --stat
git describe --tags
VERSION=`awk -F "=" '/current_version/ {print $2}' .bumpversion.cfg | tr -d ' '`
</code></pre>
<p>Update the Cargo lock file, then ammend the commit and tag to include the update
(closely check and update the <code>Bump version: from → to</code> messages as needed):</p>
<pre><code>(cd src &amp;&amp; cargo update --workspace)
git add src/Cargo.lock
git commit --amend
git tag -f -a "v$VERSION"
</code></pre>
<p>Check again:</p>
<pre><code>git log -1 --stat
git describe --tags
</code></pre>
<p>Now if everything looks good, push to GitHub:</p>
<pre><code>git push origin "v$VERSION"
</code></pre>
<p>Our releases will then be tagged off of the main branch.</p>
<p>You probably want to also reset the <code>CHANGELOG.md</code> file in a new commit after
tagging/pushing the release.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="format-of-shadow-log-messages"><a class="header" href="#format-of-shadow-log-messages">Format of Shadow Log Messages</a></h1>
<div class="table-wrapper"><table><thead><tr><th>❗ Warning</th></tr></thead><tbody>
<tr><td>The format of the log messages is not<br>stable and may change at any time.</td></tr>
</tbody></table>
</div><br>
<h2 id="log-line-prefix"><a class="header" href="#log-line-prefix">Log Line Prefix</a></h2>
<p>Shadow produces simulator log messages in the following format:</p>
<pre><code class="language-text">real-time [thread-id:thread-name] virtual-time [loglevel] [hostname:ip] [src-file:line-number] [function-name] MESSAGE
</code></pre>
<ul>
<li><code>real-time</code>:<br />
the wall clock time since the start of the experiment, represented as
<code>hours:minutes:seconds</code></li>
<li><code>thread-id</code>:<br />
the thread id (as returned by <code>gettid</code>) of the system thread that generated
the message.</li>
<li><code>thread-name</code>:<br />
the name of the system thread that generated the message</li>
<li><code>virtual-time</code>:<br />
the simulated time since the start of the experiment, represented as
<code>hours:minutes:seconds</code></li>
<li><code>loglevel</code>:<br />
one of <code>ERROR</code> &lt; <code>WARN</code> &lt; <code>INFO</code> &lt; <code>DEBUG</code> &lt; <code>TRACE</code>, in that order</li>
<li><code>hostname</code>:<br />
the name of the host as specified in <code>hosts.&lt;hostname&gt;</code> of the simulation
config</li>
<li><code>ip</code>:<br />
the IP address of the host as specified in <code>hosts.&lt;hostname&gt;.ip_address_hint</code>
of the simulation config, or a random IP address if one is not specified</li>
<li><code>src-file</code>:<br />
the name of the source code file where the message is logged</li>
<li><code>line-number</code>:<br />
the line number in the source code file where the message is logged</li>
<li><code>function-name</code>:<br />
the name of the function logging the message</li>
<li><code>MESSAGE</code>:<br />
the actual message to be logged</li>
</ul>
<p>By default, Shadow only prints core messages at or below the <a href="shadow_config_spec.html#generallog_level"><code>info</code> log
level</a>. This behavior can be changed
using the Shadow option <code>-l</code> or <code>--log-level</code> to increase or decrease the
verbosity of the output. As mentioned in the example from the previous section,
the output from each application process is stored in separate log files beneath
the <code>shadow.data</code> directory, and the format of those log files is
application-specific (i.e., Shadow writes application output <em>directly</em> to
file).</p>
<h2 id="heartbeat-messages"><a class="header" href="#heartbeat-messages">Heartbeat Messages</a></h2>
<p>Shadow logs simulator heartbeat messages that contain useful system information.
By default, these heartbeats are logged once per second, but the frequency can be
changed using the <code>--heartbeat-frequency</code> option to Shadow (see <code>shadow --help</code>).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parsing-shadow-log-messages"><a class="header" href="#parsing-shadow-log-messages">Parsing Shadow Log Messages</a></h1>
<div class="table-wrapper"><table><thead><tr><th>❗ Warning</th></tr></thead><tbody>
<tr><td>The log messages are considered experimental<br>and may change or be removed at any time.</td></tr>
</tbody></table>
</div><br>
<p>While Shadow may attempt to log messages that contain useful system information,
no attempt is made to keep these message consistent or stable over time. Thus,
the log messages should generally not be parsed by users because any parsing
tools may break at any time when Shadow is updated.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="national-science-foundation-sponsorship"><a class="header" href="#national-science-foundation-sponsorship">National Science Foundation Sponsorship</a></h1>
<p><strong>Project Title:</strong> Expanding Research Frontiers with a Next-Generation Anonymous Communication Experimentation (ACE) Framework</p>
<p><strong>Project Period:</strong> October 1, 2019 - September 30, <del>2022</del> 2023 (extended)</p>
<p><strong>Abstract:</strong> <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1925497">NSF Award Abstract #1925497</a></p>
<p>The goal of this project is to develop a scalable and mature deterministic
network simulator, capable of quickly and accurately simulating large networks
such as <a href="https://www.torproject.org">Tor</a>. This project builds on <a href="https://shadow.github.io/">the Shadow
Simulator</a>.</p>
<h2 id="nsf-project-overview"><a class="header" href="#nsf-project-overview">NSF Project Overview</a></h2>
<p>ACE will be developed with the following features:</p>
<ul>
<li><strong>Application Emulation.</strong> Learning from the community’s experience, ACE will
directly execute software and run applications as normal operating system
processes. By supporting the general execution of applications (i.e.,
anything that can be executed as a process: network servers, web browsers,
scripts, etc.), ACE will support software independent of the programming
language chosen by developers, and ACE will maximize its applicability to a
large range of evaluation approaches that CISE researchers choose to utilize.
As a result, ACE will be well-suited to website fingerprinting and censorship
circumvention research focus areas, which typically require running a variety
of tools written in a variety of languages.</li>
<li><strong>Network Simulation.</strong> ACE will feature a light-weight network simulation
component that will allow applications to communicate with each other through
the ACE framework rather than over the Internet. ACE will simulate common
transport protocols, such as TCP and UDP. ACE will also simulate virtual
network routers and other network path components between end-hosts, and
support evaluation under dynamic changes to timing, congestion, latency,
bandwidth, network location, and network path elements. Therefore, ACE will
support both network-aware and location-aware anonymous communication
research and allow researchers to continue to advance this research agenda in
current and future Internet architectures.</li>
<li><strong>Function Interposition.</strong> ACE will utilize function interposition in order
to connect the processes being run by the operating system to the core
network simulation component. ACE will support an API of common system calls
that are used to, e.g., send and receive data to and from the network.
Therefore, all processes executed in ACE will be isolated from the Internet
and connected through ACE’s simulated network, and the simulation component
will drive process execution.</li>
<li><strong>Controlled, Deterministic Execution.</strong> ACE features a deterministic
discrete-event engine, and will therefore control time and operate in
simulated timescales. As a result, ACE will be disconnected from the
computational abilities of the host machine: ACE will run
as-fast-as-possible, which could be faster or slower than real time depending
on experiment load. ACE is deterministic so that research results can be
independently and identically reproduced and verified across research labs.</li>
<li><strong>Parallel and Distributed Execution.</strong> ACE will rely on the operating system
kernel to run and manage processes. Operating system kernels have been
optimized for this task, and ACE will benefit in terms of better performance
and a smaller code base. Moreover, ACE will be embarrassingly parallel: the
Linux kernel generally scales to millions of processes that can be run in
parallel, and we will design ACE such that any number of processes can be
executed across multiple distinct machines. Therefore, ACE will scale to
realistically-sized anonymous communication networks containing millions of
virtual hosts, and can be deployed on whatever existing infrastructure is
available at community members' institutions.</li>
</ul>
<p>As part of the ACE framework, we will also develop a <strong>user interface</strong> to
control and monitor the experimental process, a <strong>toolkit</strong> to help users set up
and configure experiments (including network, mobility, and traffic
characteristics and models) and to visualize results, and a <strong>data repository</strong>
where researchers can share and archive experimental results.</p>
<h2 id="project-goalsactivities"><a class="header" href="#project-goalsactivities">Project Goals/Activities</a></h2>
<p>Here we outline some high level tasks that we are completing or plan to complete
under this project. We are using Github for project development, including for
tracking progress on major milestones and development tasks. We provide an
outline of our agenda here, and link to the appropriate Github page where
appropriate. Tasks without corresponding Github links means we don't yet have
progress to share at this time.</p>
<ul>
<li>
<p><strong>Task 0: Investigate Architectural Improvements</strong></p>
<ul>
<li>Build prototype of a process-based simulation architecture -
<a href="https://github.com/shadow/shadow/milestone/16">milestone</a></li>
<li>Evaluate and compare against a plugin-based simulation architecture</li>
<li>Decide which architecture is right for ACE</li>
</ul>
</li>
<li>
<p><strong>Task 1: Develop Core ACE System</strong></p>
<ul>
<li>Improve test coverage and infrastructure - <a href="https://github.com/shadow/shadow/milestone/15">shadow
milestone</a>,
<a href="https://github.com/shadow/shadow-plugin-tor/milestone/1">shadow-plugin-tor
milestone</a></li>
<li>Enable new code to be written in Rust -
<a href="https://github.com/shadow/shadow/milestone/17">milestone</a></li>
<li>Improve consistency of simulation options and configuration</li>
<li>Improve maintainability and accuracy of TCP implementation -
<a href="https://github.com/shadow/shadow/milestone/18">milestone</a></li>
<li>Simplify event scheduler, implement continuous event execution model</li>
<li>Build a distributed core simulation engine</li>
<li>Develop CPU usage model to ensure virtual process CPU utilization consumes
simulation time</li>
</ul>
</li>
<li>
<p><strong>Task 2: Develop User Interface and Visualizations</strong></p>
<ul>
<li>Design control protocol and API for interacting with Shadow</li>
<li>Specify/document protocol</li>
<li>Develop user interface that uses the control API</li>
<li>Improve tools for analyzing and understanding simulation results</li>
</ul>
</li>
<li>
<p><strong>Task 3: Develop Simulation Models for ACE</strong></p>
<ul>
<li>Improve tools for generating and configuring private Tor networks</li>
<li>Improve tools for generating and configuring background traffic models</li>
<li>Improve tools for modeling Internet paths and latency</li>
<li>Develop support for mobile hosts</li>
<li>Create realistic host mobility models</li>
</ul>
</li>
<li>
<p><strong>Task 4: Engage Community</strong></p>
<ul>
<li>Create data repository where users can share configs and results</li>
<li>Create user outreach material and surveys to collect feedback</li>
<li>Improve user documentation and usage instructions</li>
</ul>
</li>
</ul>
<p>Over all tasks, we plan to significantly improve documentation, test coverage,
and code maintainability.</p>
<h2 id="people"><a class="header" href="#people">People</a></h2>
<ul>
<li><a href="https://www.robgjansen.com">Rob Jansen</a> - Project Leader, Principal
Investigator, U.S. Naval Research Laboratory</li>
<li>Roger Dingledine - Principal Investigator, The Tor Project</li>
<li>Micah Sherr - Principal Investigator, Georgetown University</li>
<li>Jim Newsome - Developer, The Tor Project</li>
<li>Steven Engler - Developer, Georgetown University / The Tor Project</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
